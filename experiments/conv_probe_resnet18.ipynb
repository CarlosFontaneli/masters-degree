{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvProbe class\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Dataset\n",
    "import sys\n",
    "sys.path.append('/home/fonta42/Desktop/masters-degree/data/vess-map/')\n",
    "from vess_map_dataset import VessMapDataset\n",
    "\n",
    "# Training loop\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import jaccard_score  # For calculating IoU\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvProbe(nn.Module):\n",
    "    def __init__(self, layer_name, output_size=(256, 256), seed=42):\n",
    "        super(ConvProbe, self).__init__()\n",
    "\n",
    "        # Load pre-trained ResNet-18 model\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.layer_name = layer_name\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Freeze model weights\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Initialize the convolutional probe (to be trained)\n",
    "        self.conv_probe = nn.Conv2d(\n",
    "            in_channels=self.get_layer_channels(layer_name), # Use the layer channels\n",
    "            out_channels=2,  # For segmentation output\n",
    "            kernel_size=3,\n",
    "            padding=1  # Add padding to preserve input size\n",
    "        )\n",
    "\n",
    "        # Set a fixed random seed for consistency \n",
    "        self.set_seed(seed)\n",
    "\n",
    "        # Register a hook for the selected layer\n",
    "        self.activations = {}\n",
    "        self.register_hook()\n",
    "\n",
    "    # Set a bunch of seed to consistency training\n",
    "    def set_seed(self, seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    def get_layer_channels(self, layer_name):\n",
    "        # Helper function to get the number of channels for the specified layer\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == layer_name:\n",
    "                if isinstance(module, nn.Conv2d) or isinstance(module, nn.BatchNorm2d) or isinstance(module, nn.ReLU):\n",
    "                    return module.out_channels\n",
    "                elif isinstance(module, nn.Sequential):\n",
    "                    # For sequential layers, get the out_channels of the last module\n",
    "                    return list(module.children())[-1].out_channels\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported module type: {type(module)} for layer {layer_name}\")\n",
    "        raise ValueError(f\"Layer {layer_name} not found in the model.\")\n",
    "\n",
    "    def register_hook(self):\n",
    "        def hook_fn(module, input, output):\n",
    "            self.activations[self.layer_name] = output\n",
    "\n",
    "        # Register the hook\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == self.layer_name:\n",
    "                module.register_forward_hook(hook_fn)\n",
    "                break\n",
    "\n",
    "    def forward(self, x):\n",
    "        _ = self.model(x)  # Forward pass to get activations\n",
    "        activation = self.activations[self.layer_name]  # Get hooked activation\n",
    "\n",
    "        # Interpolate activation to match input size\n",
    "        activation = F.interpolate(\n",
    "            activation, size=self.output_size, mode='bilinear', align_corners=False\n",
    "        )\n",
    "\n",
    "        # Apply convolutional probe\n",
    "        out = self.conv_probe(activation)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "image_dir = '/home/fonta42/Desktop/masters-degree/data/vess-map/images'\n",
    "mask_dir = '/home/fonta42/Desktop/masters-degree/data/vess-map/labels'\n",
    "skeleton_dir = '/home/fonta42/Desktop/masters-degree/data/vess-map/skeletons'\n",
    "\n",
    "image_size = 256\n",
    "\n",
    "# Initialize the dataset\n",
    "vess_dataset = VessMapDataset(image_dir, mask_dir, skeleton_dir, image_size, apply_transform=True)\n",
    "\n",
    "# Get the train and test loaders\n",
    "train_loader, test_loader = vess_dataset.vess_map_dataloader(batch_size=4, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IoU calculation function\n",
    "def calculate_iou(preds, labels):\n",
    "    preds = torch.argmax(preds, dim=1)  \n",
    "    preds = preds.cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "\n",
    "    preds_flat = preds.flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    iou = jaccard_score(labels_flat, preds_flat, average='macro')\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'layer1.0.conv1'  \n",
    "\n",
    "# Initialize the ConvProbe model\n",
    "probe_model = ConvProbe(layer_name=layer_name, output_size=(image_size, image_size), seed=42)\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "probe_model.to(device)\n",
    "\n",
    "# Define loss function (Cross Entropy Loss for multi-class segmentation)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(probe_model.conv_probe.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Track the best IoU\n",
    "best_iou = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    probe_model.train()\n",
    "    running_loss = 0.0\n",
    "    train_iou = 0.0\n",
    "    \n",
    "    # Training loop\n",
    "    for inputs, masks, _ in train_loader:  # Assuming skeletons are not needed\n",
    "        inputs = inputs.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = probe_model(inputs)\n",
    "\n",
    "        # Compute loss (use masks with long type for CrossEntropyLoss)\n",
    "        masks = masks.squeeze(1)  # Shape: [batch_size, height, width]\n",
    "        loss = criterion(outputs, masks.long())\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Compute IoU for this batch\n",
    "        batch_iou = calculate_iou(outputs, masks)\n",
    "        train_iou += batch_iou * inputs.size(0)\n",
    "\n",
    "    # Calculate epoch loss and IoU\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_iou = train_iou / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Train IoU: {epoch_iou:.4f}')\n",
    "\n",
    "    # Validation loop\n",
    "    probe_model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_iou = 0.0\n",
    "    with torch.no_grad():  # Disable gradient calculations during validation\n",
    "        for val_inputs, val_masks, _ in test_loader:  # Assuming skeletons are not needed\n",
    "            val_inputs = val_inputs.to(device)\n",
    "            val_masks = val_masks.to(device)\n",
    "            val_masks = val_masks.squeeze(1)  # Shape: [batch_size, height, width]\n",
    "\n",
    "            # Forward pass\n",
    "            val_outputs = probe_model(val_inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            val_loss += criterion(val_outputs, val_masks.long()).item() * val_inputs.size(0)\n",
    "\n",
    "            # Compute IoU for this batch\n",
    "            batch_val_iou = calculate_iou(val_outputs, val_masks)\n",
    "            val_iou += batch_val_iou * val_inputs.size(0)\n",
    "\n",
    "    # Calculate validation loss and IoU\n",
    "    val_loss /= len(test_loader.dataset)\n",
    "    val_iou /= len(test_loader.dataset)\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation IoU: {val_iou:.4f}')\n",
    "\n",
    "    # Save the model if the IoU on validation set improves\n",
    "    if val_iou > best_iou:\n",
    "        best_iou = val_iou\n",
    "        torch.save(probe_model.state_dict(), f\"best_model_layer_{layer_name}.pth\")\n",
    "\n",
    "print('Training complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mestrado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
