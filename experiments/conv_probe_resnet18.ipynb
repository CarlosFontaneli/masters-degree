{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvProbe class\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Dataset\n",
    "import sys\n",
    "sys.path.append('/home/fonta42/Desktop/masters-degree/data/vess-map/')\n",
    "from vess_map_dataset import VessMapDataset\n",
    "\n",
    "# Training loop\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import jaccard_score  # For calculating IoU\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Save the results\n",
    "import json\n",
    "\n",
    "# Clear memory\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvProbe(nn.Module):\n",
    "    def __init__(self, model, layer_name, output_size=(256, 256), seed=None, single_channel=True):\n",
    "        super(ConvProbe, self).__init__()\n",
    "\n",
    "        # Load pre-trained ResNet-18 model\n",
    "        self.model =  model\n",
    "        self.layer_name = layer_name\n",
    "        self.output_size = output_size\n",
    "        self.single_channel = single_channel\n",
    "\n",
    "        # Freeze model weights to prevent training\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Get number of channels from the specified layer\n",
    "        in_channels = 1 if self.single_channel else self.get_layer_channels(layer_name)\n",
    "\n",
    "\n",
    "        # Initialize the first convolutional layer (to be trained)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,  # Numbers of channels for the activation\n",
    "            out_channels=16,  # TODO: check if 16 is ok\n",
    "            kernel_size=3,\n",
    "            padding=1  # Preserve spatial dimensions\n",
    "        )\n",
    "\n",
    "        # Initialize the second convolutional layer (to be trained)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=16,  # Input channels from conv1\n",
    "            out_channels=1,  # Single output channel for binary segmentation\n",
    "            kernel_size=3,\n",
    "            padding=1  # Preserve spatial dimensions\n",
    "        )\n",
    "\n",
    "        # Set a fixed random seed for consistency, if provided\n",
    "        if seed is not None:\n",
    "            self.set_seed(seed)\n",
    "\n",
    "        # Register a hook to capture activations from the specified layer\n",
    "        self.activations = {}\n",
    "        self.register_hook()\n",
    "\n",
    "    # Helper function to set random seed\n",
    "    def set_seed(self, seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Helper function to get the number of channels from the specified layer\n",
    "    def get_layer_channels(self, layer_name):\n",
    "        # Iterate over the named modules to find the specified layer\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == layer_name:\n",
    "                if hasattr(module, 'out_channels'):\n",
    "                    return module.out_channels\n",
    "                elif hasattr(module, 'num_features'):\n",
    "                    return module.num_features  # For BatchNorm layers\n",
    "                else:\n",
    "                    raise ValueError(f\"Layer {layer_name} does not have out_channels or num_features.\")\n",
    "        raise ValueError(f\"Layer {layer_name} not found.\")\n",
    "\n",
    "    # Register a forward hook to capture activations\n",
    "    def register_hook(self):\n",
    "        def hook_fn(module, input, output):\n",
    "            self.activations[self.layer_name] = output\n",
    "\n",
    "        # Register the hook on the specified layer\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == self.layer_name:\n",
    "                module.register_forward_hook(hook_fn)\n",
    "                break\n",
    "\n",
    "    # Forward pass through the model\n",
    "    def forward(self, x, channel_idx=None):\n",
    "        _ = self.model(x)  # Forward pass to get activations\n",
    "        activation = self.activations[self.layer_name]  # Retrieve the stored activation\n",
    "\n",
    "        # Select a specific channel if provided\n",
    "        if channel_idx is not None:\n",
    "            if channel_idx < 0 or channel_idx >= activation.size(1):\n",
    "                raise ValueError(f\"Channel index {channel_idx} is out of bounds for activation with {activation.size(1)} channels.\")\n",
    "            activation = activation[:, channel_idx:channel_idx+1, :, :]  # Select the specific channel\n",
    "\n",
    "        # Apply the first convolutional layer\n",
    "        activation = self.conv1(activation)\n",
    "\n",
    "        # Interpolate activation to match the desired output size\n",
    "        activation = F.interpolate(activation, size=self.output_size, mode='bilinear', align_corners=True)\n",
    "\n",
    "        # Apply the second convolutional layer\n",
    "        out = self.conv2(activation) # TODO: add a second conv\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "image_dir = '/home/fonta42/Desktop/masters-degree/data/vess-map/images'\n",
    "mask_dir = '/home/fonta42/Desktop/masters-degree/data/vess-map/labels'\n",
    "skeleton_dir = '/home/fonta42/Desktop/masters-degree/data/vess-map/skeletons'\n",
    "\n",
    "image_size = 256\n",
    "\n",
    "# Initialize the dataset\n",
    "vess_dataset = VessMapDataset(image_dir, mask_dir, skeleton_dir, image_size, apply_transform=True)\n",
    "\n",
    "# Get the train and test loaders\n",
    "train_loader, test_loader = vess_dataset.vess_map_dataloader(batch_size=32, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(outputs, masks, threshold=0.5):\n",
    "    # Apply sigmoid to outputs to get probabilities between 0 and 1\n",
    "    preds = torch.sigmoid(outputs)\n",
    "    preds = (preds > threshold).float()  # Convert probabilities to binary predictions\n",
    "\n",
    "    # Ensure masks are float type\n",
    "    masks = masks.float()\n",
    "\n",
    "    # Compute intersection and union\n",
    "    intersection = (preds * masks).sum(dim=(1, 2))\n",
    "    union = ((preds + masks) > 0).float().sum(dim=(1, 2))\n",
    "\n",
    "    # Avoid division by zero\n",
    "    iou = torch.where(union == 0, torch.tensor(1.0).to(outputs.device), intersection / union)\n",
    "\n",
    "    # Return mean IoU over the batch\n",
    "    return iou.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_conv_probe_all_channels(model, layer_name, num_channels, train_loader, test_loader, image_size, device, num_epochs=50, lr=0.001, single_channel=True):\n",
    "    iou_results = {}  # Dictionary to store IoU results for each channel\n",
    "\n",
    "    for channel_idx in range(num_channels):\n",
    "        print(f\"Training for channel {channel_idx} of layer {layer_name}\")\n",
    "        probe_model = ConvProbe(model=model, layer_name=layer_name, output_size=(\n",
    "            image_size, image_size), seed=42, single_channel=single_channel)\n",
    "        probe_model.to(device)\n",
    "\n",
    "        # BinaryCEWithLogitsLoss for binary segmentation\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Define optimizer for ConvProbe parameters only #TODO adjust to train only convprobe parameters\n",
    "        optimizer = optim.Adam(list(probe_model.conv1.parameters(\n",
    "        )) + list(probe_model.conv2.parameters()), lr=lr)\n",
    "\n",
    "        # TODO: save metrics for every epoch\n",
    "\n",
    "        # Track metrics for this channel\n",
    "        train_losses = []\n",
    "        train_ious = []\n",
    "        val_losses = []\n",
    "        val_ious = []\n",
    "\n",
    "        # Get a sample image from the validation loader for saving outputs\n",
    "        sample_inputs, sample_masks, _ = next(iter(test_loader))\n",
    "        sample_inputs = sample_inputs.to(device)[:1]  # Take one sample\n",
    "        sample_masks = sample_masks.to(device).float()[:1]\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            probe_model.train()\n",
    "            running_loss = 0.0\n",
    "            train_iou = 0.0\n",
    "\n",
    "            # Training loop\n",
    "            for inputs, masks, _ in train_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                masks = masks.to(device).float()  # Ensure masks are float type\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if single_channel:\n",
    "                    # Forward pass using the current channel\n",
    "                    outputs = probe_model(inputs, channel_idx=channel_idx)\n",
    "                else:\n",
    "                    outputs = probe_model(inputs)\n",
    "\n",
    "                # Shape: [batch_size, height, width]\n",
    "                outputs = outputs.squeeze(1)\n",
    "                # Shape: [batch_size, height, width]\n",
    "                masks = masks.squeeze(1)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, masks)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Accumulate running loss\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Compute IoU for this batch\n",
    "                batch_iou = calculate_iou(outputs, masks)\n",
    "                train_iou += batch_iou * inputs.size(0)\n",
    "\n",
    "            # Calculate epoch loss and IoU\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            epoch_iou = train_iou / len(train_loader.dataset)\n",
    "            print(\n",
    "                f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Train IoU: {epoch_iou:.4f}')\n",
    "\n",
    "            # Append metrics\n",
    "            train_losses.append(epoch_loss)\n",
    "            train_ious.append(epoch_iou)\n",
    "\n",
    "            # Validation loop\n",
    "            probe_model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_iou = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_masks, _ in test_loader:\n",
    "                    val_inputs = val_inputs.to(device)\n",
    "                    # Ensure masks are float type\n",
    "                    val_masks = val_masks.to(device).float()\n",
    "\n",
    "                    # Forward pass using the current channel\n",
    "                    if single_channel:\n",
    "                        val_outputs = probe_model(\n",
    "                            val_inputs, channel_idx=channel_idx)\n",
    "                    else:\n",
    "                        val_outputs = probe_model(val_inputs)\n",
    "\n",
    "                    # Shape: [batch_size, height, width]\n",
    "                    val_outputs = val_outputs.squeeze(1)\n",
    "                    # Shape: [batch_size, height, width]\n",
    "                    val_masks = val_masks.squeeze(1)\n",
    "\n",
    "                    # Compute loss\n",
    "                    loss = criterion(val_outputs, val_masks)\n",
    "                    val_loss += loss.item() * val_inputs.size(0)\n",
    "\n",
    "                    # Compute IoU for this batch\n",
    "                    batch_val_iou = calculate_iou(val_outputs, val_masks)\n",
    "                    val_iou += batch_val_iou * val_inputs.size(0)\n",
    "\n",
    "            # Calculate validation loss and IoU\n",
    "            val_loss /= len(test_loader.dataset)\n",
    "            val_iou /= len(test_loader.dataset)\n",
    "            print(\n",
    "                f'Validation Loss: {val_loss:.4f}, Validation IoU: {val_iou:.4f}')\n",
    "\n",
    "            # Append validation metrics\n",
    "            val_losses.append(val_loss)\n",
    "            val_ious.append(val_iou)\n",
    "\n",
    "            # Save model output on sample image for debugging\n",
    "            with torch.no_grad():\n",
    "                if single_channel:\n",
    "                    sample_output = probe_model(\n",
    "                        sample_inputs, channel_idx=channel_idx)\n",
    "                else:\n",
    "                    sample_output = probe_model(\n",
    "                        sample_inputs)\n",
    "                sample_output = sample_output.squeeze(1)\n",
    "                sample_output_np = sample_output.cpu().numpy()[0]\n",
    "\n",
    "                if epoch == num_epochs - 1 and val_iou < 0.0001:\n",
    "                    # Save the image\n",
    "                    plt.imsave(\n",
    "                        f\"./conv-probe-debbug/output_layer_{layer_name}_channel_{channel_idx}_epoch_{epoch+1}.png\", sample_output_np, cmap='gray')\n",
    "\n",
    "        # Save per-epoch metrics for this channel\n",
    "        iou_results[channel_idx] = {\n",
    "            'train_loss': train_losses,\n",
    "            'train_iou': train_ious,\n",
    "            'val_loss': val_losses,\n",
    "            'val_iou': val_ious\n",
    "        }\n",
    "\n",
    "        # Free GPU memory after training for the current channel is completed\n",
    "        del probe_model, optimizer, criterion\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        if not single_channel:\n",
    "            break\n",
    "\n",
    "    del train_loader, test_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return iou_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get layer names and number of channels from ResNet-18\n",
    "def get_resnet18_layers_info():\n",
    "    resnet18 = models.resnet18(pretrained=True)\n",
    "    layers_info = {}\n",
    "    for name, module in resnet18.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.BatchNorm2d)):\n",
    "            if hasattr(module, 'out_channels'):\n",
    "                out_channels = module.out_channels\n",
    "            elif hasattr(module, 'num_features'):\n",
    "                out_channels = module.num_features\n",
    "            else:\n",
    "                continue\n",
    "            layers_info[name] = out_channels\n",
    "    return layers_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save results to a JSON file\n",
    "def save_results_to_json(results, filename):\n",
    "    # Convert tensors or numpy types to native Python types\n",
    "    def convert(o):\n",
    "        if isinstance(o, np.float32) or isinstance(o, np.float64):\n",
    "            return float(o)\n",
    "        if isinstance(o, torch.Tensor):\n",
    "            return o.item()\n",
    "        raise TypeError\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(results, f, default=convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the probe for all layers and collect results\n",
    "def train_conv_probe_all_layers(train_loader, test_loader, image_size, device, num_epochs=20, lr=0.001):\n",
    "    all_layers_iou_results = {}\n",
    "    layers_info = get_resnet18_layers_info()\n",
    "    for layer_name, num_channels in layers_info.items():\n",
    "        print(f\"\\nProcessing layer: {layer_name} with {num_channels} channels\")\n",
    "        \n",
    "        # Declare the model to use\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        iou_results = train_conv_probe_all_channels(\n",
    "            model=model,\n",
    "            layer_name=layer_name,\n",
    "            num_channels=num_channels,\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            image_size=image_size,\n",
    "            device=device,\n",
    "            num_epochs=num_epochs,\n",
    "            lr=lr\n",
    "        )\n",
    "        \n",
    "        save_results_to_json(iou_results, f'./conv-probe-layers-results/{layer_name}_activation_results.json') #TODO salvar por canal/camada\n",
    "        all_layers_iou_results[layer_name] = iou_results\n",
    "        \n",
    "        # Free GPU memory\n",
    "        torch.cuda.memory_reserved(device=device)\n",
    "        torch.cuda.memory_allocated(device=device)\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()  # Collect unused GPU memory\n",
    "        break #TODO: remove\n",
    "    save_results_to_json(all_layers_iou_results, './conv-probe-layers-results/resnet18_layers_iou_results.json') #TODO salvar por canal/camada\n",
    "\n",
    "\n",
    "    return all_layers_iou_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fonta42/miniconda3/envs/mestrado/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/fonta42/miniconda3/envs/mestrado/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing layer: conv1 with 64 channels\n",
      "Training for channel 0 of layer conv1\n",
      "Epoch 1/50, Loss: 0.6707, Train IoU: 0.0990\n",
      "Validation Loss: 0.5855, Validation IoU: 0.0000\n",
      "Epoch 2/50, Loss: 0.5663, Train IoU: 0.0000\n",
      "Validation Loss: 0.5496, Validation IoU: 0.0001\n",
      "Epoch 3/50, Loss: 0.5596, Train IoU: 0.0000\n",
      "Validation Loss: 0.5766, Validation IoU: 0.0000\n",
      "Epoch 4/50, Loss: 0.5658, Train IoU: 0.0000\n",
      "Validation Loss: 0.5557, Validation IoU: 0.0000\n",
      "Epoch 5/50, Loss: 0.5482, Train IoU: 0.0002\n",
      "Validation Loss: 0.5375, Validation IoU: 0.0001\n",
      "Epoch 6/50, Loss: 0.5418, Train IoU: 0.0024\n",
      "Validation Loss: 0.5410, Validation IoU: 0.0025\n",
      "Epoch 7/50, Loss: 0.5448, Train IoU: 0.0084\n",
      "Validation Loss: 0.5431, Validation IoU: 0.0047\n",
      "Epoch 8/50, Loss: 0.5404, Train IoU: 0.0100\n",
      "Validation Loss: 0.5381, Validation IoU: 0.0030\n",
      "Epoch 9/50, Loss: 0.5385, Train IoU: 0.0076\n",
      "Validation Loss: 0.5338, Validation IoU: 0.0021\n",
      "Epoch 10/50, Loss: 0.5370, Train IoU: 0.0065\n",
      "Validation Loss: 0.5348, Validation IoU: 0.0028\n",
      "Epoch 11/50, Loss: 0.5388, Train IoU: 0.0082\n",
      "Validation Loss: 0.5406, Validation IoU: 0.0053\n",
      "Epoch 12/50, Loss: 0.5351, Train IoU: 0.0146\n",
      "Validation Loss: 0.5369, Validation IoU: 0.0096\n",
      "Epoch 13/50, Loss: 0.5336, Train IoU: 0.0223\n",
      "Validation Loss: 0.5359, Validation IoU: 0.0170\n",
      "Epoch 14/50, Loss: 0.5367, Train IoU: 0.0259\n",
      "Validation Loss: 0.5296, Validation IoU: 0.0152\n",
      "Epoch 15/50, Loss: 0.5358, Train IoU: 0.0242\n",
      "Validation Loss: 0.5336, Validation IoU: 0.0124\n",
      "Epoch 16/50, Loss: 0.5341, Train IoU: 0.0200\n",
      "Validation Loss: 0.5299, Validation IoU: 0.0117\n",
      "Epoch 17/50, Loss: 0.5379, Train IoU: 0.0168\n",
      "Validation Loss: 0.5276, Validation IoU: 0.0099\n",
      "Epoch 18/50, Loss: 0.5323, Train IoU: 0.0182\n",
      "Validation Loss: 0.5263, Validation IoU: 0.0109\n",
      "Epoch 19/50, Loss: 0.5349, Train IoU: 0.0203\n",
      "Validation Loss: 0.5337, Validation IoU: 0.0139\n",
      "Epoch 20/50, Loss: 0.5352, Train IoU: 0.0224\n",
      "Validation Loss: 0.5301, Validation IoU: 0.0136\n",
      "Epoch 21/50, Loss: 0.5352, Train IoU: 0.0219\n",
      "Validation Loss: 0.5300, Validation IoU: 0.0118\n",
      "Epoch 22/50, Loss: 0.5322, Train IoU: 0.0209\n",
      "Validation Loss: 0.5369, Validation IoU: 0.0113\n",
      "Epoch 23/50, Loss: 0.5333, Train IoU: 0.0188\n",
      "Validation Loss: 0.5263, Validation IoU: 0.0114\n",
      "Epoch 24/50, Loss: 0.5325, Train IoU: 0.0183\n",
      "Validation Loss: 0.5279, Validation IoU: 0.0112\n",
      "Epoch 25/50, Loss: 0.5351, Train IoU: 0.0194\n",
      "Validation Loss: 0.5326, Validation IoU: 0.0098\n",
      "Epoch 26/50, Loss: 0.5358, Train IoU: 0.0187\n",
      "Validation Loss: 0.5330, Validation IoU: 0.0112\n",
      "Epoch 27/50, Loss: 0.5354, Train IoU: 0.0192\n",
      "Validation Loss: 0.5333, Validation IoU: 0.0143\n",
      "Epoch 28/50, Loss: 0.5322, Train IoU: 0.0238\n",
      "Validation Loss: 0.5288, Validation IoU: 0.0135\n",
      "Epoch 29/50, Loss: 0.5339, Train IoU: 0.0220\n",
      "Validation Loss: 0.5280, Validation IoU: 0.0116\n",
      "Epoch 30/50, Loss: 0.5330, Train IoU: 0.0204\n",
      "Validation Loss: 0.5335, Validation IoU: 0.0102\n",
      "Epoch 31/50, Loss: 0.5321, Train IoU: 0.0192\n",
      "Validation Loss: 0.5308, Validation IoU: 0.0106\n",
      "Epoch 32/50, Loss: 0.5321, Train IoU: 0.0199\n",
      "Validation Loss: 0.5298, Validation IoU: 0.0119\n",
      "Epoch 33/50, Loss: 0.5296, Train IoU: 0.0213\n",
      "Validation Loss: 0.5319, Validation IoU: 0.0123\n",
      "Epoch 34/50, Loss: 0.5331, Train IoU: 0.0211\n",
      "Validation Loss: 0.5230, Validation IoU: 0.0137\n",
      "Epoch 35/50, Loss: 0.5334, Train IoU: 0.0215\n",
      "Validation Loss: 0.5321, Validation IoU: 0.0131\n",
      "Epoch 36/50, Loss: 0.5334, Train IoU: 0.0202\n",
      "Validation Loss: 0.5359, Validation IoU: 0.0105\n",
      "Epoch 37/50, Loss: 0.5322, Train IoU: 0.0207\n",
      "Validation Loss: 0.5343, Validation IoU: 0.0127\n",
      "Epoch 38/50, Loss: 0.5315, Train IoU: 0.0218\n",
      "Validation Loss: 0.5332, Validation IoU: 0.0142\n",
      "Epoch 39/50, Loss: 0.5351, Train IoU: 0.0216\n",
      "Validation Loss: 0.5282, Validation IoU: 0.0135\n",
      "Epoch 40/50, Loss: 0.5343, Train IoU: 0.0210\n",
      "Validation Loss: 0.5332, Validation IoU: 0.0116\n",
      "Epoch 41/50, Loss: 0.5333, Train IoU: 0.0203\n",
      "Validation Loss: 0.5291, Validation IoU: 0.0117\n",
      "Epoch 42/50, Loss: 0.5338, Train IoU: 0.0227\n",
      "Validation Loss: 0.5306, Validation IoU: 0.0144\n",
      "Epoch 43/50, Loss: 0.5351, Train IoU: 0.0252\n",
      "Validation Loss: 0.5287, Validation IoU: 0.0170\n",
      "Epoch 44/50, Loss: 0.5336, Train IoU: 0.0227\n",
      "Validation Loss: 0.5378, Validation IoU: 0.0100\n",
      "Epoch 45/50, Loss: 0.5355, Train IoU: 0.0186\n",
      "Validation Loss: 0.5290, Validation IoU: 0.0093\n",
      "Epoch 46/50, Loss: 0.5311, Train IoU: 0.0202\n",
      "Validation Loss: 0.5254, Validation IoU: 0.0133\n",
      "Epoch 47/50, Loss: 0.5321, Train IoU: 0.0221\n",
      "Validation Loss: 0.5341, Validation IoU: 0.0139\n",
      "Epoch 48/50, Loss: 0.5303, Train IoU: 0.0225\n",
      "Validation Loss: 0.5247, Validation IoU: 0.0143\n",
      "Epoch 49/50, Loss: 0.5315, Train IoU: 0.0211\n",
      "Validation Loss: 0.5318, Validation IoU: 0.0133\n",
      "Epoch 50/50, Loss: 0.5290, Train IoU: 0.0216\n",
      "Validation Loss: 0.5289, Validation IoU: 0.0139\n",
      "Training for channel 1 of layer conv1\n",
      "Epoch 1/50, Loss: 0.6694, Train IoU: 0.1046\n",
      "Validation Loss: 0.5627, Validation IoU: 0.0002\n",
      "Epoch 2/50, Loss: 0.5449, Train IoU: 0.0006\n",
      "Validation Loss: 0.5278, Validation IoU: 0.0011\n",
      "Epoch 3/50, Loss: 0.5282, Train IoU: 0.0046\n",
      "Validation Loss: 0.5210, Validation IoU: 0.0185\n",
      "Epoch 4/50, Loss: 0.5068, Train IoU: 0.0406\n",
      "Validation Loss: 0.4863, Validation IoU: 0.0913\n",
      "Epoch 5/50, Loss: 0.4831, Train IoU: 0.1299\n",
      "Validation Loss: 0.4669, Validation IoU: 0.2185\n",
      "Epoch 6/50, Loss: 0.4783, Train IoU: 0.2273\n",
      "Validation Loss: 0.4639, Validation IoU: 0.2672\n",
      "Epoch 7/50, Loss: 0.4709, Train IoU: 0.2539\n",
      "Validation Loss: 0.4565, Validation IoU: 0.2468\n",
      "Epoch 8/50, Loss: 0.4599, Train IoU: 0.2292\n",
      "Validation Loss: 0.4567, Validation IoU: 0.2058\n",
      "Epoch 9/50, Loss: 0.4620, Train IoU: 0.2069\n",
      "Validation Loss: 0.4499, Validation IoU: 0.2116\n",
      "Epoch 10/50, Loss: 0.4562, Train IoU: 0.2202\n",
      "Validation Loss: 0.4457, Validation IoU: 0.2432\n",
      "Epoch 11/50, Loss: 0.4510, Train IoU: 0.2551\n",
      "Validation Loss: 0.4517, Validation IoU: 0.2760\n",
      "Epoch 12/50, Loss: 0.4524, Train IoU: 0.2828\n",
      "Validation Loss: 0.4472, Validation IoU: 0.3070\n",
      "Epoch 13/50, Loss: 0.4514, Train IoU: 0.2895\n",
      "Validation Loss: 0.4485, Validation IoU: 0.2777\n",
      "Epoch 14/50, Loss: 0.4517, Train IoU: 0.2698\n",
      "Validation Loss: 0.4377, Validation IoU: 0.2638\n",
      "Epoch 15/50, Loss: 0.4521, Train IoU: 0.2565\n",
      "Validation Loss: 0.4464, Validation IoU: 0.2535\n",
      "Epoch 16/50, Loss: 0.4500, Train IoU: 0.2655\n",
      "Validation Loss: 0.4400, Validation IoU: 0.2819\n",
      "Epoch 17/50, Loss: 0.4507, Train IoU: 0.2765\n",
      "Validation Loss: 0.4370, Validation IoU: 0.2859\n",
      "Epoch 18/50, Loss: 0.4437, Train IoU: 0.2845\n",
      "Validation Loss: 0.4335, Validation IoU: 0.2886\n",
      "Epoch 19/50, Loss: 0.4484, Train IoU: 0.2789\n",
      "Validation Loss: 0.4421, Validation IoU: 0.2751\n",
      "Epoch 20/50, Loss: 0.4459, Train IoU: 0.2751\n",
      "Validation Loss: 0.4359, Validation IoU: 0.2771\n",
      "Epoch 21/50, Loss: 0.4465, Train IoU: 0.2758\n",
      "Validation Loss: 0.4389, Validation IoU: 0.2774\n",
      "Epoch 22/50, Loss: 0.4450, Train IoU: 0.2742\n",
      "Validation Loss: 0.4450, Validation IoU: 0.2749\n",
      "Epoch 23/50, Loss: 0.4471, Train IoU: 0.2687\n",
      "Validation Loss: 0.4345, Validation IoU: 0.2740\n",
      "Epoch 24/50, Loss: 0.4439, Train IoU: 0.2746\n",
      "Validation Loss: 0.4371, Validation IoU: 0.2785\n",
      "Epoch 25/50, Loss: 0.4460, Train IoU: 0.2778\n",
      "Validation Loss: 0.4400, Validation IoU: 0.2705\n",
      "Epoch 26/50, Loss: 0.4472, Train IoU: 0.2660\n",
      "Validation Loss: 0.4398, Validation IoU: 0.2672\n",
      "Epoch 27/50, Loss: 0.4469, Train IoU: 0.2680\n",
      "Validation Loss: 0.4453, Validation IoU: 0.2894\n",
      "Epoch 28/50, Loss: 0.4444, Train IoU: 0.2925\n",
      "Validation Loss: 0.4363, Validation IoU: 0.2917\n",
      "Epoch 29/50, Loss: 0.4454, Train IoU: 0.2872\n",
      "Validation Loss: 0.4303, Validation IoU: 0.2979\n",
      "Epoch 30/50, Loss: 0.4436, Train IoU: 0.2803\n",
      "Validation Loss: 0.4378, Validation IoU: 0.2814\n",
      "Epoch 31/50, Loss: 0.4447, Train IoU: 0.2703\n",
      "Validation Loss: 0.4369, Validation IoU: 0.2783\n",
      "Epoch 32/50, Loss: 0.4428, Train IoU: 0.2776\n",
      "Validation Loss: 0.4347, Validation IoU: 0.2860\n",
      "Epoch 33/50, Loss: 0.4429, Train IoU: 0.2693\n",
      "Validation Loss: 0.4403, Validation IoU: 0.2769\n",
      "Epoch 34/50, Loss: 0.4414, Train IoU: 0.2844\n",
      "Validation Loss: 0.4305, Validation IoU: 0.2844\n",
      "Epoch 35/50, Loss: 0.4427, Train IoU: 0.2817\n",
      "Validation Loss: 0.4372, Validation IoU: 0.2807\n",
      "Epoch 36/50, Loss: 0.4416, Train IoU: 0.2740\n",
      "Validation Loss: 0.4427, Validation IoU: 0.2698\n",
      "Epoch 37/50, Loss: 0.4409, Train IoU: 0.2789\n",
      "Validation Loss: 0.4431, Validation IoU: 0.2851\n",
      "Epoch 38/50, Loss: 0.4374, Train IoU: 0.2995\n",
      "Validation Loss: 0.4374, Validation IoU: 0.3000\n",
      "Epoch 39/50, Loss: 0.4440, Train IoU: 0.2838\n",
      "Validation Loss: 0.4394, Validation IoU: 0.2792\n",
      "Epoch 40/50, Loss: 0.4464, Train IoU: 0.2707\n",
      "Validation Loss: 0.4419, Validation IoU: 0.2758\n",
      "Epoch 41/50, Loss: 0.4412, Train IoU: 0.2840\n",
      "Validation Loss: 0.4332, Validation IoU: 0.2998\n",
      "Epoch 42/50, Loss: 0.4418, Train IoU: 0.3046\n",
      "Validation Loss: 0.4398, Validation IoU: 0.3146\n",
      "Epoch 43/50, Loss: 0.4458, Train IoU: 0.3097\n",
      "Validation Loss: 0.4353, Validation IoU: 0.2943\n",
      "Epoch 44/50, Loss: 0.4439, Train IoU: 0.2813\n",
      "Validation Loss: 0.4448, Validation IoU: 0.2613\n",
      "Epoch 45/50, Loss: 0.4434, Train IoU: 0.2662\n",
      "Validation Loss: 0.4348, Validation IoU: 0.2827\n",
      "Epoch 46/50, Loss: 0.4394, Train IoU: 0.2860\n",
      "Validation Loss: 0.4356, Validation IoU: 0.3052\n",
      "Epoch 47/50, Loss: 0.4424, Train IoU: 0.3120\n",
      "Validation Loss: 0.4401, Validation IoU: 0.3042\n",
      "Epoch 48/50, Loss: 0.4403, Train IoU: 0.2905\n",
      "Validation Loss: 0.4331, Validation IoU: 0.2770\n",
      "Epoch 49/50, Loss: 0.4399, Train IoU: 0.2813\n",
      "Validation Loss: 0.4360, Validation IoU: 0.2822\n",
      "Epoch 50/50, Loss: 0.4365, Train IoU: 0.2815\n",
      "Validation Loss: 0.4366, Validation IoU: 0.2864\n",
      "Training for channel 2 of layer conv1\n",
      "Epoch 1/50, Loss: 0.6680, Train IoU: 0.0986\n",
      "Validation Loss: 0.5662, Validation IoU: 0.0000\n",
      "Epoch 2/50, Loss: 0.5525, Train IoU: 0.0000\n",
      "Validation Loss: 0.5532, Validation IoU: 0.0000\n",
      "Epoch 3/50, Loss: 0.5647, Train IoU: 0.0000\n",
      "Validation Loss: 0.5819, Validation IoU: 0.0000\n",
      "Epoch 4/50, Loss: 0.5710, Train IoU: 0.0000\n",
      "Validation Loss: 0.5628, Validation IoU: 0.0000\n",
      "Epoch 5/50, Loss: 0.5557, Train IoU: 0.0000\n",
      "Validation Loss: 0.5453, Validation IoU: 0.0000\n",
      "Epoch 6/50, Loss: 0.5489, Train IoU: 0.0000\n",
      "Validation Loss: 0.5485, Validation IoU: 0.0000\n",
      "Epoch 7/50, Loss: 0.5523, Train IoU: 0.0000\n",
      "Validation Loss: 0.5560, Validation IoU: 0.0000\n",
      "Epoch 8/50, Loss: 0.5534, Train IoU: 0.0000\n",
      "Validation Loss: 0.5530, Validation IoU: 0.0000\n",
      "Epoch 9/50, Loss: 0.5520, Train IoU: 0.0000\n",
      "Validation Loss: 0.5468, Validation IoU: 0.0000\n",
      "Epoch 10/50, Loss: 0.5475, Train IoU: 0.0000\n",
      "Validation Loss: 0.5483, Validation IoU: 0.0000\n",
      "Epoch 11/50, Loss: 0.5507, Train IoU: 0.0000\n",
      "Validation Loss: 0.5561, Validation IoU: 0.0000\n",
      "Epoch 12/50, Loss: 0.5502, Train IoU: 0.0000\n",
      "Validation Loss: 0.5517, Validation IoU: 0.0000\n",
      "Epoch 13/50, Loss: 0.5476, Train IoU: 0.0000\n",
      "Validation Loss: 0.5509, Validation IoU: 0.0000\n",
      "Epoch 14/50, Loss: 0.5486, Train IoU: 0.0000\n",
      "Validation Loss: 0.5464, Validation IoU: 0.0000\n",
      "Epoch 15/50, Loss: 0.5501, Train IoU: 0.0000\n",
      "Validation Loss: 0.5501, Validation IoU: 0.0000\n",
      "Epoch 16/50, Loss: 0.5488, Train IoU: 0.0000\n",
      "Validation Loss: 0.5481, Validation IoU: 0.0000\n",
      "Epoch 17/50, Loss: 0.5512, Train IoU: 0.0000\n",
      "Validation Loss: 0.5444, Validation IoU: 0.0000\n",
      "Epoch 18/50, Loss: 0.5469, Train IoU: 0.0000\n",
      "Validation Loss: 0.5441, Validation IoU: 0.0000\n",
      "Epoch 19/50, Loss: 0.5496, Train IoU: 0.0000\n",
      "Validation Loss: 0.5500, Validation IoU: 0.0000\n",
      "Epoch 20/50, Loss: 0.5495, Train IoU: 0.0000\n",
      "Validation Loss: 0.5461, Validation IoU: 0.0000\n",
      "Epoch 21/50, Loss: 0.5496, Train IoU: 0.0000\n",
      "Validation Loss: 0.5488, Validation IoU: 0.0000\n",
      "Epoch 22/50, Loss: 0.5471, Train IoU: 0.0000\n",
      "Validation Loss: 0.5520, Validation IoU: 0.0000\n",
      "Epoch 23/50, Loss: 0.5485, Train IoU: 0.0000\n",
      "Validation Loss: 0.5439, Validation IoU: 0.0000\n",
      "Epoch 24/50, Loss: 0.5471, Train IoU: 0.0000\n",
      "Validation Loss: 0.5467, Validation IoU: 0.0000\n",
      "Epoch 25/50, Loss: 0.5492, Train IoU: 0.0000\n",
      "Validation Loss: 0.5486, Validation IoU: 0.0000\n",
      "Epoch 26/50, Loss: 0.5500, Train IoU: 0.0000\n",
      "Validation Loss: 0.5499, Validation IoU: 0.0000\n",
      "Epoch 27/50, Loss: 0.5499, Train IoU: 0.0000\n",
      "Validation Loss: 0.5502, Validation IoU: 0.0000\n",
      "Epoch 28/50, Loss: 0.5474, Train IoU: 0.0000\n",
      "Validation Loss: 0.5469, Validation IoU: 0.0000\n",
      "Epoch 29/50, Loss: 0.5485, Train IoU: 0.0000\n",
      "Validation Loss: 0.5471, Validation IoU: 0.0000\n",
      "Epoch 30/50, Loss: 0.5488, Train IoU: 0.0000\n",
      "Validation Loss: 0.5509, Validation IoU: 0.0000\n",
      "Epoch 31/50, Loss: 0.5475, Train IoU: 0.0000\n",
      "Validation Loss: 0.5483, Validation IoU: 0.0000\n",
      "Epoch 32/50, Loss: 0.5474, Train IoU: 0.0000\n",
      "Validation Loss: 0.5484, Validation IoU: 0.0000\n",
      "Epoch 33/50, Loss: 0.5460, Train IoU: 0.0000\n",
      "Validation Loss: 0.5495, Validation IoU: 0.0000\n",
      "Epoch 34/50, Loss: 0.5483, Train IoU: 0.0000\n",
      "Validation Loss: 0.5430, Validation IoU: 0.0000\n",
      "Epoch 35/50, Loss: 0.5489, Train IoU: 0.0000\n",
      "Validation Loss: 0.5509, Validation IoU: 0.0000\n",
      "Epoch 36/50, Loss: 0.5490, Train IoU: 0.0000\n",
      "Validation Loss: 0.5527, Validation IoU: 0.0000\n",
      "Epoch 37/50, Loss: 0.5473, Train IoU: 0.0000\n",
      "Validation Loss: 0.5521, Validation IoU: 0.0000\n",
      "Epoch 38/50, Loss: 0.5466, Train IoU: 0.0000\n",
      "Validation Loss: 0.5510, Validation IoU: 0.0000\n",
      "Epoch 39/50, Loss: 0.5501, Train IoU: 0.0000\n",
      "Validation Loss: 0.5478, Validation IoU: 0.0000\n",
      "Epoch 40/50, Loss: 0.5495, Train IoU: 0.0000\n",
      "Validation Loss: 0.5507, Validation IoU: 0.0000\n",
      "Epoch 41/50, Loss: 0.5485, Train IoU: 0.0000\n",
      "Validation Loss: 0.5472, Validation IoU: 0.0000\n",
      "Epoch 42/50, Loss: 0.5491, Train IoU: 0.0000\n",
      "Validation Loss: 0.5502, Validation IoU: 0.0000\n",
      "Epoch 43/50, Loss: 0.5503, Train IoU: 0.0000\n",
      "Validation Loss: 0.5475, Validation IoU: 0.0000\n",
      "Epoch 44/50, Loss: 0.5485, Train IoU: 0.0000\n",
      "Validation Loss: 0.5555, Validation IoU: 0.0000\n",
      "Epoch 45/50, Loss: 0.5493, Train IoU: 0.0000\n",
      "Validation Loss: 0.5482, Validation IoU: 0.0000\n",
      "Epoch 46/50, Loss: 0.5471, Train IoU: 0.0000\n",
      "Validation Loss: 0.5458, Validation IoU: 0.0000\n",
      "Epoch 47/50, Loss: 0.5488, Train IoU: 0.0000\n",
      "Validation Loss: 0.5508, Validation IoU: 0.0000\n",
      "Epoch 48/50, Loss: 0.5462, Train IoU: 0.0000\n",
      "Validation Loss: 0.5463, Validation IoU: 0.0000\n",
      "Epoch 49/50, Loss: 0.5481, Train IoU: 0.0000\n",
      "Validation Loss: 0.5502, Validation IoU: 0.0000\n",
      "Epoch 50/50, Loss: 0.5456, Train IoU: 0.0000\n",
      "Validation Loss: 0.5481, Validation IoU: 0.0000\n",
      "Training for channel 3 of layer conv1\n",
      "Epoch 1/50, Loss: 0.6761, Train IoU: 0.0989\n",
      "Validation Loss: 0.5698, Validation IoU: 0.0000\n",
      "Epoch 2/50, Loss: 0.5508, Train IoU: 0.0000\n",
      "Validation Loss: 0.5228, Validation IoU: 0.0003\n",
      "Epoch 3/50, Loss: 0.5160, Train IoU: 0.0021\n",
      "Validation Loss: 0.4913, Validation IoU: 0.0267\n",
      "Epoch 4/50, Loss: 0.4827, Train IoU: 0.0930\n",
      "Validation Loss: 0.4699, Validation IoU: 0.2404\n",
      "Epoch 5/50, Loss: 0.4870, Train IoU: 0.2000\n",
      "Validation Loss: 0.4497, Validation IoU: 0.2212\n",
      "Epoch 6/50, Loss: 0.4793, Train IoU: 0.1719\n",
      "Validation Loss: 0.4577, Validation IoU: 0.1296\n",
      "Epoch 7/50, Loss: 0.4886, Train IoU: 0.1254\n",
      "Validation Loss: 0.4601, Validation IoU: 0.1486\n",
      "Epoch 8/50, Loss: 0.4810, Train IoU: 0.1410\n",
      "Validation Loss: 0.4531, Validation IoU: 0.2123\n",
      "Epoch 9/50, Loss: 0.4846, Train IoU: 0.1956\n",
      "Validation Loss: 0.4523, Validation IoU: 0.2528\n",
      "Epoch 10/50, Loss: 0.4746, Train IoU: 0.2072\n",
      "Validation Loss: 0.4510, Validation IoU: 0.1842\n",
      "Epoch 11/50, Loss: 0.4771, Train IoU: 0.1383\n",
      "Validation Loss: 0.4726, Validation IoU: 0.0661\n",
      "Epoch 12/50, Loss: 0.4764, Train IoU: 0.0887\n",
      "Validation Loss: 0.4616, Validation IoU: 0.1112\n",
      "Epoch 13/50, Loss: 0.4689, Train IoU: 0.1261\n",
      "Validation Loss: 0.4617, Validation IoU: 0.1816\n",
      "Epoch 14/50, Loss: 0.4732, Train IoU: 0.1740\n",
      "Validation Loss: 0.4548, Validation IoU: 0.1974\n",
      "Epoch 15/50, Loss: 0.4706, Train IoU: 0.1654\n",
      "Validation Loss: 0.4588, Validation IoU: 0.1297\n",
      "Epoch 16/50, Loss: 0.4692, Train IoU: 0.1228\n",
      "Validation Loss: 0.4569, Validation IoU: 0.0997\n",
      "Epoch 17/50, Loss: 0.4717, Train IoU: 0.1117\n",
      "Validation Loss: 0.4502, Validation IoU: 0.1422\n",
      "Epoch 18/50, Loss: 0.4639, Train IoU: 0.1536\n",
      "Validation Loss: 0.4436, Validation IoU: 0.2093\n",
      "Epoch 19/50, Loss: 0.4668, Train IoU: 0.1846\n",
      "Validation Loss: 0.4500, Validation IoU: 0.2144\n",
      "Epoch 20/50, Loss: 0.4652, Train IoU: 0.1859\n",
      "Validation Loss: 0.4435, Validation IoU: 0.2032\n",
      "Epoch 21/50, Loss: 0.4647, Train IoU: 0.1885\n",
      "Validation Loss: 0.4429, Validation IoU: 0.1994\n",
      "Epoch 22/50, Loss: 0.4610, Train IoU: 0.1700\n",
      "Validation Loss: 0.4532, Validation IoU: 0.1616\n",
      "Epoch 23/50, Loss: 0.4632, Train IoU: 0.1539\n",
      "Validation Loss: 0.4404, Validation IoU: 0.2007\n",
      "Epoch 24/50, Loss: 0.4612, Train IoU: 0.1910\n",
      "Validation Loss: 0.4425, Validation IoU: 0.2491\n",
      "Epoch 25/50, Loss: 0.4624, Train IoU: 0.2071\n",
      "Validation Loss: 0.4469, Validation IoU: 0.1746\n",
      "Epoch 26/50, Loss: 0.4671, Train IoU: 0.1432\n",
      "Validation Loss: 0.4518, Validation IoU: 0.1269\n",
      "Epoch 27/50, Loss: 0.4655, Train IoU: 0.1586\n",
      "Validation Loss: 0.4481, Validation IoU: 0.2298\n",
      "Epoch 28/50, Loss: 0.4578, Train IoU: 0.2035\n",
      "Validation Loss: 0.4411, Validation IoU: 0.2110\n",
      "Epoch 29/50, Loss: 0.4581, Train IoU: 0.1876\n",
      "Validation Loss: 0.4393, Validation IoU: 0.1937\n",
      "Epoch 30/50, Loss: 0.4572, Train IoU: 0.1789\n",
      "Validation Loss: 0.4441, Validation IoU: 0.1940\n",
      "Epoch 31/50, Loss: 0.4560, Train IoU: 0.1777\n",
      "Validation Loss: 0.4408, Validation IoU: 0.2002\n",
      "Epoch 32/50, Loss: 0.4539, Train IoU: 0.1874\n",
      "Validation Loss: 0.4385, Validation IoU: 0.1985\n",
      "Epoch 33/50, Loss: 0.4553, Train IoU: 0.1600\n",
      "Validation Loss: 0.4410, Validation IoU: 0.1881\n",
      "Epoch 34/50, Loss: 0.4583, Train IoU: 0.1981\n",
      "Validation Loss: 0.4309, Validation IoU: 0.2541\n",
      "Epoch 35/50, Loss: 0.4550, Train IoU: 0.2146\n",
      "Validation Loss: 0.4405, Validation IoU: 0.1913\n",
      "Epoch 36/50, Loss: 0.4558, Train IoU: 0.1665\n",
      "Validation Loss: 0.4441, Validation IoU: 0.1730\n",
      "Epoch 37/50, Loss: 0.4532, Train IoU: 0.2012\n",
      "Validation Loss: 0.4402, Validation IoU: 0.2662\n",
      "Epoch 38/50, Loss: 0.4501, Train IoU: 0.2368\n",
      "Validation Loss: 0.4361, Validation IoU: 0.2463\n",
      "Epoch 39/50, Loss: 0.4547, Train IoU: 0.1942\n",
      "Validation Loss: 0.4364, Validation IoU: 0.1807\n",
      "Epoch 40/50, Loss: 0.4544, Train IoU: 0.1762\n",
      "Validation Loss: 0.4383, Validation IoU: 0.2370\n",
      "Epoch 41/50, Loss: 0.4494, Train IoU: 0.2200\n",
      "Validation Loss: 0.4340, Validation IoU: 0.2759\n",
      "Epoch 42/50, Loss: 0.4527, Train IoU: 0.2530\n",
      "Validation Loss: 0.4342, Validation IoU: 0.2779\n",
      "Epoch 43/50, Loss: 0.4529, Train IoU: 0.2349\n",
      "Validation Loss: 0.4305, Validation IoU: 0.2011\n",
      "Epoch 44/50, Loss: 0.4552, Train IoU: 0.1729\n",
      "Validation Loss: 0.4421, Validation IoU: 0.2020\n",
      "Epoch 45/50, Loss: 0.4482, Train IoU: 0.2078\n",
      "Validation Loss: 0.4336, Validation IoU: 0.2999\n",
      "Epoch 46/50, Loss: 0.4500, Train IoU: 0.2563\n",
      "Validation Loss: 0.4274, Validation IoU: 0.2672\n",
      "Epoch 47/50, Loss: 0.4472, Train IoU: 0.2287\n",
      "Validation Loss: 0.4353, Validation IoU: 0.2132\n",
      "Epoch 48/50, Loss: 0.4449, Train IoU: 0.1886\n",
      "Validation Loss: 0.4257, Validation IoU: 0.2364\n",
      "Epoch 49/50, Loss: 0.4468, Train IoU: 0.2415\n",
      "Validation Loss: 0.4314, Validation IoU: 0.2932\n",
      "Epoch 50/50, Loss: 0.4412, Train IoU: 0.2383\n",
      "Validation Loss: 0.4316, Validation IoU: 0.2133\n",
      "Training for channel 4 of layer conv1\n",
      "Epoch 1/50, Loss: 0.6680, Train IoU: 0.0986\n",
      "Validation Loss: 0.5662, Validation IoU: 0.0000\n",
      "Epoch 2/50, Loss: 0.5525, Train IoU: 0.0000\n",
      "Validation Loss: 0.5532, Validation IoU: 0.0000\n",
      "Epoch 3/50, Loss: 0.5647, Train IoU: 0.0000\n",
      "Validation Loss: 0.5819, Validation IoU: 0.0000\n",
      "Epoch 4/50, Loss: 0.5710, Train IoU: 0.0000\n",
      "Validation Loss: 0.5628, Validation IoU: 0.0000\n",
      "Epoch 5/50, Loss: 0.5557, Train IoU: 0.0000\n",
      "Validation Loss: 0.5453, Validation IoU: 0.0000\n",
      "Epoch 6/50, Loss: 0.5489, Train IoU: 0.0000\n",
      "Validation Loss: 0.5485, Validation IoU: 0.0000\n",
      "Epoch 7/50, Loss: 0.5523, Train IoU: 0.0000\n",
      "Validation Loss: 0.5560, Validation IoU: 0.0000\n",
      "Epoch 8/50, Loss: 0.5534, Train IoU: 0.0000\n",
      "Validation Loss: 0.5530, Validation IoU: 0.0000\n",
      "Epoch 9/50, Loss: 0.5520, Train IoU: 0.0000\n",
      "Validation Loss: 0.5468, Validation IoU: 0.0000\n",
      "Epoch 10/50, Loss: 0.5476, Train IoU: 0.0000\n",
      "Validation Loss: 0.5483, Validation IoU: 0.0000\n",
      "Epoch 11/50, Loss: 0.5507, Train IoU: 0.0000\n",
      "Validation Loss: 0.5561, Validation IoU: 0.0000\n",
      "Epoch 12/50, Loss: 0.5502, Train IoU: 0.0000\n",
      "Validation Loss: 0.5517, Validation IoU: 0.0000\n",
      "Epoch 13/50, Loss: 0.5476, Train IoU: 0.0000\n",
      "Validation Loss: 0.5509, Validation IoU: 0.0000\n",
      "Epoch 14/50, Loss: 0.5486, Train IoU: 0.0000\n",
      "Validation Loss: 0.5464, Validation IoU: 0.0000\n",
      "Epoch 15/50, Loss: 0.5501, Train IoU: 0.0000\n",
      "Validation Loss: 0.5501, Validation IoU: 0.0000\n",
      "Epoch 16/50, Loss: 0.5488, Train IoU: 0.0000\n",
      "Validation Loss: 0.5481, Validation IoU: 0.0000\n",
      "Epoch 17/50, Loss: 0.5512, Train IoU: 0.0000\n",
      "Validation Loss: 0.5444, Validation IoU: 0.0000\n",
      "Epoch 18/50, Loss: 0.5469, Train IoU: 0.0000\n",
      "Validation Loss: 0.5441, Validation IoU: 0.0000\n",
      "Epoch 19/50, Loss: 0.5496, Train IoU: 0.0000\n",
      "Validation Loss: 0.5500, Validation IoU: 0.0000\n",
      "Epoch 20/50, Loss: 0.5495, Train IoU: 0.0000\n",
      "Validation Loss: 0.5461, Validation IoU: 0.0000\n",
      "Epoch 21/50, Loss: 0.5496, Train IoU: 0.0000\n",
      "Validation Loss: 0.5488, Validation IoU: 0.0000\n",
      "Epoch 22/50, Loss: 0.5471, Train IoU: 0.0000\n",
      "Validation Loss: 0.5520, Validation IoU: 0.0000\n",
      "Epoch 23/50, Loss: 0.5485, Train IoU: 0.0000\n",
      "Validation Loss: 0.5439, Validation IoU: 0.0000\n",
      "Epoch 24/50, Loss: 0.5471, Train IoU: 0.0000\n",
      "Validation Loss: 0.5467, Validation IoU: 0.0000\n",
      "Epoch 25/50, Loss: 0.5492, Train IoU: 0.0000\n",
      "Validation Loss: 0.5486, Validation IoU: 0.0000\n",
      "Epoch 26/50, Loss: 0.5500, Train IoU: 0.0000\n",
      "Validation Loss: 0.5499, Validation IoU: 0.0000\n",
      "Epoch 27/50, Loss: 0.5499, Train IoU: 0.0000\n",
      "Validation Loss: 0.5502, Validation IoU: 0.0000\n",
      "Epoch 28/50, Loss: 0.5474, Train IoU: 0.0000\n",
      "Validation Loss: 0.5469, Validation IoU: 0.0000\n",
      "Epoch 29/50, Loss: 0.5485, Train IoU: 0.0000\n",
      "Validation Loss: 0.5471, Validation IoU: 0.0000\n",
      "Epoch 30/50, Loss: 0.5488, Train IoU: 0.0000\n",
      "Validation Loss: 0.5509, Validation IoU: 0.0000\n",
      "Epoch 31/50, Loss: 0.5475, Train IoU: 0.0000\n",
      "Validation Loss: 0.5483, Validation IoU: 0.0000\n",
      "Epoch 32/50, Loss: 0.5474, Train IoU: 0.0000\n",
      "Validation Loss: 0.5485, Validation IoU: 0.0000\n",
      "Epoch 33/50, Loss: 0.5460, Train IoU: 0.0000\n",
      "Validation Loss: 0.5495, Validation IoU: 0.0000\n",
      "Epoch 34/50, Loss: 0.5483, Train IoU: 0.0000\n",
      "Validation Loss: 0.5430, Validation IoU: 0.0000\n",
      "Epoch 35/50, Loss: 0.5489, Train IoU: 0.0000\n",
      "Validation Loss: 0.5509, Validation IoU: 0.0000\n",
      "Epoch 36/50, Loss: 0.5490, Train IoU: 0.0000\n",
      "Validation Loss: 0.5527, Validation IoU: 0.0000\n",
      "Epoch 37/50, Loss: 0.5473, Train IoU: 0.0000\n",
      "Validation Loss: 0.5521, Validation IoU: 0.0000\n",
      "Epoch 38/50, Loss: 0.5466, Train IoU: 0.0000\n",
      "Validation Loss: 0.5510, Validation IoU: 0.0000\n",
      "Epoch 39/50, Loss: 0.5501, Train IoU: 0.0000\n",
      "Validation Loss: 0.5478, Validation IoU: 0.0000\n",
      "Epoch 40/50, Loss: 0.5495, Train IoU: 0.0000\n",
      "Validation Loss: 0.5507, Validation IoU: 0.0000\n",
      "Epoch 41/50, Loss: 0.5485, Train IoU: 0.0000\n",
      "Validation Loss: 0.5473, Validation IoU: 0.0000\n",
      "Epoch 42/50, Loss: 0.5491, Train IoU: 0.0000\n",
      "Validation Loss: 0.5502, Validation IoU: 0.0000\n",
      "Epoch 43/50, Loss: 0.5503, Train IoU: 0.0000\n",
      "Validation Loss: 0.5475, Validation IoU: 0.0000\n",
      "Epoch 44/50, Loss: 0.5485, Train IoU: 0.0000\n",
      "Validation Loss: 0.5555, Validation IoU: 0.0000\n",
      "Epoch 45/50, Loss: 0.5493, Train IoU: 0.0000\n",
      "Validation Loss: 0.5482, Validation IoU: 0.0000\n",
      "Epoch 46/50, Loss: 0.5471, Train IoU: 0.0000\n",
      "Validation Loss: 0.5458, Validation IoU: 0.0000\n",
      "Epoch 47/50, Loss: 0.5488, Train IoU: 0.0000\n",
      "Validation Loss: 0.5508, Validation IoU: 0.0000\n",
      "Epoch 48/50, Loss: 0.5462, Train IoU: 0.0000\n",
      "Validation Loss: 0.5463, Validation IoU: 0.0000\n",
      "Epoch 49/50, Loss: 0.5481, Train IoU: 0.0000\n",
      "Validation Loss: 0.5502, Validation IoU: 0.0000\n",
      "Epoch 50/50, Loss: 0.5456, Train IoU: 0.0000\n",
      "Validation Loss: 0.5481, Validation IoU: 0.0000\n",
      "Training for channel 5 of layer conv1\n",
      "Epoch 1/50, Loss: 0.6678, Train IoU: 0.0986\n",
      "Validation Loss: 0.5660, Validation IoU: 0.0000\n",
      "Epoch 2/50, Loss: 0.5524, Train IoU: 0.0000\n",
      "Validation Loss: 0.5533, Validation IoU: 0.0000\n",
      "Epoch 3/50, Loss: 0.5648, Train IoU: 0.0000\n",
      "Validation Loss: 0.5817, Validation IoU: 0.0000\n",
      "Epoch 4/50, Loss: 0.5707, Train IoU: 0.0000\n",
      "Validation Loss: 0.5622, Validation IoU: 0.0000\n",
      "Epoch 5/50, Loss: 0.5551, Train IoU: 0.0000\n",
      "Validation Loss: 0.5449, Validation IoU: 0.0000\n",
      "Epoch 6/50, Loss: 0.5486, Train IoU: 0.0000\n",
      "Validation Loss: 0.5483, Validation IoU: 0.0000\n",
      "Epoch 7/50, Loss: 0.5520, Train IoU: 0.0000\n",
      "Validation Loss: 0.5554, Validation IoU: 0.0000\n",
      "Epoch 8/50, Loss: 0.5527, Train IoU: 0.0000\n",
      "Validation Loss: 0.5522, Validation IoU: 0.0000\n",
      "Epoch 9/50, Loss: 0.5511, Train IoU: 0.0000\n",
      "Validation Loss: 0.5459, Validation IoU: 0.0000\n",
      "Epoch 10/50, Loss: 0.5467, Train IoU: 0.0000\n",
      "Validation Loss: 0.5475, Validation IoU: 0.0000\n",
      "Epoch 11/50, Loss: 0.5499, Train IoU: 0.0000\n",
      "Validation Loss: 0.5551, Validation IoU: 0.0000\n",
      "Epoch 12/50, Loss: 0.5491, Train IoU: 0.0000\n",
      "Validation Loss: 0.5505, Validation IoU: 0.0000\n",
      "Epoch 13/50, Loss: 0.5464, Train IoU: 0.0000\n",
      "Validation Loss: 0.5497, Validation IoU: 0.0000\n",
      "Epoch 14/50, Loss: 0.5473, Train IoU: 0.0000\n",
      "Validation Loss: 0.5450, Validation IoU: 0.0000\n",
      "Epoch 15/50, Loss: 0.5487, Train IoU: 0.0000\n",
      "Validation Loss: 0.5487, Validation IoU: 0.0000\n",
      "Epoch 16/50, Loss: 0.5472, Train IoU: 0.0000\n",
      "Validation Loss: 0.5464, Validation IoU: 0.0000\n",
      "Epoch 17/50, Loss: 0.5495, Train IoU: 0.0000\n",
      "Validation Loss: 0.5426, Validation IoU: 0.0000\n",
      "Epoch 18/50, Loss: 0.5450, Train IoU: 0.0000\n",
      "Validation Loss: 0.5423, Validation IoU: 0.0000\n",
      "Epoch 19/50, Loss: 0.5477, Train IoU: 0.0000\n",
      "Validation Loss: 0.5479, Validation IoU: 0.0000\n",
      "Epoch 20/50, Loss: 0.5473, Train IoU: 0.0000\n",
      "Validation Loss: 0.5439, Validation IoU: 0.0000\n",
      "Epoch 21/50, Loss: 0.5472, Train IoU: 0.0000\n",
      "Validation Loss: 0.5464, Validation IoU: 0.0000\n",
      "Epoch 22/50, Loss: 0.5446, Train IoU: 0.0000\n",
      "Validation Loss: 0.5495, Validation IoU: 0.0000\n",
      "Epoch 23/50, Loss: 0.5458, Train IoU: 0.0000\n",
      "Validation Loss: 0.5410, Validation IoU: 0.0000\n",
      "Epoch 24/50, Loss: 0.5442, Train IoU: 0.0000\n",
      "Validation Loss: 0.5438, Validation IoU: 0.0000\n",
      "Epoch 25/50, Loss: 0.5461, Train IoU: 0.0000\n",
      "Validation Loss: 0.5456, Validation IoU: 0.0000\n",
      "Epoch 26/50, Loss: 0.5468, Train IoU: 0.0000\n",
      "Validation Loss: 0.5468, Validation IoU: 0.0000\n",
      "Epoch 27/50, Loss: 0.5463, Train IoU: 0.0000\n",
      "Validation Loss: 0.5466, Validation IoU: 0.0000\n",
      "Epoch 28/50, Loss: 0.5437, Train IoU: 0.0000\n",
      "Validation Loss: 0.5434, Validation IoU: 0.0000\n",
      "Epoch 29/50, Loss: 0.5447, Train IoU: 0.0000\n",
      "Validation Loss: 0.5434, Validation IoU: 0.0000\n",
      "Epoch 30/50, Loss: 0.5447, Train IoU: 0.0000\n",
      "Validation Loss: 0.5469, Validation IoU: 0.0000\n",
      "Epoch 31/50, Loss: 0.5430, Train IoU: 0.0000\n",
      "Validation Loss: 0.5439, Validation IoU: 0.0000\n",
      "Epoch 32/50, Loss: 0.5426, Train IoU: 0.0000\n",
      "Validation Loss: 0.5435, Validation IoU: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Call the training function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m all_layers_iou_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_conv_probe_all_layers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Save the results to a JSON file\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# TODO: add the probe na saida de uma UNET segmentacao para ver se o resultado  bom(deveria ser), ver questao de tempo de convergencia\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# TODO: verificar porque esta indo a zero a IOU, ver resultado da rede para ver se nao esta todo branco ou preto\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[34], line 11\u001b[0m, in \u001b[0;36mtrain_conv_probe_all_layers\u001b[0;34m(train_loader, test_loader, image_size, device, num_epochs, lr)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Declare the model to use\u001b[39;00m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mresnet18(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 11\u001b[0m iou_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_conv_probe_all_channels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m save_results_to_json(iou_results, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./conv-probe-layers-results/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_activation_results.json\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#TODO salvar por canal/camada\u001b[39;00m\n\u001b[1;32m     24\u001b[0m all_layers_iou_results[layer_name] \u001b[38;5;241m=\u001b[39m iou_results\n",
      "Cell \u001b[0;32mIn[31], line 34\u001b[0m, in \u001b[0;36mtrain_conv_probe_all_channels\u001b[0;34m(model, layer_name, num_channels, train_loader, test_loader, image_size, device, num_epochs, lr)\u001b[0m\n\u001b[1;32m     31\u001b[0m train_iou \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ensure masks are float type\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/Desktop/masters-degree/data/vess-map/vess_map_dataset.py:104\u001b[0m, in \u001b[0;36mVessMapDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Apply transformations\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_transform_flag:\n\u001b[0;32m--> 104\u001b[0m     image, mask, skeleton \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskeleton\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# Convert to tensor without applying random transforms\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     image \u001b[38;5;241m=\u001b[39m TF\u001b[38;5;241m.\u001b[39mto_tensor(image)\n",
      "File \u001b[0;32m~/Desktop/masters-degree/data/vess-map/vess_map_dataset.py:78\u001b[0m, in \u001b[0;36mVessMapDataset.apply_transform\u001b[0;34m(self, image, mask, skeleton)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Random rotation\u001b[39;00m\n\u001b[1;32m     77\u001b[0m angle \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mTF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m mask \u001b[38;5;241m=\u001b[39m TF\u001b[38;5;241m.\u001b[39mrotate(mask, angle)\n\u001b[1;32m     80\u001b[0m skeleton \u001b[38;5;241m=\u001b[39m TF\u001b[38;5;241m.\u001b[39mrotate(skeleton, angle)\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torchvision/transforms/functional.py:1121\u001b[0m, in \u001b[0;36mrotate\u001b[0;34m(img, angle, interpolation, expand, center, fill)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m   1120\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m center_f \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m]\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m center \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torchvision/transforms/_functional_pil.py:314\u001b[0m, in \u001b[0;36mrotate\u001b[0;34m(img, angle, interpolation, expand, center, fill)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be PIL Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(img)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    313\u001b[0m opts \u001b[38;5;241m=\u001b[39m _parse_fill(fill, img)\n\u001b[0;32m--> 314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/PIL/Image.py:2477\u001b[0m, in \u001b[0;36mImage.rotate\u001b[0;34m(self, angle, resample, expand, center, translate, fillcolor)\u001b[0m\n\u001b[1;32m   2474\u001b[0m     matrix[\u001b[38;5;241m2\u001b[39m], matrix[\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m=\u001b[39m transform(\u001b[38;5;241m-\u001b[39m(nw \u001b[38;5;241m-\u001b[39m w) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m-\u001b[39m(nh \u001b[38;5;241m-\u001b[39m h) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m, matrix)\n\u001b[1;32m   2475\u001b[0m     w, h \u001b[38;5;241m=\u001b[39m nw, nh\n\u001b[0;32m-> 2477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2478\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAFFINE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfillcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfillcolor\u001b[49m\n\u001b[1;32m   2479\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/PIL/Image.py:2852\u001b[0m, in \u001b[0;36mImage.transform\u001b[0;34m(self, size, method, data, resample, fill, fillcolor)\u001b[0m\n\u001b[1;32m   2849\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing method data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2850\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m-> 2852\u001b[0m im \u001b[38;5;241m=\u001b[39m \u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfillcolor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpalette:\n\u001b[1;32m   2854\u001b[0m     im\u001b[38;5;241m.\u001b[39mpalette \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/PIL/Image.py:3102\u001b[0m, in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   3100\u001b[0m         im\u001b[38;5;241m.\u001b[39mpalette \u001b[38;5;241m=\u001b[39m ImagePalette\u001b[38;5;241m.\u001b[39mImagePalette()\n\u001b[1;32m   3101\u001b[0m         color \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mgetcolor(color_ints)\n\u001b[0;32m-> 3102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im\u001b[38;5;241m.\u001b[39m_new(\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Call the training function\n",
    "all_layers_iou_results = train_conv_probe_all_layers(\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    image_size=image_size,\n",
    "    device=device,\n",
    "    num_epochs=50,\n",
    "    lr=0.01\n",
    ")\n",
    "\n",
    "# Save the results to a JSON file\n",
    "# TODO: add the probe na saida de uma UNET segmentacao para ver se o resultado  bom(deveria ser), ver questao de tempo de convergencia\n",
    "# TODO: verificar porque esta indo a zero a IOU, ver resultado da rede para ver se nao esta todo branco ou preto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fonta42/miniconda3/envs/mestrado/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "def train_unet_model(train_loader, val_loader, device, num_epochs=50, lr=0.001):\n",
    "    # Define the model\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet18\",        # Choose encoder, e.g. resnet18\n",
    "        encoder_weights=None,           # Use NONE pre-trained weights for encoderFalse\n",
    "        in_channels=3,                  # Input channels (3 for RGB images)\n",
    "        classes=1,                      # Output channels (1 for binary segmentation)\n",
    "        activation=None                 # No activation function on output\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    # Define loss function\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, masks, _ in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            masks = masks.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze(1)\n",
    "            masks = masks.squeeze(1)\n",
    "\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        # You can add validation and metric calculation similar to previous code\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), './models/conv_probe_unet_vess_map.pth')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.8090\n",
      "Epoch 2/50, Loss: 0.6150\n",
      "Epoch 3/50, Loss: 0.5303\n",
      "Epoch 4/50, Loss: 0.4718\n",
      "Epoch 5/50, Loss: 0.4314\n",
      "Epoch 6/50, Loss: 0.3875\n",
      "Epoch 7/50, Loss: 0.3466\n",
      "Epoch 8/50, Loss: 0.3224\n",
      "Epoch 9/50, Loss: 0.3065\n",
      "Epoch 10/50, Loss: 0.2992\n",
      "Epoch 11/50, Loss: 0.2844\n",
      "Epoch 12/50, Loss: 0.2557\n",
      "Epoch 13/50, Loss: 0.2484\n",
      "Epoch 14/50, Loss: 0.2404\n",
      "Epoch 15/50, Loss: 0.2244\n",
      "Epoch 16/50, Loss: 0.2144\n",
      "Epoch 17/50, Loss: 0.2085\n",
      "Epoch 18/50, Loss: 0.2041\n",
      "Epoch 19/50, Loss: 0.2001\n",
      "Epoch 20/50, Loss: 0.1942\n",
      "Epoch 21/50, Loss: 0.1914\n",
      "Epoch 22/50, Loss: 0.1932\n",
      "Epoch 23/50, Loss: 0.1844\n",
      "Epoch 24/50, Loss: 0.1824\n",
      "Epoch 25/50, Loss: 0.1788\n",
      "Epoch 26/50, Loss: 0.1764\n",
      "Epoch 27/50, Loss: 0.1706\n",
      "Epoch 28/50, Loss: 0.1711\n",
      "Epoch 29/50, Loss: 0.1666\n",
      "Epoch 30/50, Loss: 0.1660\n",
      "Epoch 31/50, Loss: 0.1674\n",
      "Epoch 32/50, Loss: 0.1646\n",
      "Epoch 33/50, Loss: 0.1619\n",
      "Epoch 34/50, Loss: 0.1638\n",
      "Epoch 35/50, Loss: 0.1710\n",
      "Epoch 36/50, Loss: 0.1641\n",
      "Epoch 37/50, Loss: 0.1648\n",
      "Epoch 38/50, Loss: 0.1582\n",
      "Epoch 39/50, Loss: 0.1589\n",
      "Epoch 40/50, Loss: 0.1623\n",
      "Epoch 41/50, Loss: 0.1583\n",
      "Epoch 42/50, Loss: 0.1580\n",
      "Epoch 43/50, Loss: 0.1573\n",
      "Epoch 44/50, Loss: 0.1561\n",
      "Epoch 45/50, Loss: 0.1492\n",
      "Epoch 46/50, Loss: 0.1501\n",
      "Epoch 47/50, Loss: 0.1517\n",
      "Epoch 48/50, Loss: 0.1584\n",
      "Epoch 49/50, Loss: 0.1552\n",
      "Epoch 50/50, Loss: 0.1584\n"
     ]
    }
   ],
   "source": [
    "unet_model = train_unet_model(train_loader=train_loader, val_loader=test_loader, device=device, num_epochs=50, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "encoder\n",
      "encoder.conv1\n",
      "encoder.bn1\n",
      "encoder.relu\n",
      "encoder.maxpool\n",
      "encoder.layer1\n",
      "encoder.layer1.0\n",
      "encoder.layer1.0.conv1\n",
      "encoder.layer1.0.bn1\n",
      "encoder.layer1.0.relu\n",
      "encoder.layer1.0.conv2\n",
      "encoder.layer1.0.bn2\n",
      "encoder.layer1.1\n",
      "encoder.layer1.1.conv1\n",
      "encoder.layer1.1.bn1\n",
      "encoder.layer1.1.relu\n",
      "encoder.layer1.1.conv2\n",
      "encoder.layer1.1.bn2\n",
      "encoder.layer2\n",
      "encoder.layer2.0\n",
      "encoder.layer2.0.conv1\n",
      "encoder.layer2.0.bn1\n",
      "encoder.layer2.0.relu\n",
      "encoder.layer2.0.conv2\n",
      "encoder.layer2.0.bn2\n",
      "encoder.layer2.0.downsample\n",
      "encoder.layer2.0.downsample.0\n",
      "encoder.layer2.0.downsample.1\n",
      "encoder.layer2.1\n",
      "encoder.layer2.1.conv1\n",
      "encoder.layer2.1.bn1\n",
      "encoder.layer2.1.relu\n",
      "encoder.layer2.1.conv2\n",
      "encoder.layer2.1.bn2\n",
      "encoder.layer3\n",
      "encoder.layer3.0\n",
      "encoder.layer3.0.conv1\n",
      "encoder.layer3.0.bn1\n",
      "encoder.layer3.0.relu\n",
      "encoder.layer3.0.conv2\n",
      "encoder.layer3.0.bn2\n",
      "encoder.layer3.0.downsample\n",
      "encoder.layer3.0.downsample.0\n",
      "encoder.layer3.0.downsample.1\n",
      "encoder.layer3.1\n",
      "encoder.layer3.1.conv1\n",
      "encoder.layer3.1.bn1\n",
      "encoder.layer3.1.relu\n",
      "encoder.layer3.1.conv2\n",
      "encoder.layer3.1.bn2\n",
      "encoder.layer4\n",
      "encoder.layer4.0\n",
      "encoder.layer4.0.conv1\n",
      "encoder.layer4.0.bn1\n",
      "encoder.layer4.0.relu\n",
      "encoder.layer4.0.conv2\n",
      "encoder.layer4.0.bn2\n",
      "encoder.layer4.0.downsample\n",
      "encoder.layer4.0.downsample.0\n",
      "encoder.layer4.0.downsample.1\n",
      "encoder.layer4.1\n",
      "encoder.layer4.1.conv1\n",
      "encoder.layer4.1.bn1\n",
      "encoder.layer4.1.relu\n",
      "encoder.layer4.1.conv2\n",
      "encoder.layer4.1.bn2\n",
      "decoder\n",
      "decoder.center\n",
      "decoder.blocks\n",
      "decoder.blocks.0\n",
      "decoder.blocks.0.conv1\n",
      "decoder.blocks.0.conv1.0\n",
      "decoder.blocks.0.conv1.1\n",
      "decoder.blocks.0.conv1.2\n",
      "decoder.blocks.0.attention1\n",
      "decoder.blocks.0.attention1.attention\n",
      "decoder.blocks.0.conv2\n",
      "decoder.blocks.0.conv2.0\n",
      "decoder.blocks.0.conv2.1\n",
      "decoder.blocks.0.conv2.2\n",
      "decoder.blocks.0.attention2\n",
      "decoder.blocks.0.attention2.attention\n",
      "decoder.blocks.1\n",
      "decoder.blocks.1.conv1\n",
      "decoder.blocks.1.conv1.0\n",
      "decoder.blocks.1.conv1.1\n",
      "decoder.blocks.1.conv1.2\n",
      "decoder.blocks.1.attention1\n",
      "decoder.blocks.1.attention1.attention\n",
      "decoder.blocks.1.conv2\n",
      "decoder.blocks.1.conv2.0\n",
      "decoder.blocks.1.conv2.1\n",
      "decoder.blocks.1.conv2.2\n",
      "decoder.blocks.1.attention2\n",
      "decoder.blocks.1.attention2.attention\n",
      "decoder.blocks.2\n",
      "decoder.blocks.2.conv1\n",
      "decoder.blocks.2.conv1.0\n",
      "decoder.blocks.2.conv1.1\n",
      "decoder.blocks.2.conv1.2\n",
      "decoder.blocks.2.attention1\n",
      "decoder.blocks.2.attention1.attention\n",
      "decoder.blocks.2.conv2\n",
      "decoder.blocks.2.conv2.0\n",
      "decoder.blocks.2.conv2.1\n",
      "decoder.blocks.2.conv2.2\n",
      "decoder.blocks.2.attention2\n",
      "decoder.blocks.2.attention2.attention\n",
      "decoder.blocks.3\n",
      "decoder.blocks.3.conv1\n",
      "decoder.blocks.3.conv1.0\n",
      "decoder.blocks.3.conv1.1\n",
      "decoder.blocks.3.conv1.2\n",
      "decoder.blocks.3.attention1\n",
      "decoder.blocks.3.attention1.attention\n",
      "decoder.blocks.3.conv2\n",
      "decoder.blocks.3.conv2.0\n",
      "decoder.blocks.3.conv2.1\n",
      "decoder.blocks.3.conv2.2\n",
      "decoder.blocks.3.attention2\n",
      "decoder.blocks.3.attention2.attention\n",
      "decoder.blocks.4\n",
      "decoder.blocks.4.conv1\n",
      "decoder.blocks.4.conv1.0\n",
      "decoder.blocks.4.conv1.1\n",
      "decoder.blocks.4.conv1.2\n",
      "decoder.blocks.4.attention1\n",
      "decoder.blocks.4.attention1.attention\n",
      "decoder.blocks.4.conv2\n",
      "decoder.blocks.4.conv2.0\n",
      "decoder.blocks.4.conv2.1\n",
      "decoder.blocks.4.conv2.2\n",
      "decoder.blocks.4.attention2\n",
      "decoder.blocks.4.attention2.attention\n",
      "segmentation_head\n",
      "segmentation_head.0\n",
      "segmentation_head.1\n",
      "segmentation_head.2\n",
      "segmentation_head.2.activation\n"
     ]
    }
   ],
   "source": [
    "for name, module in unet_model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found layer: decoder.blocks.4.conv2.0\n",
      "Number of channels: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_out_channels(module):\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        return module.out_channels\n",
    "    # If module is a fused type like Conv2dReLU, check its children\n",
    "    for submodule in module.children():\n",
    "        if isinstance(submodule, nn.Conv2d):\n",
    "            return submodule.out_channels\n",
    "    raise AttributeError(\"No Conv2d found in this module\")\n",
    "\n",
    "layer_name = 'decoder.blocks.4.conv2.0' #TODO: check if this is the best layer indeed\n",
    "\n",
    "for name, module in unet_model.named_modules():\n",
    "    if name == layer_name:\n",
    "        print(f\"Found layer: {name}\")\n",
    "        try:\n",
    "            num_channels = get_out_channels(module)\n",
    "            print(f\"Number of channels: {num_channels}\")\n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "\n",
    "num_channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for channel 0 of layer decoder.blocks.4.conv2.0\n",
      "Epoch 1/10, Loss: 0.7170, Train IoU: 0.2141\n",
      "Validation Loss: 0.5918, Validation IoU: 0.4335\n",
      "Epoch 2/10, Loss: 0.5630, Train IoU: 0.5123\n",
      "Validation Loss: 0.5046, Validation IoU: 0.6133\n",
      "Epoch 3/10, Loss: 0.4746, Train IoU: 0.6433\n",
      "Validation Loss: 0.4469, Validation IoU: 0.6257\n",
      "Epoch 4/10, Loss: 0.4140, Train IoU: 0.6601\n",
      "Validation Loss: 0.4037, Validation IoU: 0.6364\n",
      "Epoch 5/10, Loss: 0.3688, Train IoU: 0.6696\n",
      "Validation Loss: 0.3594, Validation IoU: 0.6535\n",
      "Epoch 6/10, Loss: 0.3250, Train IoU: 0.6919\n",
      "Validation Loss: 0.3267, Validation IoU: 0.6649\n",
      "Epoch 7/10, Loss: 0.2911, Train IoU: 0.7027\n",
      "Validation Loss: 0.3055, Validation IoU: 0.6736\n",
      "Epoch 8/10, Loss: 0.2663, Train IoU: 0.7116\n",
      "Validation Loss: 0.2719, Validation IoU: 0.6880\n",
      "Epoch 9/10, Loss: 0.2411, Train IoU: 0.7223\n",
      "Validation Loss: 0.2534, Validation IoU: 0.6920\n",
      "Epoch 10/10, Loss: 0.2217, Train IoU: 0.7298\n",
      "Validation Loss: 0.2369, Validation IoU: 0.6952\n"
     ]
    }
   ],
   "source": [
    "# Initialize ConvProbe with the UNet model\n",
    "iou_results = train_conv_probe_all_channels(\n",
    "            model=unet_model,\n",
    "            layer_name=layer_name,\n",
    "            num_channels=num_channels,\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            image_size=image_size,\n",
    "            device=device,\n",
    "            num_epochs=10,\n",
    "            lr=0.001,\n",
    "            single_channel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mestrado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
