{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvProbe class\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Dataset\n",
    "import sys\n",
    "sys.path.append('/home/fonta42/Desktop/masters-degree/data/vess-map/')\n",
    "from vess_map_dataset import VessMapDataset\n",
    "\n",
    "# Training loop\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import jaccard_score  # For calculating IoU\n",
    "import numpy as np\n",
    "\n",
    "# Save the results\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvProbe(nn.Module):\n",
    "    def __init__(self, layer_name, output_size=(256, 256), seed=None, single_channel=True):\n",
    "        super(ConvProbe, self).__init__()\n",
    "\n",
    "        # Load pre-trained ResNet-18 model\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.layer_name = layer_name\n",
    "        self.output_size = output_size\n",
    "        self.single_channel = single_channel\n",
    "\n",
    "        # Freeze model weights to prevent training\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Get number of channels from the specified layer\n",
    "        in_channels = 1 if self.single_channel else self.get_layer_channels(layer_name)\n",
    "\n",
    "\n",
    "        # Initialize the convolutional probe (to be trained)\n",
    "        self.conv_probe = nn.Conv2d(\n",
    "            in_channels=in_channels,  # Use the layer's number of channels\n",
    "            out_channels=1,  # Single output channel for binary segmentation\n",
    "            kernel_size=3,\n",
    "            padding=1  # Add padding to preserve spatial dimensions\n",
    "        )\n",
    "\n",
    "        # Set a fixed random seed for consistency, if provided\n",
    "        if seed is not None:\n",
    "            self.set_seed(seed)\n",
    "\n",
    "        # Register a hook to capture activations from the specified layer\n",
    "        self.activations = {}\n",
    "        self.register_hook()\n",
    "\n",
    "    # Helper function to set random seed\n",
    "    def set_seed(self, seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Helper function to get the number of channels from the specified layer\n",
    "    def get_layer_channels(self, layer_name):\n",
    "        # Iterate over the named modules to find the specified layer\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == layer_name:\n",
    "                if hasattr(module, 'out_channels'):\n",
    "                    return module.out_channels\n",
    "                elif hasattr(module, 'num_features'):\n",
    "                    return module.num_features  # For BatchNorm layers\n",
    "                else:\n",
    "                    raise ValueError(f\"Layer {layer_name} does not have out_channels or num_features.\")\n",
    "        raise ValueError(f\"Layer {layer_name} not found.\")\n",
    "\n",
    "    # Register a forward hook to capture activations\n",
    "    def register_hook(self):\n",
    "        def hook_fn(module, input, output):\n",
    "            self.activations[self.layer_name] = output\n",
    "\n",
    "        # Register the hook on the specified layer\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == self.layer_name:\n",
    "                module.register_forward_hook(hook_fn)\n",
    "                break\n",
    "\n",
    "    # Forward pass through the model\n",
    "    def forward(self, x, channel_idx=None):\n",
    "        _ = self.model(x)  # Forward pass to get activations\n",
    "        activation = self.activations[self.layer_name]  # Retrieve the stored activation\n",
    "\n",
    "        # Select a specific channel if provided\n",
    "        if channel_idx is not None:\n",
    "            if channel_idx < 0 or channel_idx >= activation.size(1):\n",
    "                raise ValueError(f\"Channel index {channel_idx} is out of bounds for activation with {activation.size(1)} channels.\")\n",
    "            activation = activation[:, channel_idx:channel_idx+1, :, :]  # Select the specific channel\n",
    "\n",
    "        # Interpolate activation to match the desired output size\n",
    "        activation = F.interpolate(activation, size=self.output_size, mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Apply the convolutional probe to the activation\n",
    "        out = self.conv_probe(activation)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "image_dir = '/home/fonta42/Desktop/masters-degree/data/vess-map/images'\n",
    "mask_dir = '/home/fonta42/Desktop/masters-degree/data/vess-map/labels'\n",
    "skeleton_dir = '/home/fonta42/Desktop/masters-degree/data/vess-map/skeletons'\n",
    "\n",
    "image_size = 256\n",
    "\n",
    "# Initialize the dataset\n",
    "vess_dataset = VessMapDataset(image_dir, mask_dir, skeleton_dir, image_size, apply_transform=True)\n",
    "\n",
    "# Get the train and test loaders\n",
    "train_loader, test_loader = vess_dataset.vess_map_dataloader(batch_size=32, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(outputs, masks, threshold=0.5):\n",
    "    # Apply sigmoid to outputs to get probabilities between 0 and 1\n",
    "    preds = torch.sigmoid(outputs)\n",
    "    preds = (preds > threshold).float()  # Convert probabilities to binary predictions\n",
    "\n",
    "    # Ensure masks are float type\n",
    "    masks = masks.float()\n",
    "\n",
    "    # Compute intersection and union\n",
    "    intersection = (preds * masks).sum(dim=(1, 2))\n",
    "    union = ((preds + masks) > 0).float().sum(dim=(1, 2))\n",
    "\n",
    "    # Avoid division by zero\n",
    "    iou = torch.where(union == 0, torch.tensor(1.0).to(outputs.device), intersection / union)\n",
    "\n",
    "    # Return mean IoU over the batch\n",
    "    return iou.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training code\n",
    "def train_conv_probe_all_channels(layer_name, num_channels, train_loader, test_loader, image_size, device, num_epochs=50, lr=0.001):\n",
    "    iou_results = {}  # Dictionary to store IoU results for each channel\n",
    "\n",
    "    for channel_idx in range(num_channels):\n",
    "        print(f\"Training for channel {channel_idx} of layer {layer_name}\")\n",
    "\n",
    "        probe_model = ConvProbe(layer_name=layer_name, output_size=(image_size, image_size), seed=42)\n",
    "        probe_model.to(device)\n",
    "\n",
    "        # BinaryCEWithLogitsLoss for binary segmentation\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Define optimizer\n",
    "        optimizer = optim.Adam(probe_model.conv_probe.parameters(), lr=lr)\n",
    "\n",
    "        # Track the best IoU for this channel\n",
    "        best_iou = 0.0\n",
    "        best_iou_train = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            probe_model.train()\n",
    "            running_loss = 0.0\n",
    "            train_iou = 0.0\n",
    "\n",
    "            # Training loop\n",
    "            for inputs, masks, _ in train_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                masks = masks.to(device).float()  # Ensure masks are float type\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass using the current channel\n",
    "                outputs = probe_model(inputs, channel_idx=channel_idx)\n",
    "                outputs = outputs.squeeze(1)  # Shape: [batch_size, height, width]\n",
    "                masks = masks.squeeze(1)      # Shape: [batch_size, height, width]\n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, masks)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Accumulate running loss\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Compute IoU for this batch\n",
    "                batch_iou = calculate_iou(outputs, masks)\n",
    "                train_iou += batch_iou * inputs.size(0)\n",
    "\n",
    "            # Calculate epoch loss and IoU\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            epoch_iou = train_iou / len(train_loader.dataset)\n",
    "            if epoch == num_epochs - 1:\n",
    "                print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Train IoU: {epoch_iou:.4f}')\n",
    "\n",
    "            # Validation loop\n",
    "            probe_model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_iou = 0.0\n",
    "            with torch.no_grad():  # Disable gradient calculations during validation\n",
    "                for val_inputs, val_masks, _ in test_loader:\n",
    "                    val_inputs = val_inputs.to(device)\n",
    "                    val_masks = val_masks.to(device).float()  # Ensure masks are float type\n",
    "\n",
    "                    # Forward pass using the current channel\n",
    "                    val_outputs = probe_model(val_inputs, channel_idx=channel_idx)\n",
    "                    val_outputs = val_outputs.squeeze(1)  # Shape: [batch_size, height, width]\n",
    "                    val_masks = val_masks.squeeze(1)      # Shape: [batch_size, height, width]\n",
    "\n",
    "                    # Compute loss\n",
    "                    loss = criterion(val_outputs, val_masks)\n",
    "                    val_loss += loss.item() * val_inputs.size(0)\n",
    "\n",
    "                    # Compute IoU for this batch\n",
    "                    batch_val_iou = calculate_iou(val_outputs, val_masks)\n",
    "                    val_iou += batch_val_iou * val_inputs.size(0)\n",
    "\n",
    "            # Calculate validation loss and IoU\n",
    "            val_loss /= len(test_loader.dataset)\n",
    "            val_iou /= len(test_loader.dataset)\n",
    "            \n",
    "            if epoch == num_epochs - 1:\n",
    "                print(f'Validation Loss: {val_loss:.4f}, Validation IoU: {val_iou:.4f}')\n",
    "\n",
    "\n",
    "        # Save IoU metrics for this channel\n",
    "        iou_results[channel_idx] = {'train_iou': best_iou_train, 'val_iou': best_iou}\n",
    "\n",
    "    return iou_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get layer names and number of channels from ResNet-18\n",
    "def get_resnet18_layers_info():\n",
    "    resnet18 = models.resnet18(pretrained=True)\n",
    "    layers_info = {}\n",
    "    for name, module in resnet18.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.BatchNorm2d)):\n",
    "            if hasattr(module, 'out_channels'):\n",
    "                out_channels = module.out_channels\n",
    "            elif hasattr(module, 'num_features'):\n",
    "                out_channels = module.num_features\n",
    "            else:\n",
    "                continue\n",
    "            layers_info[name] = out_channels\n",
    "    return layers_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the probe for all layers and collect results\n",
    "def train_conv_probe_all_layers(train_loader, test_loader, image_size, device, num_epochs=20, lr=0.001):\n",
    "    all_layers_iou_results = {}\n",
    "    layers_info = get_resnet18_layers_info()\n",
    "    for layer_name, num_channels in layers_info.items():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"\\nProcessing layer: {layer_name} with {num_channels} channels\")\n",
    "        iou_results = train_conv_probe_all_channels(\n",
    "            layer_name=layer_name,\n",
    "            num_channels=num_channels,\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            image_size=image_size,\n",
    "            device=device,\n",
    "            num_epochs=num_epochs,\n",
    "            lr=lr\n",
    "        )\n",
    "        all_layers_iou_results[layer_name] = iou_results\n",
    "    return all_layers_iou_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save results to a JSON file\n",
    "def save_results_to_json(results, filename):\n",
    "    # Convert tensors or numpy types to native Python types\n",
    "    def convert(o):\n",
    "        if isinstance(o, np.float32) or isinstance(o, np.float64):\n",
    "            return float(o)\n",
    "        if isinstance(o, torch.Tensor):\n",
    "            return o.item()\n",
    "        raise TypeError\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(results, f, default=convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fonta42/miniconda3/envs/mestrado/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/fonta42/miniconda3/envs/mestrado/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing layer: conv1 with 64 channels\n",
      "Training for channel 0 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6584, Train IoU: 0.0046\n",
      "Validation Loss: 0.6627, Validation IoU: 0.0095\n",
      "Training for channel 1 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6347, Train IoU: 0.0259\n",
      "Validation Loss: 0.6410, Validation IoU: 0.0406\n",
      "Training for channel 2 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 3 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6319, Train IoU: 0.0000\n",
      "Validation Loss: 0.6445, Validation IoU: 0.0000\n",
      "Training for channel 4 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 5 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6396, Train IoU: 0.0000\n",
      "Validation Loss: 0.6460, Validation IoU: 0.0000\n",
      "Training for channel 6 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6393, Train IoU: 0.0000\n",
      "Validation Loss: 0.6458, Validation IoU: 0.0000\n",
      "Training for channel 7 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 8 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6392, Train IoU: 0.0015\n",
      "Validation Loss: 0.6462, Validation IoU: 0.0045\n",
      "Training for channel 9 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 10 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6404, Train IoU: 0.0031\n",
      "Validation Loss: 0.6483, Validation IoU: 0.0056\n",
      "Training for channel 11 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6374, Train IoU: 0.0116\n",
      "Validation Loss: 0.6435, Validation IoU: 0.0217\n",
      "Training for channel 12 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6335, Train IoU: 0.0000\n",
      "Validation Loss: 0.6454, Validation IoU: 0.0000\n",
      "Training for channel 13 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 14 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6281, Train IoU: 0.1320\n",
      "Validation Loss: 0.6294, Validation IoU: 0.1793\n",
      "Training for channel 15 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6393, Train IoU: 0.0000\n",
      "Validation Loss: 0.6457, Validation IoU: 0.0000\n",
      "Training for channel 16 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6370, Train IoU: 0.0000\n",
      "Validation Loss: 0.6437, Validation IoU: 0.0000\n",
      "Training for channel 17 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6370, Train IoU: 0.0000\n",
      "Validation Loss: 0.6446, Validation IoU: 0.0001\n",
      "Training for channel 18 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6371, Train IoU: 0.0000\n",
      "Validation Loss: 0.6440, Validation IoU: 0.0001\n",
      "Training for channel 19 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6275, Train IoU: 0.0087\n",
      "Validation Loss: 0.6409, Validation IoU: 0.0101\n",
      "Training for channel 20 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6369, Train IoU: 0.0083\n",
      "Validation Loss: 0.6451, Validation IoU: 0.0150\n",
      "Training for channel 21 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6373, Train IoU: 0.0000\n",
      "Validation Loss: 0.6452, Validation IoU: 0.0001\n",
      "Training for channel 22 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6383, Train IoU: 0.0012\n",
      "Validation Loss: 0.6523, Validation IoU: 0.0015\n",
      "Training for channel 23 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6366, Train IoU: 0.0000\n",
      "Validation Loss: 0.6436, Validation IoU: 0.0000\n",
      "Training for channel 24 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6394, Train IoU: 0.0031\n",
      "Validation Loss: 0.6458, Validation IoU: 0.0071\n",
      "Training for channel 25 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6439, Train IoU: 0.0020\n",
      "Validation Loss: 0.6527, Validation IoU: 0.0046\n",
      "Training for channel 26 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6420, Train IoU: 0.0655\n",
      "Validation Loss: 0.6499, Validation IoU: 0.0834\n",
      "Training for channel 27 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6391, Train IoU: 0.0000\n",
      "Validation Loss: 0.6455, Validation IoU: 0.0000\n",
      "Training for channel 28 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 29 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6335, Train IoU: 0.0000\n",
      "Validation Loss: 0.6434, Validation IoU: 0.0001\n",
      "Training for channel 30 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6375, Train IoU: 0.0186\n",
      "Validation Loss: 0.6427, Validation IoU: 0.0317\n",
      "Training for channel 31 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6391, Train IoU: 0.0000\n",
      "Validation Loss: 0.6462, Validation IoU: 0.0000\n",
      "Training for channel 32 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6387, Train IoU: 0.0000\n",
      "Validation Loss: 0.6454, Validation IoU: 0.0000\n",
      "Training for channel 33 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6384, Train IoU: 0.0000\n",
      "Validation Loss: 0.6449, Validation IoU: 0.0000\n",
      "Training for channel 34 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6374, Train IoU: 0.0000\n",
      "Validation Loss: 0.6449, Validation IoU: 0.0001\n",
      "Training for channel 35 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6319, Train IoU: 0.0000\n",
      "Validation Loss: 0.6442, Validation IoU: 0.0000\n",
      "Training for channel 36 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 37 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6382, Train IoU: 0.0000\n",
      "Validation Loss: 0.6453, Validation IoU: 0.0000\n",
      "Training for channel 38 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 39 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0001\n",
      "Validation Loss: 0.6463, Validation IoU: 0.0004\n",
      "Training for channel 40 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0002\n",
      "Training for channel 41 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6377, Train IoU: 0.0020\n",
      "Validation Loss: 0.6436, Validation IoU: 0.0048\n",
      "Training for channel 42 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6377, Train IoU: 0.0005\n",
      "Validation Loss: 0.6475, Validation IoU: 0.0011\n",
      "Training for channel 43 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6386, Train IoU: 0.0003\n",
      "Validation Loss: 0.6454, Validation IoU: 0.0009\n",
      "Training for channel 44 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6392, Train IoU: 0.0013\n",
      "Validation Loss: 0.6464, Validation IoU: 0.0033\n",
      "Training for channel 45 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6315, Train IoU: 0.0000\n",
      "Validation Loss: 0.6431, Validation IoU: 0.0000\n",
      "Training for channel 46 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6385, Train IoU: 0.0000\n",
      "Validation Loss: 0.6459, Validation IoU: 0.0000\n",
      "Training for channel 47 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6391, Train IoU: 0.0001\n",
      "Validation Loss: 0.6462, Validation IoU: 0.0004\n",
      "Training for channel 48 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 49 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6410, Train IoU: 0.0003\n",
      "Validation Loss: 0.6488, Validation IoU: 0.0011\n",
      "Training for channel 50 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6386, Train IoU: 0.0012\n",
      "Validation Loss: 0.6447, Validation IoU: 0.0030\n",
      "Training for channel 51 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6318, Train IoU: 0.0012\n",
      "Validation Loss: 0.6421, Validation IoU: 0.0022\n",
      "Training for channel 52 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6395, Train IoU: 0.0000\n",
      "Validation Loss: 0.6460, Validation IoU: 0.0000\n",
      "Training for channel 53 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6396, Train IoU: 0.0001\n",
      "Validation Loss: 0.6467, Validation IoU: 0.0005\n",
      "Training for channel 54 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6311, Train IoU: 0.0000\n",
      "Validation Loss: 0.6433, Validation IoU: 0.0000\n",
      "Training for channel 55 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6365, Train IoU: 0.0001\n",
      "Validation Loss: 0.6447, Validation IoU: 0.0003\n",
      "Training for channel 56 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6368, Train IoU: 0.0245\n",
      "Validation Loss: 0.6444, Validation IoU: 0.0403\n",
      "Training for channel 57 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6325, Train IoU: 0.0164\n",
      "Validation Loss: 0.6373, Validation IoU: 0.0251\n",
      "Training for channel 58 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6315, Train IoU: 0.0000\n",
      "Validation Loss: 0.6443, Validation IoU: 0.0000\n",
      "Training for channel 59 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6403, Train IoU: 0.0000\n",
      "Validation Loss: 0.6471, Validation IoU: 0.0002\n",
      "Training for channel 60 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6349, Train IoU: 0.0003\n",
      "Validation Loss: 0.6456, Validation IoU: 0.0003\n",
      "Training for channel 61 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6350, Train IoU: 0.0000\n",
      "Validation Loss: 0.6430, Validation IoU: 0.0001\n",
      "Training for channel 62 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6283, Train IoU: 0.0000\n",
      "Validation Loss: 0.6408, Validation IoU: 0.0000\n",
      "Training for channel 63 of layer conv1\n",
      "Epoch 20/20, Loss: 0.6389, Train IoU: 0.0014\n",
      "Validation Loss: 0.6456, Validation IoU: 0.0035\n",
      "\n",
      "Processing layer: bn1 with 64 channels\n",
      "Training for channel 0 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6318, Train IoU: 0.0009\n",
      "Validation Loss: 0.6393, Validation IoU: 0.0017\n",
      "Training for channel 1 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6212, Train IoU: 0.0047\n",
      "Validation Loss: 0.6278, Validation IoU: 0.0046\n",
      "Training for channel 2 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 3 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6396, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 4 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 5 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6345, Train IoU: 0.0004\n",
      "Validation Loss: 0.6403, Validation IoU: 0.0000\n",
      "Training for channel 6 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6372, Train IoU: 0.0010\n",
      "Validation Loss: 0.6367, Validation IoU: 0.0001\n",
      "Training for channel 7 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 8 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6277, Train IoU: 0.0014\n",
      "Validation Loss: 0.6358, Validation IoU: 0.0027\n",
      "Training for channel 9 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 10 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6369, Train IoU: 0.0102\n",
      "Validation Loss: 0.6456, Validation IoU: 0.0098\n",
      "Training for channel 11 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6306, Train IoU: 0.0154\n",
      "Validation Loss: 0.6380, Validation IoU: 0.0173\n",
      "Training for channel 12 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6373, Train IoU: 0.0000\n",
      "Validation Loss: 0.6451, Validation IoU: 0.0000\n",
      "Training for channel 13 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 14 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6331, Train IoU: 0.0037\n",
      "Validation Loss: 0.6394, Validation IoU: 0.0049\n",
      "Training for channel 15 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6365, Train IoU: 0.0001\n",
      "Validation Loss: 0.6411, Validation IoU: 0.0000\n",
      "Training for channel 16 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6322, Train IoU: 0.0000\n",
      "Validation Loss: 0.6385, Validation IoU: 0.0000\n",
      "Training for channel 17 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6338, Train IoU: 0.0948\n",
      "Validation Loss: 0.6391, Validation IoU: 0.0710\n",
      "Training for channel 18 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6308, Train IoU: 0.1277\n",
      "Validation Loss: 0.6349, Validation IoU: 0.1070\n",
      "Training for channel 19 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6113, Train IoU: 0.0005\n",
      "Validation Loss: 0.6200, Validation IoU: 0.0005\n",
      "Training for channel 20 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6221, Train IoU: 0.0015\n",
      "Validation Loss: 0.6295, Validation IoU: 0.0017\n",
      "Training for channel 21 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6300, Train IoU: 0.0010\n",
      "Validation Loss: 0.6380, Validation IoU: 0.0009\n",
      "Training for channel 22 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6197, Train IoU: 0.0001\n",
      "Validation Loss: 0.6290, Validation IoU: 0.0002\n",
      "Training for channel 23 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6218, Train IoU: 0.0000\n",
      "Validation Loss: 0.6310, Validation IoU: 0.0000\n",
      "Training for channel 24 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6326, Train IoU: 0.0039\n",
      "Validation Loss: 0.6406, Validation IoU: 0.0052\n",
      "Training for channel 25 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6415, Train IoU: 0.0007\n",
      "Validation Loss: 0.6505, Validation IoU: 0.0008\n",
      "Training for channel 26 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6416, Train IoU: 0.0017\n",
      "Validation Loss: 0.6508, Validation IoU: 0.0020\n",
      "Training for channel 27 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6370, Train IoU: 0.0125\n",
      "Validation Loss: 0.6444, Validation IoU: 0.0001\n",
      "Training for channel 28 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6329, Train IoU: 0.0017\n",
      "Validation Loss: 0.6315, Validation IoU: 0.0000\n",
      "Training for channel 29 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6334, Train IoU: 0.0001\n",
      "Validation Loss: 0.6425, Validation IoU: 0.0001\n",
      "Training for channel 30 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6339, Train IoU: 0.0070\n",
      "Validation Loss: 0.6410, Validation IoU: 0.0076\n",
      "Training for channel 31 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6365, Train IoU: 0.0005\n",
      "Validation Loss: 0.6433, Validation IoU: 0.0004\n",
      "Training for channel 32 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6386, Train IoU: 0.0004\n",
      "Validation Loss: 0.6427, Validation IoU: 0.0000\n",
      "Training for channel 33 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6320, Train IoU: 0.0000\n",
      "Validation Loss: 0.6359, Validation IoU: 0.0000\n",
      "Training for channel 34 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6321, Train IoU: 0.1780\n",
      "Validation Loss: 0.6344, Validation IoU: 0.1565\n",
      "Training for channel 35 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6304, Train IoU: 0.0000\n",
      "Validation Loss: 0.6411, Validation IoU: 0.0000\n",
      "Training for channel 36 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 37 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6347, Train IoU: 0.0000\n",
      "Validation Loss: 0.6417, Validation IoU: 0.0001\n",
      "Training for channel 38 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 39 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6321, Train IoU: 0.0012\n",
      "Validation Loss: 0.6401, Validation IoU: 0.0020\n",
      "Training for channel 40 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6307, Train IoU: 0.0003\n",
      "Validation Loss: 0.6383, Validation IoU: 0.0008\n",
      "Training for channel 41 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6284, Train IoU: 0.0040\n",
      "Validation Loss: 0.6353, Validation IoU: 0.0054\n",
      "Training for channel 42 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6226, Train IoU: 0.0007\n",
      "Validation Loss: 0.6318, Validation IoU: 0.0013\n",
      "Training for channel 43 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6330, Train IoU: 0.0004\n",
      "Validation Loss: 0.6406, Validation IoU: 0.0006\n",
      "Training for channel 44 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6361, Train IoU: 0.0063\n",
      "Validation Loss: 0.6439, Validation IoU: 0.0071\n",
      "Training for channel 45 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6077, Train IoU: 0.0003\n",
      "Validation Loss: 0.6177, Validation IoU: 0.0000\n",
      "Training for channel 46 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6332, Train IoU: 0.0004\n",
      "Validation Loss: 0.6410, Validation IoU: 0.0004\n",
      "Training for channel 47 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6330, Train IoU: 0.0010\n",
      "Validation Loss: 0.6411, Validation IoU: 0.0013\n",
      "Training for channel 48 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6397, Train IoU: 0.0000\n",
      "Validation Loss: 0.6461, Validation IoU: 0.0000\n",
      "Training for channel 49 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6315, Train IoU: 0.0011\n",
      "Validation Loss: 0.6404, Validation IoU: 0.0021\n",
      "Training for channel 50 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6263, Train IoU: 0.0009\n",
      "Validation Loss: 0.6338, Validation IoU: 0.0015\n",
      "Training for channel 51 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6091, Train IoU: 0.0046\n",
      "Validation Loss: 0.6175, Validation IoU: 0.0046\n",
      "Training for channel 52 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6163, Train IoU: 0.0018\n",
      "Validation Loss: 0.6313, Validation IoU: 0.0000\n",
      "Training for channel 53 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6325, Train IoU: 0.0014\n",
      "Validation Loss: 0.6410, Validation IoU: 0.0022\n",
      "Training for channel 54 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6391, Train IoU: 0.0000\n",
      "Validation Loss: 0.6460, Validation IoU: 0.0000\n",
      "Training for channel 55 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6231, Train IoU: 0.0003\n",
      "Validation Loss: 0.6314, Validation IoU: 0.0009\n",
      "Training for channel 56 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6387, Train IoU: 0.0016\n",
      "Validation Loss: 0.6480, Validation IoU: 0.0020\n",
      "Training for channel 57 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6283, Train IoU: 0.0035\n",
      "Validation Loss: 0.6343, Validation IoU: 0.0040\n",
      "Training for channel 58 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6376, Train IoU: 0.0000\n",
      "Validation Loss: 0.6452, Validation IoU: 0.0000\n",
      "Training for channel 59 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6341, Train IoU: 0.0010\n",
      "Validation Loss: 0.6426, Validation IoU: 0.0017\n",
      "Training for channel 60 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6120, Train IoU: 0.0005\n",
      "Validation Loss: 0.6205, Validation IoU: 0.0006\n",
      "Training for channel 61 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6282, Train IoU: 0.0002\n",
      "Validation Loss: 0.6359, Validation IoU: 0.0002\n",
      "Training for channel 62 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6375, Train IoU: 0.0000\n",
      "Validation Loss: 0.6452, Validation IoU: 0.0000\n",
      "Training for channel 63 of layer bn1\n",
      "Epoch 20/20, Loss: 0.6303, Train IoU: 0.0004\n",
      "Validation Loss: 0.6383, Validation IoU: 0.0009\n",
      "\n",
      "Processing layer: layer1.0.conv1 with 64 channels\n",
      "Training for channel 0 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6405, Train IoU: 0.0006\n",
      "Validation Loss: 0.6527, Validation IoU: 0.0006\n",
      "Training for channel 1 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5770, Train IoU: 0.2595\n",
      "Validation Loss: 0.5951, Validation IoU: 0.1359\n",
      "Training for channel 2 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6245, Train IoU: 0.1812\n",
      "Validation Loss: 0.6553, Validation IoU: 0.0068\n",
      "Training for channel 3 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6219, Train IoU: 0.0032\n",
      "Validation Loss: 0.6462, Validation IoU: 0.0021\n",
      "Training for channel 4 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5957, Train IoU: 0.0014\n",
      "Validation Loss: 0.6362, Validation IoU: 0.0016\n",
      "Training for channel 5 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6205, Train IoU: 0.0003\n",
      "Validation Loss: 0.6491, Validation IoU: 0.0003\n",
      "Training for channel 6 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6335, Train IoU: 0.0740\n",
      "Validation Loss: 0.6428, Validation IoU: 0.0300\n",
      "Training for channel 7 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6645, Train IoU: 0.0228\n",
      "Validation Loss: 0.6746, Validation IoU: 0.0281\n",
      "Training for channel 8 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6079, Train IoU: 0.0005\n",
      "Validation Loss: 0.6348, Validation IoU: 0.0004\n",
      "Training for channel 9 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6145, Train IoU: 0.0880\n",
      "Validation Loss: 0.6242, Validation IoU: 0.0926\n",
      "Training for channel 10 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6358, Train IoU: 0.0169\n",
      "Validation Loss: 0.6376, Validation IoU: 0.0652\n",
      "Training for channel 11 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6176, Train IoU: 0.0008\n",
      "Validation Loss: 0.6556, Validation IoU: 0.0008\n",
      "Training for channel 12 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6359, Train IoU: 0.0579\n",
      "Validation Loss: 0.6410, Validation IoU: 0.0544\n",
      "Training for channel 13 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5935, Train IoU: 0.0208\n",
      "Validation Loss: 0.6042, Validation IoU: 0.0287\n",
      "Training for channel 14 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6077, Train IoU: 0.0302\n",
      "Validation Loss: 0.6248, Validation IoU: 0.0285\n",
      "Training for channel 15 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6091, Train IoU: 0.0005\n",
      "Validation Loss: 0.6072, Validation IoU: 0.0007\n",
      "Training for channel 16 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5828, Train IoU: 0.0000\n",
      "Validation Loss: 0.5974, Validation IoU: 0.0000\n",
      "Training for channel 17 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6393, Train IoU: 0.1197\n",
      "Validation Loss: 0.6472, Validation IoU: 0.0640\n",
      "Training for channel 18 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6047, Train IoU: 0.0000\n",
      "Validation Loss: 0.6019, Validation IoU: 0.0000\n",
      "Training for channel 19 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6407, Train IoU: 0.0012\n",
      "Validation Loss: 0.6487, Validation IoU: 0.0013\n",
      "Training for channel 20 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6262, Train IoU: 0.0020\n",
      "Validation Loss: 0.6538, Validation IoU: 0.0017\n",
      "Training for channel 21 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6164, Train IoU: 0.0025\n",
      "Validation Loss: 0.6478, Validation IoU: 0.0027\n",
      "Training for channel 22 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6228, Train IoU: 0.0021\n",
      "Validation Loss: 0.6606, Validation IoU: 0.0026\n",
      "Training for channel 23 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6327, Train IoU: 0.0018\n",
      "Validation Loss: 0.6306, Validation IoU: 0.0002\n",
      "Training for channel 24 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6320, Train IoU: 0.0006\n",
      "Validation Loss: 0.6411, Validation IoU: 0.0002\n",
      "Training for channel 25 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6319, Train IoU: 0.0009\n",
      "Validation Loss: 0.6423, Validation IoU: 0.0001\n",
      "Training for channel 26 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6362, Train IoU: 0.0211\n",
      "Validation Loss: 0.6458, Validation IoU: 0.0248\n",
      "Training for channel 27 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6133, Train IoU: 0.0014\n",
      "Validation Loss: 0.6517, Validation IoU: 0.0016\n",
      "Training for channel 28 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6302, Train IoU: 0.0089\n",
      "Validation Loss: 0.6364, Validation IoU: 0.0011\n",
      "Training for channel 29 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6369, Train IoU: 0.1016\n",
      "Validation Loss: 0.6428, Validation IoU: 0.1225\n",
      "Training for channel 30 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5486, Train IoU: 0.1676\n",
      "Validation Loss: 0.5802, Validation IoU: 0.1619\n",
      "Training for channel 31 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6162, Train IoU: 0.0002\n",
      "Validation Loss: 0.6463, Validation IoU: 0.0001\n",
      "Training for channel 32 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6226, Train IoU: 0.0023\n",
      "Validation Loss: 0.6243, Validation IoU: 0.0020\n",
      "Training for channel 33 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5905, Train IoU: 0.0027\n",
      "Validation Loss: 0.6331, Validation IoU: 0.0033\n",
      "Training for channel 34 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5908, Train IoU: 0.0037\n",
      "Validation Loss: 0.6237, Validation IoU: 0.0041\n",
      "Training for channel 35 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6209, Train IoU: 0.0010\n",
      "Validation Loss: 0.6563, Validation IoU: 0.0010\n",
      "Training for channel 36 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6295, Train IoU: 0.0008\n",
      "Validation Loss: 0.6467, Validation IoU: 0.0015\n",
      "Training for channel 37 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6388, Train IoU: 0.0145\n",
      "Validation Loss: 0.6463, Validation IoU: 0.0041\n",
      "Training for channel 38 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5878, Train IoU: 0.0025\n",
      "Validation Loss: 0.6297, Validation IoU: 0.0030\n",
      "Training for channel 39 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6048, Train IoU: 0.0062\n",
      "Validation Loss: 0.6328, Validation IoU: 0.0068\n",
      "Training for channel 40 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6200, Train IoU: 0.1227\n",
      "Validation Loss: 0.6340, Validation IoU: 0.0083\n",
      "Training for channel 41 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5706, Train IoU: 0.0003\n",
      "Validation Loss: 0.6122, Validation IoU: 0.0007\n",
      "Training for channel 42 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6331, Train IoU: 0.0124\n",
      "Validation Loss: 0.6437, Validation IoU: 0.0209\n",
      "Training for channel 43 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6138, Train IoU: 0.0052\n",
      "Validation Loss: 0.6282, Validation IoU: 0.0057\n",
      "Training for channel 44 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5436, Train IoU: 0.0004\n",
      "Validation Loss: 0.5740, Validation IoU: 0.0014\n",
      "Training for channel 45 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5981, Train IoU: 0.0105\n",
      "Validation Loss: 0.6217, Validation IoU: 0.0082\n",
      "Training for channel 46 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6145, Train IoU: 0.0035\n",
      "Validation Loss: 0.6539, Validation IoU: 0.0042\n",
      "Training for channel 47 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5818, Train IoU: 0.0000\n",
      "Validation Loss: 0.6104, Validation IoU: 0.0000\n",
      "Training for channel 48 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5854, Train IoU: 0.0001\n",
      "Validation Loss: 0.6277, Validation IoU: 0.0001\n",
      "Training for channel 49 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6174, Train IoU: 0.0021\n",
      "Validation Loss: 0.6338, Validation IoU: 0.0023\n",
      "Training for channel 50 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5863, Train IoU: 0.0027\n",
      "Validation Loss: 0.6204, Validation IoU: 0.0029\n",
      "Training for channel 51 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6002, Train IoU: 0.0016\n",
      "Validation Loss: 0.6332, Validation IoU: 0.0017\n",
      "Training for channel 52 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6345, Train IoU: 0.0003\n",
      "Validation Loss: 0.6513, Validation IoU: 0.0002\n",
      "Training for channel 53 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6154, Train IoU: 0.0010\n",
      "Validation Loss: 0.6480, Validation IoU: 0.0011\n",
      "Training for channel 54 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5822, Train IoU: 0.0001\n",
      "Validation Loss: 0.6230, Validation IoU: 0.0002\n",
      "Training for channel 55 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.6349, Train IoU: 0.0024\n",
      "Validation Loss: 0.6431, Validation IoU: 0.0128\n",
      "Training for channel 56 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5725, Train IoU: 0.0000\n",
      "Validation Loss: 0.6159, Validation IoU: 0.0000\n",
      "Training for channel 57 of layer layer1.0.conv1\n",
      "Epoch 20/20, Loss: 0.5841, Train IoU: 0.0046\n",
      "Validation Loss: 0.6296, Validation IoU: 0.0046\n",
      "Training for channel 58 of layer layer1.0.conv1\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacity of 5.70 GiB of which 117.81 MiB is free. Including non-PyTorch memory, this process has 5.54 GiB memory in use. Of the allocated memory 5.14 GiB is allocated by PyTorch, and 268.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Call the training function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m all_layers_iou_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_conv_probe_all_layers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Save the results to a JSON file\u001b[39;00m\n\u001b[1;32m     10\u001b[0m save_results_to_json(all_layers_iou_results, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet18_layers_iou_results.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m, in \u001b[0;36mtrain_conv_probe_all_layers\u001b[0;34m(train_loader, test_loader, image_size, device, num_epochs, lr)\u001b[0m\n\u001b[1;32m      6\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProcessing layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_channels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m channels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     iou_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_conv_probe_all_channels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     all_layers_iou_results[layer_name] \u001b[38;5;241m=\u001b[39m iou_results\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_layers_iou_results\n",
      "Cell \u001b[0;32mIn[6], line 35\u001b[0m, in \u001b[0;36mtrain_conv_probe_all_channels\u001b[0;34m(layer_name, num_channels, train_loader, test_loader, image_size, device, num_epochs, lr)\u001b[0m\n\u001b[1;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Forward pass using the current channel\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mprobe_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape: [batch_size, height, width]\u001b[39;00m\n\u001b[1;32m     37\u001b[0m masks \u001b[38;5;241m=\u001b[39m masks\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)      \u001b[38;5;66;03m# Shape: [batch_size, height, width]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 71\u001b[0m, in \u001b[0;36mConvProbe.forward\u001b[0;34m(self, x, channel_idx)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, channel_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 71\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Forward pass to get activations\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_name]  \u001b[38;5;66;03m# Retrieve the stored activation\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# Select a specific channel if provided\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torchvision/models/resnet.py:269\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m--> 269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m    271\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:176\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mestrado/lib/python3.11/site-packages/torch/nn/functional.py:2512\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2510\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2513\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacity of 5.70 GiB of which 117.81 MiB is free. Including non-PyTorch memory, this process has 5.54 GiB memory in use. Of the allocated memory 5.14 GiB is allocated by PyTorch, and 268.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Call the training function\n",
    "all_layers_iou_results = train_conv_probe_all_layers(\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    image_size=image_size,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Save the results to a JSON file\n",
    "save_results_to_json(all_layers_iou_results, 'resnet18_layers_iou_results.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mestrado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
