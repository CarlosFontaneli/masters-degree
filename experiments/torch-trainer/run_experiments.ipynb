{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import itertools\n",
    "import subprocess \n",
    "from torchtrainer.util.train_util import dict_to_argv \n",
    "\n",
    "# All samples in the VessMAP dataset\n",
    "names = [\n",
    "    '5472', '2413', '3406', '7577', '4404', '12005', '10084', '3882', '15577', '15375', '8353', '17035',\n",
    "    '13114', '4413', '7783', '11411', '6524', '6581', '13200', '9860', '525', '2643', '8990', '9284',\n",
    "    '2050', '2071', '13128', '7865', '14440', '8196', '17880', '1643', '11558', '12943', '2546', '9452',\n",
    "    '11828', '8493', '14225', '8256', '1816', '14121', '11161', '16707', '356', '12877', '6818', '10571',\n",
    "    '6672', '17702', '15821', '8429', '18180', '13528', '16689', '12960', '5359', '6384', '7392', '6887',\n",
    "    '8506', '1585', '4938', '458', '5801', '8686', '15160', '7413', '8065', '8284', '9593', '17584', '2849',\n",
    "    '9710', '5740', '4739', '2958', '14787', '11098', '17630', '11111', '6656', '17852', '9000', '12455', '9523',\n",
    "    '4909', '12618', '14778', '16295', '17425', '14690', '12749', '12335', '7083', '2287', '482', '7344', '18035',\n",
    "    '16766'\n",
    "]\n",
    "\n",
    "# These parameters are common defaults for all experiments.\n",
    "base_params = {\n",
    "    # Logging parameters:\n",
    "    \"experiments_path\": \"/home/fonta42/Desktop/masters-degree/experiments/torch-trainer\",\n",
    "    \"run_name\": \"\", # Will be dynamically generated per run\n",
    "    \"validate_every\": 50,\n",
    "    \"copy_model_every\": 0,\n",
    "    \"wandb_project\": \"uncategorized\",\n",
    "\n",
    "    # Dataset parameters:\n",
    "    \"dataset_path\": \"/home/fonta42/Desktop/masters-degree/data/torch-trainer/VessMAP\",\n",
    "    \"dataset_class\": \"vessmap_few\",\n",
    "    \"resize_size\": \"256 256\", # Default, can/will be overridden by model specifics\n",
    "    \"loss_function\": \"bce\", # Default, can/will be overridden by variations\n",
    "\n",
    "    # Model parameters:\n",
    "    \"model_class\": \"\", # To be set specifically for each model type\n",
    "\n",
    "    # Training parameters:\n",
    "    \"num_epochs\": 1000,\n",
    "    \"validation_metric\": \"Dice\",\n",
    "    \"lr\": 0.001, # Default, can/will be overridden by variations\n",
    "    \"lr_decay\": 1.0, # Default, can/will be overridden by variations\n",
    "    \"bs_train\": 2,\n",
    "    \"bs_valid\": 2,\n",
    "    \"weight_decay\": 0.0, # Default, can/will be overridden by variations\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"momentum\": 0.9,\n",
    "    \"seed\": 42,\n",
    "\n",
    "    # Device and efficiency parameters:\n",
    "    \"device\": \"cuda:0\",\n",
    "    \"num_workers\": 5,\n",
    "    \"benchmark\": \"\", # Empty string means 'use benchmark if available'\n",
    "}\n",
    "\n",
    "\n",
    "# Define the parameters to vary and their possible values.\n",
    "parameter_variations = {\n",
    "    \"split_strategy\": [20, 90],  # Number of samples to select for the training split strategy\n",
    "    \"val_img_indices\": [\"0 1 2 3\", \"0 2 4\"], \n",
    "    \"loss_function\": [\"bce\", \"cross_entropy\"],\n",
    "    \"lr\": [0.001, 0.01],\n",
    "    \"lr_decay\": [1.0, 0.9],\n",
    "    \"weight_decay\": [0.0, 1e-4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Generate Parameter Combinations\n",
    "def generate_parameter_combinations(base_params, variations_dict):\n",
    "    \"\"\"\n",
    "    Generates a list of parameter dictionaries, representing all combinations\n",
    "    of the variations provided.\n",
    "\n",
    "    Args:\n",
    "        base_params (dict): Dictionary of default parameters.\n",
    "        variations_dict (dict): Dictionary where keys are parameter names and\n",
    "                                values are lists of possible settings.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, each representing a unique experiment configuration.\n",
    "    \"\"\"\n",
    "    keys = list(variations_dict.keys())\n",
    "    value_lists = [variations_dict[key] for key in keys]\n",
    "\n",
    "    all_combinations = []\n",
    "    # Use itertools.product to efficiently get the Cartesian product of all value lists\n",
    "    for value_combination in itertools.product(*value_lists):\n",
    "        # Start with a fresh copy of the base parameters for each combination\n",
    "        params = copy.deepcopy(base_params)\n",
    "        # Create a dictionary for the current combination of varying parameters\n",
    "        variation_params = dict(zip(keys, value_combination))\n",
    "        params.update(variation_params)\n",
    "        all_combinations.append(params)\n",
    "\n",
    "    print(f\"Generated {len(all_combinations)} parameter combinations.\")\n",
    "    return all_combinations\n",
    "\n",
    "# Generate all parameter sets\n",
    "all_params_list = generate_parameter_combinations(base_params, parameter_variations)\n",
    "total_experiments = len(all_params_list)\n",
    "\n",
    "# Define Keys to Exclude from Command Line Arguments\n",
    "exclude_argv_common = [\"dataset_path\", \"dataset_class\", \"model_class\", \"split_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run MedSAM Experiments ---\n",
    "print(f\"\\n--- Starting MedSAM Experiments ({total_experiments} runs) ---\")\n",
    "medsam_script = \"./medsam_train_torchtrainer.py\"\n",
    "medsam_overrides = {\n",
    "    \"resize_size\": \"1024 1024\",\n",
    "    \"model_class\": \"medsam\",\n",
    "    \"experiment_name\": \"medsam_runs\"\n",
    "}\n",
    "\n",
    "# Model specific exclusions\n",
    "medsam_exclude_argv = exclude_argv_common\n",
    "\n",
    "for i, base_combo_params in enumerate(all_params_list):\n",
    "    params = copy.deepcopy(base_combo_params)\n",
    "\n",
    "    # Apply MedSAM specific overrides\n",
    "    params.update(medsam_overrides)\n",
    "\n",
    "    # Generate the split_strategy string dynamically using the 'split_size'\n",
    "    split_size = params['split_strategy']\n",
    "    params['split_strategy'] = ','.join(random.sample(names, split_size))\n",
    "\n",
    "    # Construct a unique run_name reflecting the parameters for this MedSAM run\n",
    "    params[\"run_name\"] = f\"medsam_{split_size}_{params['resize_size'].replace(' ','x')}_{params['loss_function']}_{params['num_epochs']}_{params['lr']}_{params['bs_train']}_{params['bs_valid']}_{params['weight_decay']}\"\n",
    "\n",
    "    print(f\"\\nRunning MedSAM experiment {i+1}/{total_experiments}: {params['run_name']}\")\n",
    "    try:\n",
    "        commandline = ' '.join(dict_to_argv(params, medsam_exclude_argv)) \n",
    "        print(f\"Executing: python {medsam_script} {commandline}\")\n",
    "\n",
    "        !python {medsam_script} {commandline}\n",
    "\n",
    "        print(f\"Finished attempt for experiment: {params['run_name']}\") # Log successful attempt\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch any exception during the '!' execution and report it\n",
    "        print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(f\"!!! ERROR during MedSAM experiment: {params['run_name']}\")\n",
    "        print(f\"!!! Error type: {type(e).__name__}\")\n",
    "        print(f\"!!! Error details: {e}\")\n",
    "        print(f\"!!! Skipping this run and continuing with the next experiment.\")\n",
    "        print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "print(f\"--- Finished MedSAM Experiment Loop ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run U-Mamba Experiments ---\n",
    "print(f\"\\n--- Starting U-Mamba Experiments ({total_experiments} runs) ---\")\n",
    "umamba_script = \"./umamba_train_torchtrainer.py\"\n",
    "umamba_overrides = {\n",
    "    \"resize_size\": \"256 256\",\n",
    "    \"model_class\": \"umamba\",\n",
    "    \"experiment_name\": \"umamba_runs\"\n",
    "}\n",
    "umamba_exclude_argv = exclude_argv_common \n",
    "\n",
    "for i, base_combo_params in enumerate(all_params_list):\n",
    "    params = copy.deepcopy(base_combo_params)\n",
    "    params.update(umamba_overrides)\n",
    "\n",
    "    split_size = params['split_strategy']\n",
    "    params['split_strategy'] = ','.join(random.sample(names, split_size))\n",
    "\n",
    "    val_indices_str = params['val_img_indices'].replace(' ','') \n",
    "    params[\"run_name\"] = f\"umamba_{split_size}_{params['resize_size'].replace(' ','x')}_{params['loss_function']}_{params['num_epochs']}_{params['lr']}_{params['bs_train']}_{params['bs_valid']}_{params['weight_decay']}_val{val_indices_str}\"\n",
    "\n",
    "    print(f\"\\nRunning U-Mamba experiment {i+1}/{total_experiments}: {params['run_name']}\")\n",
    "    try:\n",
    "        commandline = ' '.join(dict_to_argv(params, umamba_exclude_argv))\n",
    "        print(f\"Executing: python {umamba_script} {commandline}\")\n",
    "\n",
    "        !python {umamba_script} {commandline}\n",
    "\n",
    "        print(f\"Finished attempt for experiment: {params['run_name']}\") \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(f\"!!! ERROR during U-Mamba experiment: {params['run_name']}\")\n",
    "        print(f\"!!! Error type: {type(e).__name__}\")\n",
    "        print(f\"!!! Error details: {e}\")\n",
    "        print(f\"!!! Skipping this run and continuing with the next experiment.\")\n",
    "        print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "\n",
    "print(f\"--- Finished U-Mamba Experiment Loop ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run U-Net Experiments ---\n",
    "print(f\"\\n--- Starting U-Net Experiments ({total_experiments} runs) ---\")\n",
    "unet_script = \"unet_train_torchtrainer.py\" \n",
    "unet_overrides = {\n",
    "    \"resize_size\": \"256 256\",\n",
    "    \"model_class\": \"unet_smp\", \n",
    "    \"experiment_name\": \"unet_runs\"\n",
    "}\n",
    "unet_exclude_argv = exclude_argv_common \n",
    "\n",
    "for i, base_combo_params in enumerate(all_params_list):\n",
    "    params = copy.deepcopy(base_combo_params)\n",
    "    params.update(unet_overrides)\n",
    "\n",
    "    split_size = params['split_strategy']\n",
    "    params['split_strategy'] = ','.join(random.sample(names, split_size))\n",
    "\n",
    "    val_indices_str = params['val_img_indices'].replace(' ','')\n",
    "    params[\"run_name\"] = f\"unet_{split_size}_{params['resize_size'].replace(' ','x')}_{params['loss_function']}_{params['num_epochs']}_{params['lr']}_{params['bs_train']}_{params['bs_valid']}_{params['weight_decay']}_val{val_indices_str}\"\n",
    "\n",
    "    print(f\"\\nRunning U-Net experiment {i+1}/{total_experiments}: {params['run_name']}\")\n",
    "\n",
    "    print(\"Running U-Net experiment with:\")\n",
    "    try:\n",
    "        commandline = ' '.join(dict_to_argv(params, unet_exclude_argv))\n",
    "        print(f\"Executing: python {unet_script} {commandline}\") \n",
    "\n",
    "        !python {unet_script} {commandline}\n",
    "\n",
    "        print(f\"Finished attempt for experiment: {params['run_name']}\") \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(f\"!!! ERROR during U-Net experiment: {params['run_name']}\")\n",
    "        print(f\"!!! Error type: {type(e).__name__}\")\n",
    "        print(f\"!!! Error details: {e}\")\n",
    "        print(f\"!!! Skipping this run and continuing with the next experiment.\")\n",
    "        print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "\n",
    "print(f\"--- Finished U-Net Experiment Loop ---\")\n",
    "\n",
    "\n",
    "print(\"\\n--- All experiment loops finished ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtrainer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
