{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvProbe class\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Dataset\n",
    "import sys\n",
    "sys.path.append('../data/vess-map/')\n",
    "from vess_map_dataset import VessMapDataset\n",
    "\n",
    "# Training loop\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Save the results\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Clear memory\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvProbe(nn.Module):\n",
    "    def __init__(self, model, layer_name, output_size=(256, 256), seed=None, single_channel=True):\n",
    "        super(ConvProbe, self).__init__()\n",
    "\n",
    "        # Load pre-trained ResNet-18 model\n",
    "        self.model =  model\n",
    "        self.layer_name = layer_name\n",
    "        self.output_size = output_size\n",
    "        self.single_channel = single_channel\n",
    "\n",
    "        # Freeze model weights to prevent training\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Get number of channels from the specified layer\n",
    "        in_channels = 1 if self.single_channel else self.get_layer_channels(layer_name)\n",
    "\n",
    "\n",
    "        # Initialize the first convolutional layer (to be trained)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,  # Numbers of channels for the activation\n",
    "            out_channels=1,  \n",
    "            kernel_size=3,\n",
    "            padding=1  # Preserve spatial dimensions\n",
    "        )\n",
    "\n",
    "        # Initialize the second convolutional layer (to be trained)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=1,  # Input channels from conv1\n",
    "            out_channels=1,  # Single output channel for binary segmentation\n",
    "            kernel_size=3,\n",
    "            padding=1  # Preserve spatial dimensions\n",
    "        )\n",
    "\n",
    "        # Set a fixed random seed for consistency, if provided\n",
    "        if seed is not None:\n",
    "            self.set_seed(seed)\n",
    "\n",
    "        # Register a hook to capture activations from the specified layer\n",
    "        self.activations = {}\n",
    "        self.register_hook()\n",
    "\n",
    "    # Helper function to set random seed\n",
    "    def set_seed(self, seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Helper function to get the number of channels from the specified layer\n",
    "    def get_layer_channels(self, layer_name):\n",
    "        # Iterate over the named modules to find the specified layer\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == layer_name:\n",
    "                if hasattr(module, 'out_channels'):\n",
    "                    return module.out_channels\n",
    "                elif hasattr(module, 'num_features'):\n",
    "                    return module.num_features  # For BatchNorm layers\n",
    "                else:\n",
    "                    raise ValueError(f\"Layer {layer_name} does not have out_channels or num_features.\")\n",
    "        raise ValueError(f\"Layer {layer_name} not found.\")\n",
    "\n",
    "    # Register a forward hook to capture activations\n",
    "    def register_hook(self):\n",
    "        def hook_fn(module, input, output):\n",
    "            self.activations[self.layer_name] = output\n",
    "\n",
    "        # Register the hook on the specified layer\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == self.layer_name:\n",
    "                module.register_forward_hook(hook_fn)\n",
    "                break\n",
    "\n",
    "    # Forward pass through the model\n",
    "    def forward(self, x, channel_idx=None):\n",
    "        _ = self.model(x)  # Forward pass to get activations\n",
    "        activation = self.activations[self.layer_name]  # Retrieve the stored activation\n",
    "\n",
    "        # Select a specific channel if provided\n",
    "        if channel_idx is not None:\n",
    "            if channel_idx < 0 or channel_idx >= activation.size(1):\n",
    "                raise ValueError(f\"Channel index {channel_idx} is out of bounds for activation with {activation.size(1)} channels.\")\n",
    "            activation = activation[:, channel_idx:channel_idx+1, :, :]  # Select the specific channel\n",
    "\n",
    "        # Apply the first convolutional layer\n",
    "        activation = self.conv1(activation)\n",
    "\n",
    "        # Interpolate activation to match the desired output size\n",
    "        activation = F.interpolate(activation, size=self.output_size, mode='bilinear', align_corners=True)\n",
    "\n",
    "        # Apply the second convolutional layer\n",
    "        out = self.conv2(activation) \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "image_dir = '../data/vess-map/images'\n",
    "mask_dir = '../data/vess-map/labels'\n",
    "skeleton_dir = '../data/vess-map/skeletons'\n",
    "\n",
    "image_size = 256\n",
    "\n",
    "# Initialize the dataset\n",
    "vess_dataset = VessMapDataset(image_dir, mask_dir, skeleton_dir, image_size, apply_transform=True)\n",
    "\n",
    "# Get the train and test loaders\n",
    "train_loader, test_loader = vess_dataset.vess_map_dataloader(batch_size=80, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(outputs, masks, threshold=0.5):\n",
    "    # Apply sigmoid to outputs to get probabilities between 0 and 1\n",
    "    preds = torch.sigmoid(outputs)\n",
    "    preds = (preds > threshold).float()  # Convert probabilities to binary predictions\n",
    "\n",
    "    # Ensure masks are float type\n",
    "    masks = masks.float()\n",
    "\n",
    "    # Compute intersection and union\n",
    "    intersection = (preds * masks).sum(dim=(1, 2))\n",
    "    union = ((preds + masks) > 0).float().sum(dim=(1, 2))\n",
    "\n",
    "    # Avoid division by zero\n",
    "    iou = torch.where(union == 0, torch.tensor(1.0).to(outputs.device), intersection / union)\n",
    "\n",
    "    # Return mean IoU over the batch\n",
    "    return iou.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, smooth=1e-6):\n",
    "    # Apply sigmoid activation if outputs are logits\n",
    "    pred = torch.sigmoid(pred)\n",
    "    \n",
    "    # Flatten the tensors\n",
    "    pred_flat = pred.view(-1)\n",
    "    target_flat = target.view(-1)\n",
    "    \n",
    "    # Compute intersection and union\n",
    "    intersection = (pred_flat * target_flat).sum()\n",
    "    union = pred_flat.sum() + target_flat.sum()\n",
    "    \n",
    "    # Compute Dice Coefficient\n",
    "    dice_coef = (2 * intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    # Compute Dice Loss\n",
    "    loss = 1 - dice_coef\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_conv_probe_all_channels(\n",
    "    model, layer_name, num_channels, train_loader, test_loader, image_size, device,\n",
    "    num_epochs=50, lr=0.001, single_channel=True, loss_function='BCE',\n",
    "    channels_to_train=None\n",
    "):\n",
    "    iou_results = {}  # Dictionary to store IoU results for each channel\n",
    "\n",
    "    if channels_to_train is not None:\n",
    "        # Train only the specified channels\n",
    "        channels = channels_to_train\n",
    "    else:\n",
    "        # Train all channels\n",
    "        channels = range(num_channels)\n",
    "\n",
    "    for channel_idx in channels:\n",
    "        print(f\"Training for channel {channel_idx} of layer {layer_name}\")\n",
    "\n",
    "        probe_model = ConvProbe(\n",
    "            model=model,\n",
    "            layer_name=layer_name,\n",
    "            output_size=(image_size, image_size),\n",
    "            seed=42,\n",
    "            single_channel=single_channel\n",
    "        )\n",
    "        probe_model.to(device)\n",
    "\n",
    "        # Choose the loss function based on the parameter\n",
    "        if loss_function == 'BCE':\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "        elif loss_function == 'Dice':\n",
    "            criterion = dice_loss  # We'll define dice_loss function separately\n",
    "        else:\n",
    "            raise ValueError(\"Invalid loss_function. Choose 'BCE' or 'Dice'.\")\n",
    "\n",
    "        # Define optimizer for ConvProbe parameters only\n",
    "        optimizer = optim.Adam(\n",
    "            list(probe_model.conv1.parameters()) + list(probe_model.conv2.parameters()), lr=lr\n",
    "        )\n",
    "\n",
    "        # Track metrics for this channel\n",
    "        train_losses = []\n",
    "        train_ious = []\n",
    "        val_losses = []\n",
    "        val_ious = []\n",
    "        \n",
    "        # Get a sample image from the validation loader for saving outputs\n",
    "        sample_inputs, sample_masks, _ = next(iter(test_loader))\n",
    "        sample_inputs = sample_inputs.to(device)[:5]  # Take one sample\n",
    "        sample_masks = sample_masks.to(device).float()[:5]\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            probe_model.train()\n",
    "            running_loss = 0.0\n",
    "            train_iou = 0.0\n",
    "\n",
    "            # Training loop\n",
    "            for inputs, masks, _ in train_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                masks = masks.to(device).float()  # Ensure masks are float type\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if single_channel:\n",
    "                    # Forward pass using the current channel\n",
    "                    outputs = probe_model(inputs, channel_idx=channel_idx)\n",
    "                else:\n",
    "                    outputs = probe_model(inputs)\n",
    "\n",
    "                # Shape: [batch_size, height, width]\n",
    "                outputs = outputs.squeeze(1)\n",
    "                # Shape: [batch_size, height, width]\n",
    "                masks = masks.squeeze(1)\n",
    "\n",
    "                # Compute loss\n",
    "                if loss_function == 'BCE':\n",
    "                    loss = criterion(outputs, masks)\n",
    "                elif loss_function == 'Dice':\n",
    "                    loss = criterion(outputs, masks)  # dice_loss function handles activation\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Accumulate running loss\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Compute IoU for this batch\n",
    "                batch_iou = calculate_iou(outputs, masks)\n",
    "                train_iou += batch_iou * inputs.size(0)\n",
    "\n",
    "            # Calculate epoch loss and IoU\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            epoch_iou = train_iou / len(train_loader.dataset)\n",
    "            if epoch % (num_epochs - 1) == 0:\n",
    "                print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Train IoU: {epoch_iou:.4f}')\n",
    "\n",
    "            # Append metrics\n",
    "            train_losses.append(epoch_loss)\n",
    "            train_ious.append(epoch_iou)\n",
    "\n",
    "            # Validation loop\n",
    "            probe_model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_iou = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_masks, _ in test_loader:\n",
    "                    val_inputs = val_inputs.to(device)\n",
    "                    val_masks = val_masks.to(device).float()\n",
    "\n",
    "                    # Forward pass using the current channel\n",
    "                    if single_channel:\n",
    "                        val_outputs = probe_model(val_inputs, channel_idx=channel_idx)\n",
    "                    else:\n",
    "                        val_outputs = probe_model(val_inputs)\n",
    "\n",
    "                    val_outputs = val_outputs.squeeze(1)\n",
    "                    val_masks = val_masks.squeeze(1)\n",
    "\n",
    "                    # Compute loss\n",
    "                    if loss_function == 'BCE':\n",
    "                        val_loss_batch = criterion(val_outputs, val_masks)\n",
    "                    elif loss_function == 'Dice':\n",
    "                        val_loss_batch = criterion(val_outputs, val_masks)\n",
    "\n",
    "                    val_loss += val_loss_batch.item() * val_inputs.size(0)\n",
    "\n",
    "                    # Compute IoU for this batch\n",
    "                    batch_val_iou = calculate_iou(val_outputs, val_masks)\n",
    "                    val_iou += batch_val_iou * val_inputs.size(0)\n",
    "\n",
    "            # Calculate validation loss and IoU\n",
    "            val_loss /= len(test_loader.dataset)\n",
    "            val_iou /= len(test_loader.dataset)\n",
    "            if epoch % (num_epochs - 1) == 0:\n",
    "                print(f'Validation Loss: {val_loss:.4f}, Validation IoU: {val_iou:.4f}')\n",
    "\n",
    "            # Append validation metrics\n",
    "            val_losses.append(val_loss)\n",
    "            val_ious.append(val_iou)\n",
    "\n",
    "            # Save model output on sample image for debugging\n",
    "            if epoch == num_epochs - 1 and val_iou < 0.0001:\n",
    "                with torch.no_grad():\n",
    "                    if single_channel:\n",
    "                        sample_output = probe_model(\n",
    "                            sample_inputs, channel_idx=channel_idx)\n",
    "                    else:\n",
    "                        sample_output = probe_model(\n",
    "                            sample_inputs)\n",
    "                    sample_output = sample_output.squeeze(1)\n",
    "                    sample_output_np = sample_output.cpu().numpy()[0]\n",
    "                    # Save the image\n",
    "                    plt.imsave(f\"./conv-probe-debbug/output_layer_{layer_name}_channel_{channel_idx}_epoch_{epoch+1}.png\",\n",
    "                                sample_output_np,\n",
    "                                cmap='gray')\n",
    "\n",
    "        # Save per-epoch metrics for this channel\n",
    "        iou_results[channel_idx] = {\n",
    "            'train_loss': train_losses,\n",
    "            'train_iou': train_ious,\n",
    "            'val_loss': val_losses,\n",
    "            'val_iou': val_ious\n",
    "        }\n",
    "\n",
    "        # Free GPU memory after training for the current channel is completed\n",
    "        del probe_model, optimizer\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        if not single_channel:\n",
    "            break\n",
    "\n",
    "    del train_loader, test_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return iou_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get layer names and number of channels from ResNet-18\n",
    "def get_resnet18_layers_info():\n",
    "    resnet18 = models.resnet18(pretrained=True)\n",
    "    layers_info = {}\n",
    "    for name, module in resnet18.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.BatchNorm2d)):\n",
    "            if hasattr(module, 'out_channels'):\n",
    "                out_channels = module.out_channels\n",
    "            elif hasattr(module, 'num_features'):\n",
    "                out_channels = module.num_features\n",
    "            else:\n",
    "                continue\n",
    "            layers_info[name] = out_channels\n",
    "    return layers_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save results to a JSON file\n",
    "def save_results_to_json(results, filename):\n",
    "    # Convert tensors or numpy types to native Python types\n",
    "    def convert(o):\n",
    "        if isinstance(o, np.float32) or isinstance(o, np.float64):\n",
    "            return float(o)\n",
    "        if isinstance(o, torch.Tensor):\n",
    "            return o.item()\n",
    "        raise TypeError\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(results, f, default=convert)\n",
    "        \n",
    "# Function to save layer time to a JSON file\n",
    "def save_layer_time_to_json(layer_name, layer_time, json_file):\n",
    "    # Convert layer time to minutes and round to 3 decimal places\n",
    "    layer_time_minutes = round(layer_time / 60.0, 3)\n",
    "\n",
    "    # Check if the JSON file exists\n",
    "    if os.path.exists(json_file):\n",
    "        with open(json_file, 'r') as f:\n",
    "            time_results = json.load(f)\n",
    "    else:\n",
    "        time_results = {}  # Initialize empty dictionary if file doesn't exist\n",
    "\n",
    "    # Update the dictionary with the current layer's time (in minutes)\n",
    "    time_results[layer_name] = layer_time_minutes\n",
    "\n",
    "    # Save back to the JSON file\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(time_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_conv_probe_all_layers(\n",
    "    train_loader, test_loader, image_size, device, num_epochs=20, lr=0.001,\n",
    "    loss_function=\"BCE\", time_results_file='./times/time_results.json',\n",
    "    specific_layer_channel_pairs=None\n",
    "):\n",
    "    all_layers_iou_results = {}\n",
    "    layers_info = get_resnet18_layers_info()\n",
    "\n",
    "    start_total_time = time.time()  # Start timing for the entire process\n",
    "\n",
    "    if specific_layer_channel_pairs:\n",
    "        # If specific layer-channel pairs are provided\n",
    "        # Group the pairs by layer\n",
    "        from collections import defaultdict\n",
    "        layer_channel_dict = defaultdict(list)\n",
    "        for pair in specific_layer_channel_pairs:\n",
    "            layer_name = pair[0]\n",
    "            channel_idx = int(pair[1])\n",
    "            layer_channel_dict[layer_name].append(channel_idx)\n",
    "\n",
    "        for layer_name, channels_to_train in layer_channel_dict.items():\n",
    "            print(f\"\\nProcessing layer: {layer_name} with channels {channels_to_train}\")\n",
    "            print(f\"Training {num_epochs} epochs, with loss: {loss_function}\")\n",
    "\n",
    "            # Start timing for each layer\n",
    "            start_layer_time = time.time()\n",
    "\n",
    "            # Declare the model to use\n",
    "            model = models.resnet18(pretrained=True)\n",
    "\n",
    "            # Get num_channels for the layer\n",
    "            num_channels = layers_info.get(layer_name, None)\n",
    "            if num_channels is None:\n",
    "                raise ValueError(f\"Layer {layer_name} not found in layers_info.\")\n",
    "\n",
    "            # Train the conv probe for the current layer\n",
    "            iou_results = train_conv_probe_all_channels(\n",
    "                model=model,\n",
    "                layer_name=layer_name,\n",
    "                num_channels=num_channels,\n",
    "                train_loader=train_loader,\n",
    "                test_loader=test_loader,\n",
    "                image_size=image_size,\n",
    "                device=device,\n",
    "                num_epochs=num_epochs,\n",
    "                lr=lr,\n",
    "                loss_function=loss_function,\n",
    "                channels_to_train=channels_to_train  # Pass the specific channels\n",
    "            )\n",
    "\n",
    "            # Save individual layer results\n",
    "            save_results_to_json(iou_results, f'./top-k-dice-conv-probe-layers-results/{layer_name}_activation_results.json')\n",
    "            all_layers_iou_results[layer_name] = iou_results\n",
    "\n",
    "            # Calculate time taken for this layer\n",
    "            layer_time_taken = time.time() - start_layer_time\n",
    "            print(f\"Time taken for {layer_name}: {layer_time_taken:.2f} seconds\")\n",
    "\n",
    "            # Save the time result for the current layer to the JSON file\n",
    "            save_layer_time_to_json(layer_name, layer_time_taken, time_results_file)\n",
    "\n",
    "            # Free GPU memory\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    else:\n",
    "        # If no specific pairs provided, train all layers and all channels\n",
    "        for layer_name, num_channels in layers_info.items():\n",
    "            print(f\"\\nProcessing layer: {layer_name} with {num_channels} channels\")\n",
    "            print(f\"Training {num_epochs} epochs, with loss: {loss_function}\")\n",
    "\n",
    "            # Start timing for each layer\n",
    "            start_layer_time = time.time()\n",
    "\n",
    "            # Declare the model to use\n",
    "            model = models.resnet18(pretrained=True)\n",
    "\n",
    "            # Train the conv probe for the current layer\n",
    "            iou_results = train_conv_probe_all_channels(\n",
    "                model=model,\n",
    "                layer_name=layer_name,\n",
    "                num_channels=num_channels,\n",
    "                train_loader=train_loader,\n",
    "                test_loader=test_loader,\n",
    "                image_size=image_size,\n",
    "                device=device,\n",
    "                num_epochs=num_epochs,\n",
    "                lr=lr,\n",
    "                loss_function=loss_function\n",
    "            )\n",
    "\n",
    "            # Save individual layer results\n",
    "            save_results_to_json(iou_results, f'./top-k-dice-conv-probe-layers-results/{layer_name}_activation_results.json')\n",
    "            all_layers_iou_results[layer_name] = iou_results\n",
    "\n",
    "            # Calculate time taken for this layer\n",
    "            layer_time_taken = time.time() - start_layer_time\n",
    "            print(f\"Time taken for {layer_name}: {layer_time_taken:.2f} seconds\")\n",
    "\n",
    "            # Save the time result for the current layer to the JSON file\n",
    "            save_layer_time_to_json(layer_name, layer_time_taken, time_results_file)\n",
    "\n",
    "            # Free GPU memory\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    # Calculate and store the total time taken\n",
    "    total_time_taken = time.time() - start_total_time\n",
    "    print(f\"Total time taken: {total_time_taken:.2f} seconds\")\n",
    "\n",
    "    # Save the total time to the JSON file\n",
    "    save_layer_time_to_json('total_time', total_time_taken, time_results_file)\n",
    "\n",
    "    # Save all layers' IoU results to JSON\n",
    "    save_results_to_json(all_layers_iou_results, './top-k-dice-conv-probe-layers-results/resnet18_layers_iou_results.json')\n",
    "\n",
    "    return all_layers_iou_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lavic-3080/carlos/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/lavic-3080/carlos/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing layer: layer2.0.downsample.0 with channels [126, 121, 0]\n",
      "Training 500 epochs, with loss: Dice\n",
      "Training for channel 126 of layer layer2.0.downsample.0\n",
      "Epoch 1/500, Loss: 0.6644, Train IoU: 0.2391\n",
      "Validation Loss: 0.6467, Validation IoU: 0.2252\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 121 of layer layer2.0.downsample.0\n",
      "Epoch 1/500, Loss: 0.6840, Train IoU: 0.0030\n",
      "Validation Loss: 0.7486, Validation IoU: 0.0000\n",
      "Epoch 500/500, Loss: 0.4525, Train IoU: 0.3747\n",
      "Validation Loss: 0.4273, Validation IoU: 0.3937\n",
      "Training for channel 0 of layer layer2.0.downsample.0\n",
      "Epoch 1/500, Loss: 0.6827, Train IoU: 0.0090\n",
      "Validation Loss: 0.6720, Validation IoU: 0.2224\n",
      "Epoch 500/500, Loss: 0.5163, Train IoU: 0.3146\n",
      "Validation Loss: 0.5103, Validation IoU: 0.3179\n",
      "Time taken for layer2.0.downsample.0: 250.40 seconds\n",
      "\n",
      "Processing layer: layer1.0.conv1 with channels [43, 62, 29, 0, 26]\n",
      "Training 500 epochs, with loss: Dice\n",
      "Training for channel 43 of layer layer1.0.conv1\n",
      "Epoch 1/500, Loss: 0.6933, Train IoU: 0.0117\n",
      "Validation Loss: 0.7229, Validation IoU: 0.0020\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 62 of layer layer1.0.conv1\n",
      "Epoch 1/500, Loss: 0.6837, Train IoU: 0.0037\n",
      "Validation Loss: 0.7574, Validation IoU: 0.0000\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 29 of layer layer1.0.conv1\n",
      "Epoch 1/500, Loss: 0.6851, Train IoU: 0.0080\n",
      "Validation Loss: 0.7303, Validation IoU: 0.0011\n",
      "Epoch 500/500, Loss: 0.3931, Train IoU: 0.4315\n",
      "Validation Loss: 0.3676, Validation IoU: 0.4529\n",
      "Training for channel 0 of layer layer1.0.conv1\n",
      "Epoch 1/500, Loss: 0.6811, Train IoU: 0.0353\n",
      "Validation Loss: 0.6382, Validation IoU: 0.2282\n",
      "Epoch 500/500, Loss: 0.4681, Train IoU: 0.3593\n",
      "Validation Loss: 0.4297, Validation IoU: 0.3870\n",
      "Training for channel 26 of layer layer1.0.conv1\n",
      "Epoch 1/500, Loss: 0.6796, Train IoU: 0.0684\n",
      "Validation Loss: 0.6356, Validation IoU: 0.2296\n",
      "Epoch 500/500, Loss: 0.4466, Train IoU: 0.3784\n",
      "Validation Loss: 0.4110, Validation IoU: 0.4092\n",
      "Time taken for layer1.0.conv1: 411.78 seconds\n",
      "\n",
      "Processing layer: layer1.1.bn2 with channels [61, 8, 34, 11, 28, 63, 14, 6, 46, 27]\n",
      "Training 500 epochs, with loss: Dice\n",
      "Training for channel 61 of layer layer1.1.bn2\n",
      "Epoch 1/500, Loss: 0.6910, Train IoU: 0.0026\n",
      "Validation Loss: 0.7205, Validation IoU: 0.0020\n",
      "Epoch 500/500, Loss: 0.3762, Train IoU: 0.4525\n",
      "Validation Loss: 0.3539, Validation IoU: 0.4693\n",
      "Training for channel 8 of layer layer1.1.bn2\n",
      "Epoch 1/500, Loss: 0.6829, Train IoU: 0.0095\n",
      "Validation Loss: 0.6412, Validation IoU: 0.2252\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 34 of layer layer1.1.bn2\n",
      "Epoch 1/500, Loss: 0.6829, Train IoU: 0.0092\n",
      "Validation Loss: 0.6477, Validation IoU: 0.2251\n",
      "Epoch 500/500, Loss: 0.5181, Train IoU: 0.3070\n",
      "Validation Loss: 0.4927, Validation IoU: 0.3303\n",
      "Training for channel 11 of layer layer1.1.bn2\n",
      "Epoch 1/500, Loss: 0.6841, Train IoU: 0.0157\n",
      "Validation Loss: 0.7342, Validation IoU: 0.0003\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 28 of layer layer1.1.bn2\n",
      "Epoch 1/500, Loss: 0.6851, Train IoU: 0.0140\n",
      "Validation Loss: 0.6943, Validation IoU: 0.0140\n",
      "Epoch 500/500, Loss: 0.4418, Train IoU: 0.3872\n",
      "Validation Loss: 0.4201, Validation IoU: 0.4041\n",
      "Training for channel 63 of layer layer1.1.bn2\n",
      "Epoch 1/500, Loss: 0.6834, Train IoU: 0.0179\n",
      "Validation Loss: 0.6667, Validation IoU: 0.2252\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 14 of layer layer1.1.bn2\n",
      "Epoch 1/500, Loss: 0.6817, Train IoU: 0.0084\n",
      "Validation Loss: 0.6479, Validation IoU: 0.2251\n",
      "Epoch 500/500, Loss: 0.3852, Train IoU: 0.4421\n",
      "Validation Loss: 0.3731, Validation IoU: 0.4543\n",
      "Training for channel 6 of layer layer1.1.bn2\n",
      "Epoch 1/500, Loss: 0.6834, Train IoU: 0.0061\n",
      "Validation Loss: 0.6394, Validation IoU: 0.2252\n",
      "Epoch 500/500, Loss: 0.4117, Train IoU: 0.4154\n",
      "Validation Loss: 0.3889, Validation IoU: 0.4259\n",
      "Training for channel 46 of layer layer1.1.bn2\n",
      "Epoch 1/500, Loss: 0.6823, Train IoU: 0.0112\n",
      "Validation Loss: 0.6481, Validation IoU: 0.2252\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 27 of layer layer1.1.bn2\n",
      "Epoch 1/500, Loss: 0.6839, Train IoU: 0.0059\n",
      "Validation Loss: 0.7217, Validation IoU: 0.0001\n",
      "Epoch 500/500, Loss: 0.5023, Train IoU: 0.3120\n",
      "Validation Loss: 0.4812, Validation IoU: 0.3210\n",
      "Time taken for layer1.1.bn2: 771.27 seconds\n",
      "\n",
      "Processing layer: layer1.0.bn2 with channels [61, 6, 51, 42, 11, 46, 60, 55, 28]\n",
      "Training 500 epochs, with loss: Dice\n",
      "Training for channel 61 of layer layer1.0.bn2\n",
      "Epoch 1/500, Loss: 0.6907, Train IoU: 0.0013\n",
      "Validation Loss: 0.7188, Validation IoU: 0.0019\n",
      "Epoch 500/500, Loss: 0.3773, Train IoU: 0.4485\n",
      "Validation Loss: 0.3480, Validation IoU: 0.4724\n",
      "Training for channel 6 of layer layer1.0.bn2\n",
      "Epoch 1/500, Loss: 0.6834, Train IoU: 0.0009\n",
      "Validation Loss: 0.6380, Validation IoU: 0.2252\n",
      "Epoch 500/500, Loss: 0.4177, Train IoU: 0.4074\n",
      "Validation Loss: 0.3886, Validation IoU: 0.4269\n",
      "Training for channel 51 of layer layer1.0.bn2\n",
      "Epoch 1/500, Loss: 0.6830, Train IoU: 0.0017\n",
      "Validation Loss: 0.6419, Validation IoU: 0.2252\n",
      "Epoch 500/500, Loss: 0.5455, Train IoU: 0.2851\n",
      "Validation Loss: 0.5522, Validation IoU: 0.2824\n",
      "Training for channel 42 of layer layer1.0.bn2\n",
      "Epoch 1/500, Loss: 0.6834, Train IoU: 0.0023\n",
      "Validation Loss: 0.6566, Validation IoU: 0.2252\n",
      "Epoch 500/500, Loss: 0.5363, Train IoU: 0.3086\n",
      "Validation Loss: 0.5449, Validation IoU: 0.2968\n",
      "Training for channel 11 of layer layer1.0.bn2\n",
      "Epoch 1/500, Loss: 0.6840, Train IoU: 0.0068\n",
      "Validation Loss: 0.7316, Validation IoU: 0.0001\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 46 of layer layer1.0.bn2\n",
      "Epoch 1/500, Loss: 0.6821, Train IoU: 0.0066\n",
      "Validation Loss: 0.6465, Validation IoU: 0.2252\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 60 of layer layer1.0.bn2\n",
      "Epoch 1/500, Loss: 0.6832, Train IoU: 0.0015\n",
      "Validation Loss: 0.6467, Validation IoU: 0.2252\n",
      "Epoch 500/500, Loss: 0.5580, Train IoU: 0.2738\n",
      "Validation Loss: 0.5568, Validation IoU: 0.2761\n",
      "Training for channel 55 of layer layer1.0.bn2\n",
      "Epoch 1/500, Loss: 0.6834, Train IoU: 0.0008\n",
      "Validation Loss: 0.6739, Validation IoU: 0.2260\n",
      "Epoch 500/500, Loss: 0.5387, Train IoU: 0.3065\n",
      "Validation Loss: 0.5406, Validation IoU: 0.2994\n",
      "Training for channel 28 of layer layer1.0.bn2\n",
      "Epoch 1/500, Loss: 0.6846, Train IoU: 0.0035\n",
      "Validation Loss: 0.7262, Validation IoU: 0.0001\n",
      "Epoch 500/500, Loss: 0.4136, Train IoU: 0.4117\n",
      "Validation Loss: 0.3858, Validation IoU: 0.4290\n",
      "Time taken for layer1.0.bn2: 669.52 seconds\n",
      "\n",
      "Processing layer: layer4.1.bn2 with channels [286, 163, 357, 17, 460, 255, 188, 210, 509, 300, 371, 190, 380, 145, 335, 27, 79, 65, 46, 168, 351, 4, 386, 7, 390, 254, 507, 24, 151, 226, 155, 162, 339, 81, 306, 32, 449, 182, 440, 134, 465, 332, 144, 236, 387, 58, 398, 120, 57, 209, 238, 427, 8, 394, 416, 316, 400, 167, 310, 256, 63, 178, 322, 405, 9, 458, 56]\n",
      "Training 500 epochs, with loss: Dice\n",
      "Training for channel 286 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6922, Train IoU: 0.0376\n",
      "Validation Loss: 0.7266, Validation IoU: 0.0001\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6272, Validation IoU: 0.2291\n",
      "Training for channel 163 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6824, Train IoU: 0.0612\n",
      "Validation Loss: 0.6563, Validation IoU: 0.2248\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 357 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6841, Train IoU: 0.0346\n",
      "Validation Loss: 0.7320, Validation IoU: 0.0040\n",
      "Epoch 500/500, Loss: 0.6116, Train IoU: 0.2329\n",
      "Validation Loss: 0.6315, Validation IoU: 0.2229\n",
      "Training for channel 17 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6833, Train IoU: 0.0700\n",
      "Validation Loss: 0.7178, Validation IoU: 0.0019\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 460 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6839, Train IoU: 0.0456\n",
      "Validation Loss: 0.7268, Validation IoU: 0.0034\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 255 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6832, Train IoU: 0.0623\n",
      "Validation Loss: 0.6530, Validation IoU: 0.2244\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 188 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6824, Train IoU: 0.0511\n",
      "Validation Loss: 0.6562, Validation IoU: 0.2250\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 210 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6834, Train IoU: 0.0365\n",
      "Validation Loss: 0.7213, Validation IoU: 0.0008\n",
      "Epoch 500/500, Loss: 0.6145, Train IoU: 0.2381\n",
      "Validation Loss: 0.6288, Validation IoU: 0.2291\n",
      "Training for channel 509 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6829, Train IoU: 0.0479\n",
      "Validation Loss: 0.6523, Validation IoU: 0.2255\n",
      "Epoch 500/500, Loss: 0.6118, Train IoU: 0.2287\n",
      "Validation Loss: 0.6353, Validation IoU: 0.2061\n",
      "Training for channel 300 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6834, Train IoU: 0.0313\n",
      "Validation Loss: 0.7083, Validation IoU: 0.0022\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 371 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6835, Train IoU: 0.0474\n",
      "Validation Loss: 0.7253, Validation IoU: 0.0066\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 190 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6835, Train IoU: 0.0473\n",
      "Validation Loss: 0.7233, Validation IoU: 0.0075\n",
      "Epoch 500/500, Loss: 0.6146, Train IoU: 0.2381\n",
      "Validation Loss: 0.6304, Validation IoU: 0.2291\n",
      "Training for channel 380 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6830, Train IoU: 0.0579\n",
      "Validation Loss: 0.6536, Validation IoU: 0.2254\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 145 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6827, Train IoU: 0.0476\n",
      "Validation Loss: 0.6537, Validation IoU: 0.2240\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 335 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6833, Train IoU: 0.0350\n",
      "Validation Loss: 0.6694, Validation IoU: 0.2240\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 27 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6828, Train IoU: 0.0539\n",
      "Validation Loss: 0.6511, Validation IoU: 0.2249\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 79 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6826, Train IoU: 0.0502\n",
      "Validation Loss: 0.6593, Validation IoU: 0.2245\n",
      "Epoch 500/500, Loss: 0.6144, Train IoU: 0.2311\n",
      "Validation Loss: 0.6228, Validation IoU: 0.2226\n",
      "Training for channel 65 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6831, Train IoU: 0.0480\n",
      "Validation Loss: 0.6460, Validation IoU: 0.2243\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 46 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6835, Train IoU: 0.0478\n",
      "Validation Loss: 0.7211, Validation IoU: 0.0061\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 168 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6828, Train IoU: 0.0460\n",
      "Validation Loss: 0.6543, Validation IoU: 0.2245\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 351 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6835, Train IoU: 0.0348\n",
      "Validation Loss: 0.7222, Validation IoU: 0.0042\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 4 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6833, Train IoU: 0.0443\n",
      "Validation Loss: 0.6718, Validation IoU: 0.2243\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 386 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6827, Train IoU: 0.0425\n",
      "Validation Loss: 0.6568, Validation IoU: 0.2236\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 7 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6830, Train IoU: 0.0694\n",
      "Validation Loss: 0.6531, Validation IoU: 0.2236\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 390 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6823, Train IoU: 0.0582\n",
      "Validation Loss: 0.6526, Validation IoU: 0.2246\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 254 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6831, Train IoU: 0.0557\n",
      "Validation Loss: 0.6502, Validation IoU: 0.2253\n",
      "Epoch 500/500, Loss: 0.6130, Train IoU: 0.2351\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2294\n",
      "Training for channel 507 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6833, Train IoU: 0.0477\n",
      "Validation Loss: 0.6738, Validation IoU: 0.2240\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 24 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6833, Train IoU: 0.0400\n",
      "Validation Loss: 0.7205, Validation IoU: 0.0018\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 151 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6835, Train IoU: 0.0385\n",
      "Validation Loss: 0.7193, Validation IoU: 0.0080\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 226 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6824, Train IoU: 0.0613\n",
      "Validation Loss: 0.6534, Validation IoU: 0.2254\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 155 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6840, Train IoU: 0.0412\n",
      "Validation Loss: 0.7306, Validation IoU: 0.0043\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 162 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6826, Train IoU: 0.0552\n",
      "Validation Loss: 0.6612, Validation IoU: 0.2253\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 339 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6826, Train IoU: 0.0473\n",
      "Validation Loss: 0.6604, Validation IoU: 0.2249\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 81 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6828, Train IoU: 0.0533\n",
      "Validation Loss: 0.6636, Validation IoU: 0.2247\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 306 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6829, Train IoU: 0.0592\n",
      "Validation Loss: 0.6498, Validation IoU: 0.2244\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 32 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6832, Train IoU: 0.0485\n",
      "Validation Loss: 0.6564, Validation IoU: 0.2247\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 449 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6844, Train IoU: 0.0305\n",
      "Validation Loss: 0.7298, Validation IoU: 0.0057\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 182 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6820, Train IoU: 0.0713\n",
      "Validation Loss: 0.6472, Validation IoU: 0.2253\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 440 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6831, Train IoU: 0.0483\n",
      "Validation Loss: 0.6608, Validation IoU: 0.2250\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 134 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6837, Train IoU: 0.0400\n",
      "Validation Loss: 0.7291, Validation IoU: 0.0091\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 465 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6832, Train IoU: 0.0464\n",
      "Validation Loss: 0.6611, Validation IoU: 0.2250\n",
      "Epoch 500/500, Loss: 0.6113, Train IoU: 0.2375\n",
      "Validation Loss: 0.6280, Validation IoU: 0.2247\n",
      "Training for channel 332 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6834, Train IoU: 0.0498\n",
      "Validation Loss: 0.7483, Validation IoU: 0.0032\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 144 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6830, Train IoU: 0.0472\n",
      "Validation Loss: 0.6555, Validation IoU: 0.2255\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 236 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6831, Train IoU: 0.0548\n",
      "Validation Loss: 0.6604, Validation IoU: 0.2255\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 387 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6826, Train IoU: 0.0612\n",
      "Validation Loss: 0.6500, Validation IoU: 0.2238\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 58 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6833, Train IoU: 0.0399\n",
      "Validation Loss: 0.7411, Validation IoU: 0.0021\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 398 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6832, Train IoU: 0.0495\n",
      "Validation Loss: 0.6618, Validation IoU: 0.2245\n",
      "Epoch 500/500, Loss: 0.6096, Train IoU: 0.2337\n",
      "Validation Loss: 0.6283, Validation IoU: 0.2238\n",
      "Training for channel 120 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6827, Train IoU: 0.0562\n",
      "Validation Loss: 0.6490, Validation IoU: 0.2257\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 57 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6835, Train IoU: 0.0380\n",
      "Validation Loss: 0.7251, Validation IoU: 0.0046\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 209 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6831, Train IoU: 0.0523\n",
      "Validation Loss: 0.6571, Validation IoU: 0.2240\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 238 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6829, Train IoU: 0.0390\n",
      "Validation Loss: 0.6578, Validation IoU: 0.2250\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 427 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6846, Train IoU: 0.0316\n",
      "Validation Loss: 0.7263, Validation IoU: 0.0057\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 8 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6827, Train IoU: 0.0415\n",
      "Validation Loss: 0.6580, Validation IoU: 0.2245\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 394 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6824, Train IoU: 0.0575\n",
      "Validation Loss: 0.6582, Validation IoU: 0.2245\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 416 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6828, Train IoU: 0.0431\n",
      "Validation Loss: 0.6561, Validation IoU: 0.2249\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 316 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6822, Train IoU: 0.0661\n",
      "Validation Loss: 0.6584, Validation IoU: 0.2245\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 400 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6829, Train IoU: 0.0580\n",
      "Validation Loss: 0.6503, Validation IoU: 0.2243\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 167 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6831, Train IoU: 0.0508\n",
      "Validation Loss: 0.6512, Validation IoU: 0.2249\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 310 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6834, Train IoU: 0.0412\n",
      "Validation Loss: 0.7275, Validation IoU: 0.0053\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 256 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6832, Train IoU: 0.0539\n",
      "Validation Loss: 0.6633, Validation IoU: 0.2244\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 63 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6824, Train IoU: 0.0585\n",
      "Validation Loss: 0.6556, Validation IoU: 0.2242\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 178 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6831, Train IoU: 0.0548\n",
      "Validation Loss: 0.6543, Validation IoU: 0.2252\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 322 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6826, Train IoU: 0.0572\n",
      "Validation Loss: 0.6501, Validation IoU: 0.2256\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 405 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6831, Train IoU: 0.0464\n",
      "Validation Loss: 0.6600, Validation IoU: 0.2259\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 9 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6829, Train IoU: 0.0474\n",
      "Validation Loss: 0.6487, Validation IoU: 0.2250\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 458 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6837, Train IoU: 0.0266\n",
      "Validation Loss: 0.7196, Validation IoU: 0.0022\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Training for channel 56 of layer layer4.1.bn2\n",
      "Epoch 1/500, Loss: 0.6817, Train IoU: 0.0711\n",
      "Validation Loss: 0.6562, Validation IoU: 0.2248\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Time taken for layer4.1.bn2: 5260.59 seconds\n",
      "\n",
      "Processing layer: layer3.1.conv1 with channels [208]\n",
      "Training 500 epochs, with loss: Dice\n",
      "Training for channel 208 of layer layer3.1.conv1\n",
      "Epoch 1/500, Loss: 0.6905, Train IoU: 0.0002\n",
      "Validation Loss: 0.7412, Validation IoU: 0.0000\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Time taken for layer3.1.conv1: 77.70 seconds\n",
      "\n",
      "Processing layer: layer1.1.conv1 with channels [42]\n",
      "Training 500 epochs, with loss: Dice\n",
      "Training for channel 42 of layer layer1.1.conv1\n",
      "Epoch 1/500, Loss: 0.6920, Train IoU: 0.0031\n",
      "Validation Loss: 0.7115, Validation IoU: 0.0000\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Time taken for layer1.1.conv1: 75.48 seconds\n",
      "\n",
      "Processing layer: bn1 with channels [6, 21, 61]\n",
      "Training 500 epochs, with loss: Dice\n",
      "Training for channel 6 of layer bn1\n",
      "Epoch 1/500, Loss: 0.6889, Train IoU: 0.0007\n",
      "Validation Loss: 0.6693, Validation IoU: 0.2254\n",
      "Epoch 500/500, Loss: 0.4262, Train IoU: 0.4028\n",
      "Validation Loss: 0.4159, Validation IoU: 0.4081\n",
      "Training for channel 21 of layer bn1\n",
      "Epoch 1/500, Loss: 0.6834, Train IoU: 0.0003\n",
      "Validation Loss: 0.6498, Validation IoU: 0.2252\n",
      "Epoch 500/500, Loss: 0.4345, Train IoU: 0.3922\n",
      "Validation Loss: 0.4163, Validation IoU: 0.4112\n",
      "Training for channel 61 of layer bn1\n",
      "Epoch 1/500, Loss: 0.6832, Train IoU: 0.0000\n",
      "Validation Loss: 0.6456, Validation IoU: 0.2252\n",
      "Epoch 500/500, Loss: 0.4752, Train IoU: 0.3669\n",
      "Validation Loss: 0.4610, Validation IoU: 0.3754\n",
      "Time taken for bn1: 230.20 seconds\n",
      "\n",
      "Processing layer: layer4.1.conv1 with channels [115]\n",
      "Training 500 epochs, with loss: Dice\n",
      "Training for channel 115 of layer layer4.1.conv1\n",
      "Epoch 1/500, Loss: 0.6909, Train IoU: 0.0002\n",
      "Validation Loss: 0.7211, Validation IoU: 0.0000\n",
      "Epoch 500/500, Loss: 0.6153, Train IoU: 0.2381\n",
      "Validation Loss: 0.6271, Validation IoU: 0.2291\n",
      "Time taken for layer4.1.conv1: 80.92 seconds\n",
      "Total time taken: 7828.46 seconds\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# File path of the saved JSON file\n",
    "best_layers = './dice-conv-probe/conv-probe-layers-results/top_k_iou_layers.json'\n",
    "\n",
    "# Read the JSON file back into a Python object\n",
    "with open(best_layers, 'r') as f:\n",
    "    top_k_iou_layers = json.load(f)\n",
    "\n",
    "\n",
    "# Convert channel indices to integers if they are strings\n",
    "top_k_iou_layers = [[layer, int(channel_idx), iou_metric] for layer, channel_idx, iou_metric in top_k_iou_layers]\n",
    "\n",
    "# Call the function with specific_layer_channel_pairs\n",
    "all_layers_iou_results = train_conv_probe_all_layers(\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    image_size=image_size,\n",
    "    device=device,\n",
    "    num_epochs=500, \n",
    "    lr=0.1,\n",
    "    loss_function='Dice',\n",
    "    specific_layer_channel_pairs=top_k_iou_layers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lavic-3080/Downloads/carlos/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/lavic-3080/Downloads/carlos/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/lavic-3080/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing layer: conv1 with 64 channels\n",
      "Training 2 epochs, with loss: Dice\n",
      "Training for channel 0 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6916, Train IoU: 0.0000\n",
      "Validation Loss: 0.6862, Validation IoU: 0.0000\n",
      "Epoch 2/2, Loss: 0.6907, Train IoU: 0.0000\n",
      "Validation Loss: 0.6811, Validation IoU: 0.0001\n",
      "Training for channel 1 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6723, Train IoU: 0.2328\n",
      "Validation Loss: 0.6678, Validation IoU: 0.2360\n",
      "Epoch 2/2, Loss: 0.6719, Train IoU: 0.2323\n",
      "Validation Loss: 0.6622, Validation IoU: 0.2405\n",
      "Training for channel 2 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6688, Train IoU: 0.2340\n",
      "Validation Loss: 0.6629, Validation IoU: 0.2383\n",
      "Epoch 2/2, Loss: 0.6681, Train IoU: 0.2332\n",
      "Validation Loss: 0.6570, Validation IoU: 0.2425\n",
      "Training for channel 3 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6737, Train IoU: 0.2337\n",
      "Validation Loss: 0.6696, Validation IoU: 0.2374\n",
      "Epoch 2/2, Loss: 0.6730, Train IoU: 0.2330\n",
      "Validation Loss: 0.6634, Validation IoU: 0.2423\n",
      "Training for channel 4 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6688, Train IoU: 0.2340\n",
      "Validation Loss: 0.6629, Validation IoU: 0.2383\n",
      "Epoch 2/2, Loss: 0.6681, Train IoU: 0.2332\n",
      "Validation Loss: 0.6570, Validation IoU: 0.2425\n",
      "Training for channel 5 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6688, Train IoU: 0.2340\n",
      "Validation Loss: 0.6629, Validation IoU: 0.2383\n",
      "Epoch 2/2, Loss: 0.6680, Train IoU: 0.2332\n",
      "Validation Loss: 0.6570, Validation IoU: 0.2425\n",
      "Training for channel 6 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6682, Train IoU: 0.2340\n",
      "Validation Loss: 0.6617, Validation IoU: 0.2383\n",
      "Epoch 2/2, Loss: 0.6672, Train IoU: 0.2332\n",
      "Validation Loss: 0.6555, Validation IoU: 0.2425\n",
      "Training for channel 7 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6688, Train IoU: 0.2340\n",
      "Validation Loss: 0.6629, Validation IoU: 0.2383\n",
      "Epoch 2/2, Loss: 0.6681, Train IoU: 0.2332\n",
      "Validation Loss: 0.6570, Validation IoU: 0.2425\n",
      "Training for channel 8 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6691, Train IoU: 0.2339\n",
      "Validation Loss: 0.6633, Validation IoU: 0.2382\n",
      "Epoch 2/2, Loss: 0.6684, Train IoU: 0.2332\n",
      "Validation Loss: 0.6574, Validation IoU: 0.2425\n",
      "Training for channel 9 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6688, Train IoU: 0.2340\n",
      "Validation Loss: 0.6629, Validation IoU: 0.2383\n",
      "Epoch 2/2, Loss: 0.6681, Train IoU: 0.2332\n",
      "Validation Loss: 0.6570, Validation IoU: 0.2425\n",
      "Training for channel 10 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6651, Train IoU: 0.2340\n",
      "Validation Loss: 0.6566, Validation IoU: 0.2383\n",
      "Epoch 2/2, Loss: 0.6632, Train IoU: 0.2332\n",
      "Validation Loss: 0.6490, Validation IoU: 0.2425\n",
      "Training for channel 11 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6660, Train IoU: 0.2338\n",
      "Validation Loss: 0.6581, Validation IoU: 0.2381\n",
      "Epoch 2/2, Loss: 0.6644, Train IoU: 0.2331\n",
      "Validation Loss: 0.6508, Validation IoU: 0.2423\n",
      "Training for channel 12 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6733, Train IoU: 0.2337\n",
      "Validation Loss: 0.6690, Validation IoU: 0.2375\n",
      "Epoch 2/2, Loss: 0.6724, Train IoU: 0.2330\n",
      "Validation Loss: 0.6627, Validation IoU: 0.2422\n",
      "Training for channel 13 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6688, Train IoU: 0.2340\n",
      "Validation Loss: 0.6629, Validation IoU: 0.2383\n",
      "Epoch 2/2, Loss: 0.6681, Train IoU: 0.2332\n",
      "Validation Loss: 0.6570, Validation IoU: 0.2425\n",
      "Training for channel 14 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6697, Train IoU: 0.2320\n",
      "Validation Loss: 0.6636, Validation IoU: 0.2345\n",
      "Epoch 2/2, Loss: 0.6688, Train IoU: 0.2314\n",
      "Validation Loss: 0.6575, Validation IoU: 0.2382\n",
      "Training for channel 15 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6684, Train IoU: 0.2340\n",
      "Validation Loss: 0.6621, Validation IoU: 0.2383\n",
      "Epoch 2/2, Loss: 0.6675, Train IoU: 0.2332\n",
      "Validation Loss: 0.6559, Validation IoU: 0.2425\n",
      "Training for channel 16 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6656, Train IoU: 0.2340\n",
      "Validation Loss: 0.6569, Validation IoU: 0.2383\n",
      "Epoch 2/2, Loss: 0.6637, Train IoU: 0.2332\n",
      "Validation Loss: 0.6493, Validation IoU: 0.2425\n",
      "Training for channel 17 of layer conv1\n",
      "Epoch 1/2, Loss: 0.6630, Train IoU: 0.2340\n",
      "Validation Loss: 0.6524, Validation IoU: 0.2383\n",
      "Epoch 2/2, Loss: 0.6603, Train IoU: 0.2332\n",
      "Validation Loss: 0.6436, Validation IoU: 0.2425\n",
      "Training for channel 18 of layer conv1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Call the training function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m all_layers_iou_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_conv_probe_all_layers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m, in \u001b[0;36mtrain_conv_probe_all_layers\u001b[0;34m(train_loader, test_loader, image_size, device, num_epochs, lr, loss_function, time_results_file)\u001b[0m\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mresnet18(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train the conv probe for the current layer\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m iou_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_conv_probe_all_channels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_function\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Save individual layer results\u001b[39;00m\n\u001b[1;32m     33\u001b[0m save_results_to_json(iou_results, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./conv-probe-layers-results/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_activation_results.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 48\u001b[0m, in \u001b[0;36mtrain_conv_probe_all_channels\u001b[0;34m(model, layer_name, num_channels, train_loader, test_loader, image_size, device, num_epochs, lr, single_channel, loss_function)\u001b[0m\n\u001b[1;32m     45\u001b[0m train_iou \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ensure masks are float type\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Downloads/carlos/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/Downloads/carlos/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Downloads/carlos/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/Downloads/carlos/lib/python3.12/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/mestrado-carlos/masters-degree/experiments/../data/vess-map/vess_map_dataset.py:104\u001b[0m, in \u001b[0;36mVessMapDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Apply transformations\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_transform_flag:\n\u001b[0;32m--> 104\u001b[0m     image, mask, skeleton \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskeleton\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# Convert to tensor without applying random transforms\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     image \u001b[38;5;241m=\u001b[39m TF\u001b[38;5;241m.\u001b[39mto_tensor(image)\n",
      "File \u001b[0;32m~/mestrado-carlos/masters-degree/experiments/../data/vess-map/vess_map_dataset.py:91\u001b[0m, in \u001b[0;36mVessMapDataset.apply_transform\u001b[0;34m(self, image, mask, skeleton)\u001b[0m\n\u001b[1;32m     88\u001b[0m skeleton \u001b[38;5;241m=\u001b[39m TF\u001b[38;5;241m.\u001b[39mcrop(skeleton, i, j, h, w)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Convert to tensor\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mTF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m mask \u001b[38;5;241m=\u001b[39m TF\u001b[38;5;241m.\u001b[39mto_tensor(mask)\n\u001b[1;32m     93\u001b[0m skeleton \u001b[38;5;241m=\u001b[39m TF\u001b[38;5;241m.\u001b[39mto_tensor(skeleton)\n",
      "File \u001b[0;32m~/Downloads/carlos/lib/python3.12/site-packages/torchvision/transforms/functional.py:174\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    172\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mview(pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m], pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m], F_pil\u001b[38;5;241m.\u001b[39mget_image_num_channels(pic))\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mdefault_float_dtype)\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Call the training function\n",
    "all_layers_iou_results = train_conv_probe_all_layers(\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    image_size=image_size,\n",
    "    device=device,\n",
    "    num_epochs=200,\n",
    "    lr=0.01,\n",
    "    loss_function = \"Dice\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' import segmentation_models_pytorch as smp\\n\\ndef train_unet_model(train_loader, val_loader, device, num_epochs=50, lr=0.001):\\n    # Define the model\\n    model = smp.Unet(\\n        encoder_name=\"resnet18\",        # Choose encoder, e.g. resnet18\\n        encoder_weights=None,           # Use NONE pre-trained weights for encoderFalse\\n        in_channels=3,                  # Input channels (3 for RGB images)\\n        classes=1,                      # Output channels (1 for binary segmentation)\\n        activation=None                 # No activation function on output\\n    )\\n    model.to(device)\\n\\n    # Define loss function\\n    criterion = nn.BCEWithLogitsLoss()\\n\\n    # Define optimizer\\n    optimizer = optim.Adam(model.parameters(), lr=lr)\\n\\n    # Training loop\\n    for epoch in range(num_epochs):\\n        model.train()\\n        running_loss = 0.0\\n\\n        for inputs, masks, _ in train_loader:\\n            inputs = inputs.to(device)\\n            masks = masks.to(device).float()\\n\\n            optimizer.zero_grad()\\n\\n            outputs = model(inputs)\\n            outputs = outputs.squeeze(1)\\n            masks = masks.squeeze(1)\\n\\n            loss = criterion(outputs, masks)\\n            loss.backward()\\n            optimizer.step()\\n\\n            running_loss += loss.item() * inputs.size(0)\\n\\n        epoch_loss = running_loss / len(train_loader.dataset)\\n        print(f\\'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\\')\\n\\n        # You can add validation and metric calculation similar to previous code\\n\\n    # Save the trained model\\n    torch.save(model.state_dict(), \\'./models/conv_probe_unet_vess_map.pth\\')\\n\\n    return model\\n\\nunet_model = train_unet_model(train_loader=train_loader, val_loader=test_loader, device=device, num_epochs=200, lr=0.001) '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import segmentation_models_pytorch as smp\n",
    "\n",
    "def train_unet_model(train_loader, val_loader, device, num_epochs=50, lr=0.001):\n",
    "    # Define the model\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet18\",        # Choose encoder, e.g. resnet18\n",
    "        encoder_weights=None,           # Use NONE pre-trained weights for encoderFalse\n",
    "        in_channels=3,                  # Input channels (3 for RGB images)\n",
    "        classes=1,                      # Output channels (1 for binary segmentation)\n",
    "        activation=None                 # No activation function on output\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    # Define loss function\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, masks, _ in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            masks = masks.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze(1)\n",
    "            masks = masks.squeeze(1)\n",
    "\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        # You can add validation and metric calculation similar to previous code\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), './models/conv_probe_unet_vess_map.pth')\n",
    "\n",
    "    return model\n",
    "\n",
    "unet_model = train_unet_model(train_loader=train_loader, val_loader=test_loader, device=device, num_epochs=200, lr=0.001) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" layer_name = 'decoder.blocks.4.conv2.0' #TODO: check if this is the best layer to test, the results are OK\\n\\nnum_channels = 16\\n\\n# Initialize ConvProbe with the UNet model\\niou_results = train_conv_probe_all_channels(\\n            model=unet_model,\\n            layer_name=layer_name,\\n            num_channels=num_channels,\\n            train_loader=train_loader,\\n            test_loader=test_loader,\\n            image_size=image_size,\\n            device=device,\\n            num_epochs=100,\\n            lr=0.001,\\n            single_channel=False) \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" layer_name = 'decoder.blocks.4.conv2.0' #TODO: check if this is the best layer to test, the results are OK\n",
    "\n",
    "num_channels = 16\n",
    "\n",
    "# Initialize ConvProbe with the UNet model\n",
    "iou_results = train_conv_probe_all_channels(\n",
    "            model=unet_model,\n",
    "            layer_name=layer_name,\n",
    "            num_channels=num_channels,\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            image_size=image_size,\n",
    "            device=device,\n",
    "            num_epochs=100,\n",
    "            lr=0.001,\n",
    "            single_channel=False) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carlos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
