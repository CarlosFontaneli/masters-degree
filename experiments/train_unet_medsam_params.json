{
  "unet_train": [
    {
      "train_size": 5,
      "epochs": 500,
      "lr": 0.001,
      "batch_size": 5,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "none",
      "augment": true,
      "image_size": 256,
      "accumulate_grad_steps": 1
    },
    {
      "train_size": 25,
      "epochs": 500,
      "lr": 0.001,
      "batch_size": 25,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "none",
      "augment": true,
      "image_size": 256,
      "accumulate_grad_steps": 1
    },
    {
      "train_size": 50,
      "epochs": 500,
      "lr": 0.001,
      "batch_size": 50,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "none",
      "augment": true,
      "image_size": 256,
      "accumulate_grad_steps": 1
    },
    {
      "train_size": 75,
      "epochs": 500,
      "lr": 0.001,
      "batch_size": 75,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "none",
      "augment": true,
      "image_size": 256,
      "accumulate_grad_steps": 1
    },
    {
      "train_size": 80,
      "epochs": 500,
      "lr": 0.001,
      "batch_size": 4,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "none",
      "augment": true,
      "image_size": 256,
      "accumulate_grad_steps": 1
    },
    {
      "train_size": 95,
      "epochs": 500,
      "lr": 0.001,
      "batch_size": 95,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "none",
      "augment": true,
      "image_size": 256,
      "accumulate_grad_steps": 1
    },
    {
      "train_size": 5,
      "epochs": 500,
      "lr": 0.01,
      "batch_size": 5,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "none",
      "augment": true,
      "image_size": 256,
      "accumulate_grad_steps": 1
    },
    {
      "train_size": 25,
      "epochs": 500,
      "lr": 0.01,
      "batch_size": 25,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "none",
      "augment": true,
      "image_size": 256,
      "accumulate_grad_steps": 1
    },
    {
      "train_size": 50,
      "epochs": 500,
      "lr": 0.01,
      "batch_size": 50,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "none",
      "augment": true,
      "image_size": 256,
      "accumulate_grad_steps": 1
    },
    {
      "train_size": 75,
      "epochs": 500,
      "lr": 0.01,
      "batch_size": 75,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "none",
      "augment": true,
      "image_size": 256,
      "accumulate_grad_steps": 1
    },
    {
      "train_size": 80,
      "epochs": 500,
      "lr": 0.01,
      "batch_size": 4,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "none",
      "augment": true,
      "image_size": 256,
      "accumulate_grad_steps": 1
    },
    {
      "train_size": 95,
      "epochs": 500,
      "lr": 0.01,
      "batch_size": 95,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "none",
      "augment": true,
      "image_size": 256,
      "accumulate_grad_steps": 1
    }
  ],
  "medsam_fine_tune": [
    {
      "train_size": 5,
      "epochs": 500,
      "lr": 0.001,
      "batch_size": 2,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "cosine",
      "augment": true,
      "accumulate_grad_steps": 1,
      "precision": "32-true"
    },
    {
      "train_size": 25,
      "epochs": 500,
      "lr": 0.001,
      "batch_size": 2,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "cosine",
      "augment": true,
      "accumulate_grad_steps": 1,
      "precision": "32-true"
    },
    {
      "train_size": 50,
      "epochs": 500,
      "lr": 0.001,
      "batch_size": 2,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "cosine",
      "augment": true,
      "accumulate_grad_steps": 1,
      "precision": "32-true"
    },
    {
      "train_size": 75,
      "epochs": 500,
      "lr": 0.001,
      "batch_size": 2,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "cosine",
      "augment": true,
      "accumulate_grad_steps": 1,
      "precision": "32-true"
    },
    {
      "train_size": 80,
      "epochs": 500,
      "lr": 0.001,
      "batch_size": 2,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "cosine",
      "augment": true,
      "accumulate_grad_steps": 1,
      "precision": "32-true"
    },
    {
      "train_size": 95,
      "epochs": 500,
      "lr": 0.001,
      "batch_size": 2,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "cosine",
      "augment": true,
      "accumulate_grad_steps": 1,
      "precision": "32-true"
    },
    {
      "train_size": 5,
      "epochs": 500,
      "lr": 0.01,
      "batch_size": 2,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "cosine",
      "augment": true,
      "accumulate_grad_steps": 1,
      "precision": "32-true"
    },
    {
      "train_size": 25,
      "epochs": 500,
      "lr": 0.01,
      "batch_size": 2,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "cosine",
      "augment": true,
      "accumulate_grad_steps": 1,
      "precision": "32-true"
    },
    {
      "train_size": 50,
      "epochs": 500,
      "lr": 0.01,
      "batch_size": 2,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "cosine",
      "augment": true,
      "accumulate_grad_steps": 1,
      "precision": "32-true"
    },
    {
      "train_size": 75,
      "epochs": 500,
      "lr": 0.01,
      "batch_size": 2,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "cosine",
      "augment": true,
      "accumulate_grad_steps": 1,
      "precision": "32-true"
    },
    {
      "train_size": 80,
      "epochs": 500,
      "lr": 0.01,
      "batch_size": 2,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "cosine",
      "augment": true,
      "accumulate_grad_steps": 1,
      "precision": "32-true"
    },
    {
      "train_size": 95,
      "epochs": 500,
      "lr": 0.01,
      "batch_size": 2,
      "optimizer": "adam",
      "loss_type": "both",
      "scheduler": "cosine",
      "augment": true,
      "accumulate_grad_steps": 1,
      "precision": "32-true"
    }
  ]
}
