{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fonta42/Desktop/masters-degree/U-Mamba/umamba/nnunetv2/nets/UMambaEnc_2d.py:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Import U-Mamba modules (assume nnunetv2 and dynamic_network_architectures are in PYTHONPATH)\n",
    "from nnunetv2.nets.UMambaEnc_2d import get_umamba_enc_2d_from_plans\n",
    "from nnunetv2.utilities.plans_handling.plans_handler import ConfigurationManager, PlansManager\n",
    "from dynamic_network_architectures.building_blocks.helper import convert_dim_to_conv_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Definition\n",
    "class VessMapDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, skeleton_dir, image_size, mode='train', apply_transform=False):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.skeleton_dir = skeleton_dir\n",
    "        self.image_size = image_size\n",
    "        self.mode = mode\n",
    "        self.apply_transform_flag = apply_transform\n",
    "        self.class_weights_tensor = torch.tensor([0.26, 0.74])\n",
    "\n",
    "        # List all image files with .tiff or .tif extension\n",
    "        self.image_files = [f for f in os.listdir(self.image_dir) if f.endswith('.tiff') or f.endswith('.tif')]\n",
    "        self.image_files.sort()\n",
    "\n",
    "        # Find matching pairs of images, masks, and skeletons\n",
    "        self.pairs = []\n",
    "        for img_file in self.image_files:\n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            mask_file = base_name + \".png\"\n",
    "            skeleton_file = base_name + \".png\"\n",
    "\n",
    "            mask_path = os.path.join(self.mask_dir, mask_file)\n",
    "            skeleton_path = os.path.join(self.skeleton_dir, skeleton_file)\n",
    "\n",
    "            if os.path.exists(mask_path) and os.path.exists(skeleton_path):\n",
    "                self.pairs.append((img_file, mask_file, skeleton_file))\n",
    "            else:\n",
    "                print(f\"Warning: Missing mask or skeleton for image {img_file}\")\n",
    "\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.skeletons = []\n",
    "        for img_file, mask_file, skeleton_file in self.pairs:\n",
    "            image_path = os.path.join(self.image_dir, img_file)\n",
    "            mask_path = os.path.join(self.mask_dir, mask_file)\n",
    "            skeleton_path = os.path.join(self.skeleton_dir, skeleton_file)\n",
    "\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            mask = Image.open(mask_path).convert('L')\n",
    "            skeleton = Image.open(skeleton_path).convert('L')\n",
    "\n",
    "            self.images.append(image)\n",
    "            self.labels.append(mask)\n",
    "            self.skeletons.append(skeleton)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def apply_transform(self, image, mask, skeleton, seed=42):\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            mask = TF.hflip(mask)\n",
    "            skeleton = TF.hflip(skeleton)\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.vflip(image)\n",
    "            mask = TF.vflip(mask)\n",
    "            skeleton = TF.vflip(skeleton)\n",
    "        angle = random.uniform(-30, 30)\n",
    "        image = TF.rotate(image, angle)\n",
    "        mask = TF.rotate(mask, angle)\n",
    "        skeleton = TF.rotate(skeleton, angle)\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(image, output_size=(self.image_size, self.image_size))\n",
    "        image = TF.crop(image, i, j, h, w)\n",
    "        mask = TF.crop(mask, i, j, h, w)\n",
    "        skeleton = TF.crop(skeleton, i, j, h, w)\n",
    "        image = TF.to_tensor(image)\n",
    "        mask = TF.to_tensor(mask)\n",
    "        skeleton = TF.to_tensor(skeleton)\n",
    "        return image, mask, skeleton\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.labels[idx]\n",
    "        skeleton = self.skeletons[idx]\n",
    "        if self.mode == 'train' and self.apply_transform_flag:\n",
    "            image, mask, skeleton = self.apply_transform(image, mask, skeleton)\n",
    "        else:\n",
    "            image = TF.to_tensor(image)\n",
    "            mask = TF.to_tensor(mask)\n",
    "            skeleton = TF.to_tensor(skeleton)\n",
    "        return image, mask, skeleton\n",
    "\n",
    "    def vess_map_dataloader(self, batch_size, train_size, shuffle=True):\n",
    "        dataset_size = len(self)\n",
    "        train_len = int(train_size * dataset_size)\n",
    "        indices = list(range(dataset_size))\n",
    "        train_indices = indices[:train_len]\n",
    "        test_indices = indices[train_len:]\n",
    "        train_dataset = Subset(VessMapDataset(self.image_dir, self.mask_dir, self.skeleton_dir, self.image_size, mode='train', apply_transform=self.apply_transform_flag), train_indices)\n",
    "        test_dataset = Subset(VessMapDataset(self.image_dir, self.mask_dir, self.skeleton_dir, self.image_size, mode='test', apply_transform=False), test_indices)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging Utilities\n",
    "LOG_RECORDS = []\n",
    "def log_message(level, message):\n",
    "    logger = logging.getLogger(\"UMamba_Training\")\n",
    "    logger.log(level, message)\n",
    "    LOG_RECORDS.append({\n",
    "        \"level\": logging.getLevelName(level),\n",
    "        \"message\": message,\n",
    "        \"time\": datetime.datetime.now().isoformat()\n",
    "    })\n",
    "\n",
    "# -------------------------------\n",
    "# Dice Metric\n",
    "# -------------------------------\n",
    "def compute_dice(preds, targets):\n",
    "    preds = preds.long()\n",
    "    targets = targets.long()\n",
    "    intersection = (preds & targets).sum(dim=(2, 3))\n",
    "    dice = (2.0 * intersection.float()) / (preds.sum(dim=(2, 3)) + targets.sum(dim=(2, 3)) + 1e-6)\n",
    "    return dice.mean().item()\n",
    "\n",
    "# -------------------------------\n",
    "# Difference Mask Visualization\n",
    "# -------------------------------\n",
    "def create_difference_mask(bin_preds, bin_targets):\n",
    "    b, _, h, w = bin_preds.shape\n",
    "    diff_masks = np.zeros((b, h, w, 3), dtype=np.uint8)\n",
    "    for idx in range(b):\n",
    "        bin_pred = bin_preds[idx, 0]\n",
    "        bin_tgt  = bin_targets[idx, 0]\n",
    "        tp = (bin_pred == 1) & (bin_tgt == 1)\n",
    "        fp = (bin_pred == 1) & (bin_tgt == 0)\n",
    "        fn = (bin_pred == 0) & (bin_tgt == 1)\n",
    "        diff_masks[idx][tp] = [0, 255, 0]       # Green\n",
    "        diff_masks[idx][fp] = [255, 255, 0]       # Yellow\n",
    "        diff_masks[idx][fn] = [255, 0, 0]         # Red\n",
    "    return diff_masks\n",
    "\n",
    "def save_comparison_plot(original_img, bin_pred, diff_mask, epoch, batch_idx, model_name):\n",
    "    if torch.is_tensor(original_img):\n",
    "        original_img = original_img.cpu().numpy()\n",
    "    if torch.is_tensor(bin_pred):\n",
    "        bin_pred = bin_pred.cpu().numpy()\n",
    "    original_img = np.transpose(original_img, (1, 2, 0))\n",
    "    output_dir = os.path.join(\"umamba\", \"validation-diff-masks\", f\"{model_name}_validation-diff-masks\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    axs[0].imshow(original_img, cmap=\"gray\") \n",
    "    axs[0].set_title(\"Original Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[1].imshow(bin_pred, cmap=\"gray\")\n",
    "    axs[1].set_title(\"Prediction\")\n",
    "    axs[1].axis(\"off\")\n",
    "    axs[2].imshow(diff_mask)\n",
    "    axs[2].set_title(\"Diff Mask\")\n",
    "    axs[2].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(output_dir, f\"comparison_epoch{epoch}_batch{batch_idx}.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "# -------------------------------\n",
    "# Loss Functions\n",
    "# -------------------------------\n",
    "def dice_loss(pred_logits, target):\n",
    "    # Upsample predictions if needed to match target spatial dimensions.\n",
    "    if pred_logits.shape[-2:] != target.shape[-2:]:\n",
    "        pred_logits = F.interpolate(pred_logits, size=target.shape[-2:], mode='bilinear', align_corners=False)\n",
    "    pred_prob = torch.sigmoid(pred_logits)\n",
    "    pred_bin = (pred_prob > 0.5).float()\n",
    "    target = target.float()\n",
    "    intersection = torch.sum(pred_bin * target)\n",
    "    union = torch.sum(pred_bin) + torch.sum(target)\n",
    "    dice_coeff = (2.0 * intersection + 1e-8) / (union + 1e-8)\n",
    "    return 1.0 - dice_coeff\n",
    "\n",
    "def ce_loss_wrapper(pred, target):\n",
    "    # Upsample pred if its spatial dimensions do not match the target's\n",
    "    if pred.shape[-2:] != target.shape[-2:]:\n",
    "        pred = F.interpolate(pred, size=target.shape[-2:], mode='bilinear', align_corners=False)\n",
    "    return F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "\n",
    "def compute_loss(preds, masks, seg_loss_func, ce_loss_func, loss_type):\n",
    "    # If preds is a list (deep supervision), compute loss on each output and average.\n",
    "    if isinstance(preds, list):\n",
    "        loss_total = 0.0\n",
    "        for pred in preds:\n",
    "            if loss_type == \"dice\":\n",
    "                loss_total += seg_loss_func(pred, masks)\n",
    "            elif loss_type == \"ce\":\n",
    "                loss_total += ce_loss_wrapper(pred, masks.float())\n",
    "            elif loss_type == \"both\":\n",
    "                loss_total += seg_loss_func(pred, masks) + ce_loss_wrapper(pred, masks.float())\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown loss type: {loss_type}\")\n",
    "        return loss_total / len(preds)\n",
    "    else:\n",
    "        if loss_type == \"dice\":\n",
    "            return seg_loss_func(preds, masks)\n",
    "        elif loss_type == \"ce\":\n",
    "            return ce_loss_wrapper(preds, masks.float())\n",
    "        elif loss_type == \"both\":\n",
    "            return seg_loss_func(preds, masks) + ce_loss_wrapper(preds, masks.float())\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown loss type: {loss_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Loops\n",
    "def train_one_epoch(model, dataloader, device, optimizer, seg_loss_func, ce_loss_func, loss_type, accumulate_grad_steps=1, clip_grad=True):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    step_count = 0\n",
    "    for step, (images, masks, _) in enumerate(tqdm(dataloader, desc=\"Training\")):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        preds = model(images)\n",
    "        loss = compute_loss(preds, masks, seg_loss_func, ce_loss_func, loss_type)\n",
    "        loss.backward()\n",
    "        if (step + 1) % accumulate_grad_steps == 0:\n",
    "            if clip_grad:\n",
    "                clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "        step_count += 1\n",
    "    return running_loss / step_count\n",
    "\n",
    "def validate(model, dataloader, device, seg_loss_func, ce_loss_func, loss_type, epoch=0, model_name=\"default_model\"):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_dice = 0.0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, masks, _) in enumerate(tqdm(dataloader, desc=\"Validating\")):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            preds = model(images)\n",
    "            loss = compute_loss(preds, masks, seg_loss_func, ce_loss_func, loss_type)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # If deep supervision returns a list, choose one output (e.g. the last)\n",
    "            if isinstance(preds, list):\n",
    "                pred_eval = preds[-1]\n",
    "            else:\n",
    "                pred_eval = preds\n",
    "\n",
    "            # Upsample pred_eval if needed\n",
    "            if pred_eval.shape[-2:] != masks.shape[-2:]:\n",
    "                pred_eval = torch.nn.functional.interpolate(pred_eval, size=masks.shape[-2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "            probs = torch.sigmoid(pred_eval)\n",
    "            bin_preds = (probs > 0.5).float()\n",
    "            bin_masks = (masks > 0.5).float()\n",
    "            dice_value = compute_dice(bin_preds, bin_masks)\n",
    "            val_dice += dice_value\n",
    "            count += 1\n",
    "\n",
    "        if epoch % 50 == 0 and epoch != 0:\n",
    "            # For visualization, again use the last output\n",
    "            if isinstance(preds, list):\n",
    "                pred_vis = preds[-1]\n",
    "            else:\n",
    "                pred_vis = preds\n",
    "            if pred_vis.shape[-2:] != masks.shape[-2:]:\n",
    "                pred_vis = torch.nn.functional.interpolate(pred_vis, size=masks.shape[-2:], mode='bilinear', align_corners=False)\n",
    "            probs_vis = torch.sigmoid(pred_vis)\n",
    "            bin_preds_vis = (probs_vis > 0.5).float()\n",
    "            diff_masks = create_difference_mask(bin_preds_vis.cpu().numpy(), (masks > 0.5).float().cpu().numpy())\n",
    "            first_original = images[0]\n",
    "            first_bin_pred = bin_preds_vis[0, 0]\n",
    "            first_diff_mask = diff_masks[0]\n",
    "            save_comparison_plot(\n",
    "                original_img=first_original, \n",
    "                bin_pred=first_bin_pred, \n",
    "                diff_mask=first_diff_mask, \n",
    "                epoch=epoch, \n",
    "                batch_idx=batch_idx,\n",
    "                model_name=model_name\n",
    "            )\n",
    "    return val_loss / count, val_dice / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Training Routine for U-Mamba\n",
    "def train_umamba(model, args):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    log_message(logging.INFO, \"Preparing dataset...\")\n",
    "    vess_dataset = VessMapDataset(\n",
    "        image_dir=args.image_dir,\n",
    "        mask_dir=args.mask_dir,\n",
    "        skeleton_dir=args.skeleton_dir,\n",
    "        image_size=args.image_size,\n",
    "        apply_transform=args.augment\n",
    "    )\n",
    "    train_loader, test_loader = vess_dataset.vess_map_dataloader(batch_size=args.batch_size, train_size=args.train_size / 100)\n",
    "    ce_loss_func = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "    seg_loss_func = dice_loss  # using our dice_loss as segmentation loss\n",
    "    if args.optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\n",
    "    elif args.optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown optimizer choice. Choose from ['sgd', 'adam'].\")\n",
    "    if args.scheduler == \"cosine\":\n",
    "        num_steps = args.epochs * len(train_loader)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_steps)\n",
    "    else:\n",
    "        scheduler = None\n",
    "    log_message(logging.INFO, \"Training parameters:\")\n",
    "    for arg_name, val in vars(args).items():\n",
    "        log_message(logging.INFO, f\" - {arg_name}: {val}\")\n",
    "    now = datetime.datetime.now()\n",
    "    date_str = now.strftime(\"%d%m%Y\")\n",
    "    model_name = f\"umamba_{args.optimizer}_lr{args.lr}_bs{args.batch_size}_{args.loss_type}_{args.train_size}pct_{date_str}\"\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_dices = []\n",
    "    best_loss = float(\"inf\")\n",
    "    for epoch in range(args.epochs):\n",
    "        log_message(logging.INFO, f\"Starting epoch {epoch+1}/{args.epochs}\")\n",
    "        train_loss = train_one_epoch(model=model, dataloader=train_loader, device=device, optimizer=optimizer, seg_loss_func=seg_loss_func, ce_loss_func=ce_loss_func, loss_type=args.loss_type, accumulate_grad_steps=args.accumulate_grad_steps, clip_grad=True)\n",
    "        train_losses.append(train_loss)\n",
    "        val_loss, val_dice = validate(model=model, dataloader=test_loader, device=device, seg_loss_func=seg_loss_func, ce_loss_func=ce_loss_func, loss_type=args.loss_type, epoch=epoch, model_name=model_name)\n",
    "        val_losses.append(val_loss)\n",
    "        val_dices.append(val_dice)\n",
    "        log_message(logging.INFO, f\"Epoch {epoch+1:02d}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}\")\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            os.makedirs(\"./umamba/models\", exist_ok=True)\n",
    "            torch.save(model.state_dict(), f\"./umamba/models/{model_name}_best.pth\")\n",
    "            log_message(logging.INFO, f\"Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}\")\n",
    "        torch.save(model.state_dict(), f\"./umamba/models/{model_name}_latest.pth\")\n",
    "    metrics = {\n",
    "        \"train_losses\": train_losses,\n",
    "        \"val_losses\": val_losses,\n",
    "        \"val_dices\": val_dices,\n",
    "    }\n",
    "    os.makedirs(\"./umamba/metrics\", exist_ok=True)\n",
    "    with open(f\"./umamba/metrics/{model_name}_metrics.json\", \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "    log_message(logging.INFO, f\"Metrics saved to ./umamba/metrics/{model_name}_metrics.json\")\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss', color='tab:blue')\n",
    "    l1 = ax1.plot(range(1, args.epochs+1), train_losses, label='Train Loss', color='tab:blue', linestyle='-')\n",
    "    l2 = ax1.plot(range(1, args.epochs+1), val_losses, label='Val Loss', color='tab:blue', linestyle='--')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Val Dice', color='tab:red')\n",
    "    l3 = ax2.plot(range(1, args.epochs+1), val_dices, label='Val Dice', color='tab:red', linestyle='-')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "    lines = l1 + l2 + l3\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax1.legend(lines, labels, loc='upper center')\n",
    "    plt.title('Training & Validation Loss and Dice Over Epochs')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"./umamba/metrics/{model_name}_training_validation_metrics.png\")\n",
    "    plt.close(fig)\n",
    "    log_message(logging.INFO, f\"Plot saved to ./umamba/metrics/{model_name}_training_validation_metrics.png\")\n",
    "    os.makedirs(\"./umamba/logs\", exist_ok=True)\n",
    "    with open(f\"./umamba/logs/{model_name}_logs.json\", \"w\") as f:\n",
    "        json.dump(LOG_RECORDS, f, indent=4)\n",
    "    log_message(logging.INFO, f\"Logs saved to ./umamba/logs/{model_name}_logs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_map_sizes: [[256, 256], [128, 128], [64, 64], [32, 32]]\n",
      "do_channel_token: [False, False, False, False]\n",
      "MambaLayer: dim: 64\n",
      "MambaLayer: dim: 256\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/fonta42/Desktop/masters-degree/U-Mamba')\n",
    "from umamba.nnunetv2.nets.UMambaEnc_2d import UMambaEnc\n",
    "from dynamic_network_architectures.building_blocks.helper import convert_dim_to_conv_op\n",
    "\n",
    "# Define your model parameters manually:\n",
    "input_size = (256, 256)            # Input patch size\n",
    "input_channels = 3                 # RGB images\n",
    "n_stages = 4                       # Number of stages in the encoder/decoder\n",
    "features_per_stage = [32, 64, 128, 256]  # Feature channels per stage\n",
    "kernel_sizes = [[3, 3]] * n_stages       # 3x3 convolutions at each stage\n",
    "# Define strides (e.g., no downsampling at first stage, then downsample by factor of 2)\n",
    "strides = [[1, 1], [2, 2], [2, 2], [2, 2]]\n",
    "n_conv_per_stage = 2               # Number of convolutional blocks per encoder stage\n",
    "n_conv_per_stage_decoder = 2       # Number of convolutional blocks per decoder stage\n",
    "num_classes = 1                    # For binary segmentation\n",
    "conv_op = nn.Conv2d               # Use standard 2D convolutions\n",
    "norm_op = nn.InstanceNorm2d       # InstanceNorm is commonly used\n",
    "norm_op_kwargs = {'eps': 1e-5, 'affine': True}\n",
    "nonlin = nn.LeakyReLU             # Activation function\n",
    "nonlin_kwargs = {'inplace': True}\n",
    "deep_supervision = True           # If you want deep supervision from the decoder\n",
    "stem_channels = features_per_stage[0]  # The stem uses the first stage's feature count\n",
    "\n",
    "# Create the U-Mamba model instance directly:\n",
    "model = UMambaEnc(\n",
    "    input_size=input_size,\n",
    "    input_channels=input_channels,\n",
    "    n_stages=n_stages,\n",
    "    features_per_stage=features_per_stage,\n",
    "    conv_op=conv_op,\n",
    "    kernel_sizes=kernel_sizes,\n",
    "    strides=strides,\n",
    "    n_conv_per_stage=n_conv_per_stage,\n",
    "    num_classes=num_classes,\n",
    "    n_conv_per_stage_decoder=n_conv_per_stage_decoder,\n",
    "    conv_bias=True,\n",
    "    norm_op=norm_op,\n",
    "    norm_op_kwargs=norm_op_kwargs,\n",
    "    dropout_op=None,\n",
    "    dropout_op_kwargs=None,\n",
    "    nonlin=nonlin,\n",
    "    nonlin_kwargs=nonlin_kwargs,\n",
    "    deep_supervision=deep_supervision,\n",
    "    stem_channels=stem_channels\n",
    ")\n",
    "\n",
    "# Move the model to your device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:14:44,730 - UMamba_Training - INFO - Preparing dataset...\n",
      "2025-02-27 10:14:45,041 - UMamba_Training - INFO - Training parameters:\n",
      "2025-02-27 10:14:45,041 - UMamba_Training - INFO -  - lr: 0.001\n",
      "2025-02-27 10:14:45,042 - UMamba_Training - INFO -  - batch_size: 8\n",
      "2025-02-27 10:14:45,042 - UMamba_Training - INFO -  - epochs: 50\n",
      "2025-02-27 10:14:45,042 - UMamba_Training - INFO -  - optimizer: adam\n",
      "2025-02-27 10:14:45,043 - UMamba_Training - INFO -  - loss_type: both\n",
      "2025-02-27 10:14:45,043 - UMamba_Training - INFO -  - scheduler: none\n",
      "2025-02-27 10:14:45,043 - UMamba_Training - INFO -  - train_size: 80\n",
      "2025-02-27 10:14:45,044 - UMamba_Training - INFO -  - image_size: 256\n",
      "2025-02-27 10:14:45,044 - UMamba_Training - INFO -  - accumulate_grad_steps: 1\n",
      "2025-02-27 10:14:45,044 - UMamba_Training - INFO -  - image_dir: ../../data/vess-map/images\n",
      "2025-02-27 10:14:45,044 - UMamba_Training - INFO -  - mask_dir: ../../data/vess-map/labels\n",
      "2025-02-27 10:14:45,045 - UMamba_Training - INFO -  - skeleton_dir: ../../data/vess-map/skeletons\n",
      "2025-02-27 10:14:45,045 - UMamba_Training - INFO -  - augment: True\n",
      "2025-02-27 10:14:45,045 - UMamba_Training - INFO - Starting epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.80it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:14:48,843 - UMamba_Training - INFO - Epoch 01, Train Loss: 0.8750, Val Loss: 0.6447, Val Dice: 0.7387\n",
      "2025-02-27 10:14:48,873 - UMamba_Training - INFO - Best model saved at epoch 1 with val_loss 0.6447\n",
      "2025-02-27 10:14:48,901 - UMamba_Training - INFO - Starting epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  3.33it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:14:52,123 - UMamba_Training - INFO - Epoch 02, Train Loss: 0.4342, Val Loss: 0.5737, Val Dice: 0.7675\n",
      "2025-02-27 10:14:52,155 - UMamba_Training - INFO - Best model saved at epoch 2 with val_loss 0.5737\n",
      "2025-02-27 10:14:52,189 - UMamba_Training - INFO - Starting epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  3.30it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:14:55,437 - UMamba_Training - INFO - Epoch 03, Train Loss: 0.3607, Val Loss: 0.5278, Val Dice: 0.7923\n",
      "2025-02-27 10:14:55,469 - UMamba_Training - INFO - Best model saved at epoch 3 with val_loss 0.5278\n",
      "2025-02-27 10:14:55,501 - UMamba_Training - INFO - Starting epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  3.28it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 13.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:14:58,778 - UMamba_Training - INFO - Epoch 04, Train Loss: 0.3233, Val Loss: 0.4853, Val Dice: 0.8149\n",
      "2025-02-27 10:14:58,811 - UMamba_Training - INFO - Best model saved at epoch 4 with val_loss 0.4853\n",
      "2025-02-27 10:14:58,845 - UMamba_Training - INFO - Starting epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  3.25it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 14.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:02,147 - UMamba_Training - INFO - Epoch 05, Train Loss: 0.3030, Val Loss: 0.4358, Val Dice: 0.8267\n",
      "2025-02-27 10:15:02,179 - UMamba_Training - INFO - Best model saved at epoch 5 with val_loss 0.4358\n",
      "2025-02-27 10:15:02,211 - UMamba_Training - INFO - Starting epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  3.22it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 13.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:05,546 - UMamba_Training - INFO - Epoch 06, Train Loss: 0.2984, Val Loss: 0.4138, Val Dice: 0.8317\n",
      "2025-02-27 10:15:05,580 - UMamba_Training - INFO - Best model saved at epoch 6 with val_loss 0.4138\n",
      "2025-02-27 10:15:05,614 - UMamba_Training - INFO - Starting epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  3.17it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:08,998 - UMamba_Training - INFO - Epoch 07, Train Loss: 0.2803, Val Loss: 0.4022, Val Dice: 0.8428\n",
      "2025-02-27 10:15:09,030 - UMamba_Training - INFO - Best model saved at epoch 7 with val_loss 0.4022\n",
      "2025-02-27 10:15:09,062 - UMamba_Training - INFO - Starting epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  3.12it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 13.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:12,497 - UMamba_Training - INFO - Epoch 08, Train Loss: 0.2767, Val Loss: 0.3785, Val Dice: 0.8449\n",
      "2025-02-27 10:15:12,530 - UMamba_Training - INFO - Best model saved at epoch 8 with val_loss 0.3785\n",
      "2025-02-27 10:15:12,564 - UMamba_Training - INFO - Starting epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  3.11it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:16,011 - UMamba_Training - INFO - Epoch 09, Train Loss: 0.2636, Val Loss: 0.3772, Val Dice: 0.8441\n",
      "2025-02-27 10:15:16,043 - UMamba_Training - INFO - Best model saved at epoch 9 with val_loss 0.3772\n",
      "2025-02-27 10:15:16,076 - UMamba_Training - INFO - Starting epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  3.09it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 13.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:19,544 - UMamba_Training - INFO - Epoch 10, Train Loss: 0.2571, Val Loss: 0.3597, Val Dice: 0.8445\n",
      "2025-02-27 10:15:19,579 - UMamba_Training - INFO - Best model saved at epoch 10 with val_loss 0.3597\n",
      "2025-02-27 10:15:19,614 - UMamba_Training - INFO - Starting epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  3.07it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:23,108 - UMamba_Training - INFO - Epoch 11, Train Loss: 0.2570, Val Loss: 0.3729, Val Dice: 0.8410\n",
      "2025-02-27 10:15:23,142 - UMamba_Training - INFO - Starting epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  3.07it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:26,636 - UMamba_Training - INFO - Epoch 12, Train Loss: 0.2527, Val Loss: 0.3616, Val Dice: 0.8474\n",
      "2025-02-27 10:15:26,669 - UMamba_Training - INFO - Starting epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  3.05it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 13.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:30,187 - UMamba_Training - INFO - Epoch 13, Train Loss: 0.2448, Val Loss: 0.3724, Val Dice: 0.8393\n",
      "2025-02-27 10:15:30,220 - UMamba_Training - INFO - Starting epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  3.01it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 13.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:33,779 - UMamba_Training - INFO - Epoch 14, Train Loss: 0.2367, Val Loss: 0.3619, Val Dice: 0.8428\n",
      "2025-02-27 10:15:33,812 - UMamba_Training - INFO - Starting epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  3.02it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:37,361 - UMamba_Training - INFO - Epoch 15, Train Loss: 0.2355, Val Loss: 0.3457, Val Dice: 0.8558\n",
      "2025-02-27 10:15:37,395 - UMamba_Training - INFO - Best model saved at epoch 15 with val_loss 0.3457\n",
      "2025-02-27 10:15:37,433 - UMamba_Training - INFO - Starting epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  3.03it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:40,974 - UMamba_Training - INFO - Epoch 16, Train Loss: 0.2135, Val Loss: 0.3736, Val Dice: 0.8571\n",
      "2025-02-27 10:15:41,006 - UMamba_Training - INFO - Starting epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.99it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:44,587 - UMamba_Training - INFO - Epoch 17, Train Loss: 0.1955, Val Loss: 0.3521, Val Dice: 0.8592\n",
      "2025-02-27 10:15:44,622 - UMamba_Training - INFO - Starting epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  3.00it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:48,191 - UMamba_Training - INFO - Epoch 18, Train Loss: 0.1889, Val Loss: 0.3472, Val Dice: 0.8537\n",
      "2025-02-27 10:15:48,223 - UMamba_Training - INFO - Starting epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.98it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:51,811 - UMamba_Training - INFO - Epoch 19, Train Loss: 0.1884, Val Loss: 0.3534, Val Dice: 0.8518\n",
      "2025-02-27 10:15:51,843 - UMamba_Training - INFO - Starting epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:55,443 - UMamba_Training - INFO - Epoch 20, Train Loss: 0.1868, Val Loss: 0.3506, Val Dice: 0.8576\n",
      "2025-02-27 10:15:55,476 - UMamba_Training - INFO - Starting epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:15:59,077 - UMamba_Training - INFO - Epoch 21, Train Loss: 0.1834, Val Loss: 0.3460, Val Dice: 0.8640\n",
      "2025-02-27 10:15:59,110 - UMamba_Training - INFO - Starting epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:02,714 - UMamba_Training - INFO - Epoch 22, Train Loss: 0.1762, Val Loss: 0.3585, Val Dice: 0.8555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:02,894 - UMamba_Training - INFO - Starting epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:06,496 - UMamba_Training - INFO - Epoch 23, Train Loss: 0.1743, Val Loss: 0.3524, Val Dice: 0.8584\n",
      "2025-02-27 10:16:06,530 - UMamba_Training - INFO - Starting epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.96it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:10,148 - UMamba_Training - INFO - Epoch 24, Train Loss: 0.1704, Val Loss: 0.3530, Val Dice: 0.8634\n",
      "2025-02-27 10:16:10,180 - UMamba_Training - INFO - Starting epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:13,791 - UMamba_Training - INFO - Epoch 25, Train Loss: 0.1598, Val Loss: 0.3557, Val Dice: 0.8634\n",
      "2025-02-27 10:16:13,824 - UMamba_Training - INFO - Starting epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:17,434 - UMamba_Training - INFO - Epoch 26, Train Loss: 0.1530, Val Loss: 0.3658, Val Dice: 0.8597\n",
      "2025-02-27 10:16:17,467 - UMamba_Training - INFO - Starting epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:21,069 - UMamba_Training - INFO - Epoch 27, Train Loss: 0.1515, Val Loss: 0.3677, Val Dice: 0.8575\n",
      "2025-02-27 10:16:21,101 - UMamba_Training - INFO - Starting epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:24,702 - UMamba_Training - INFO - Epoch 28, Train Loss: 0.1529, Val Loss: 0.3870, Val Dice: 0.8530\n",
      "2025-02-27 10:16:24,734 - UMamba_Training - INFO - Starting epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.96it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:28,347 - UMamba_Training - INFO - Epoch 29, Train Loss: 0.1557, Val Loss: 0.3843, Val Dice: 0.8581\n",
      "2025-02-27 10:16:28,382 - UMamba_Training - INFO - Starting epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:31,990 - UMamba_Training - INFO - Epoch 30, Train Loss: 0.1541, Val Loss: 0.3972, Val Dice: 0.8590\n",
      "2025-02-27 10:16:32,024 - UMamba_Training - INFO - Starting epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.96it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:35,636 - UMamba_Training - INFO - Epoch 31, Train Loss: 0.1527, Val Loss: 0.3723, Val Dice: 0.8579\n",
      "2025-02-27 10:16:35,669 - UMamba_Training - INFO - Starting epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:39,279 - UMamba_Training - INFO - Epoch 32, Train Loss: 0.1572, Val Loss: 0.3663, Val Dice: 0.8570\n",
      "2025-02-27 10:16:39,312 - UMamba_Training - INFO - Starting epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.96it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:42,934 - UMamba_Training - INFO - Epoch 33, Train Loss: 0.1523, Val Loss: 0.3585, Val Dice: 0.8654\n",
      "2025-02-27 10:16:42,966 - UMamba_Training - INFO - Starting epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.93it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:46,616 - UMamba_Training - INFO - Epoch 34, Train Loss: 0.1472, Val Loss: 0.3790, Val Dice: 0.8522\n",
      "2025-02-27 10:16:46,650 - UMamba_Training - INFO - Starting epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.92it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:50,310 - UMamba_Training - INFO - Epoch 35, Train Loss: 0.1419, Val Loss: 0.3923, Val Dice: 0.8573\n",
      "2025-02-27 10:16:50,344 - UMamba_Training - INFO - Starting epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.90it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:54,041 - UMamba_Training - INFO - Epoch 36, Train Loss: 0.1372, Val Loss: 0.3939, Val Dice: 0.8528\n",
      "2025-02-27 10:16:54,074 - UMamba_Training - INFO - Starting epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.90it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:16:57,773 - UMamba_Training - INFO - Epoch 37, Train Loss: 0.1377, Val Loss: 0.3842, Val Dice: 0.8540\n",
      "2025-02-27 10:16:57,805 - UMamba_Training - INFO - Starting epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.90it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:17:01,527 - UMamba_Training - INFO - Epoch 38, Train Loss: 0.1388, Val Loss: 0.4044, Val Dice: 0.8545\n",
      "2025-02-27 10:17:01,559 - UMamba_Training - INFO - Starting epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.90it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:17:05,254 - UMamba_Training - INFO - Epoch 39, Train Loss: 0.1408, Val Loss: 0.4111, Val Dice: 0.8486\n",
      "2025-02-27 10:17:05,288 - UMamba_Training - INFO - Starting epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.88it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:17:08,997 - UMamba_Training - INFO - Epoch 40, Train Loss: 0.1445, Val Loss: 0.4320, Val Dice: 0.8398\n",
      "2025-02-27 10:17:09,046 - UMamba_Training - INFO - Starting epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.86it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:17:12,794 - UMamba_Training - INFO - Epoch 41, Train Loss: 0.1519, Val Loss: 0.3839, Val Dice: 0.8555\n",
      "2025-02-27 10:17:12,828 - UMamba_Training - INFO - Starting epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.87it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:17:16,562 - UMamba_Training - INFO - Epoch 42, Train Loss: 0.1534, Val Loss: 0.3894, Val Dice: 0.8540\n",
      "2025-02-27 10:17:16,595 - UMamba_Training - INFO - Starting epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.88it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:17:20,318 - UMamba_Training - INFO - Epoch 43, Train Loss: 0.1526, Val Loss: 0.4395, Val Dice: 0.8314\n",
      "2025-02-27 10:17:20,351 - UMamba_Training - INFO - Starting epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.88it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:17:24,078 - UMamba_Training - INFO - Epoch 44, Train Loss: 0.1693, Val Loss: 0.4864, Val Dice: 0.8215\n",
      "2025-02-27 10:17:24,111 - UMamba_Training - INFO - Starting epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.83it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:17:27,894 - UMamba_Training - INFO - Epoch 45, Train Loss: 0.1889, Val Loss: 0.3852, Val Dice: 0.8428\n",
      "2025-02-27 10:17:27,928 - UMamba_Training - INFO - Starting epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.85it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:17:31,685 - UMamba_Training - INFO - Epoch 46, Train Loss: 0.1827, Val Loss: 0.3822, Val Dice: 0.8555\n",
      "2025-02-27 10:17:31,719 - UMamba_Training - INFO - Starting epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.85it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:17:35,475 - UMamba_Training - INFO - Epoch 47, Train Loss: 0.1637, Val Loss: 0.4509, Val Dice: 0.8525\n",
      "2025-02-27 10:17:35,508 - UMamba_Training - INFO - Starting epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.81it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:17:39,317 - UMamba_Training - INFO - Epoch 48, Train Loss: 0.1477, Val Loss: 0.3784, Val Dice: 0.8618\n",
      "2025-02-27 10:17:39,351 - UMamba_Training - INFO - Starting epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.86it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:17:43,099 - UMamba_Training - INFO - Epoch 49, Train Loss: 0.1331, Val Loss: 0.3844, Val Dice: 0.8668\n",
      "2025-02-27 10:17:43,132 - UMamba_Training - INFO - Starting epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.81it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:17:46,934 - UMamba_Training - INFO - Epoch 50, Train Loss: 0.1259, Val Loss: 0.4075, Val Dice: 0.8623\n",
      "2025-02-27 10:17:46,968 - UMamba_Training - INFO - Metrics saved to ./umamba/metrics/umamba_adam_lr0.001_bs8_both_80pct_27022025_metrics.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-27 10:17:47,112 - UMamba_Training - INFO - Plot saved to ./umamba/metrics/umamba_adam_lr0.001_bs8_both_80pct_27022025_training_validation_metrics.png\n",
      "2025-02-27 10:17:47,113 - UMamba_Training - INFO - Logs saved to ./umamba/logs/umamba_adam_lr0.001_bs8_both_80pct_27022025_logs.json\n",
      "2025-02-27 10:17:47,115 - UMamba_Training - INFO - Training completed.\n"
     ]
    }
   ],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Train U-Mamba on Vessel Segmentation Dataset.\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-3, help=\"Learning rate\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=8, help=\"Batch size\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=50, help=\"Number of epochs\")\n",
    "    parser.add_argument(\"--optimizer\", type=str, default=\"adam\", choices=[\"sgd\", \"adam\"], help=\"Optimizer choice\")\n",
    "    parser.add_argument(\"--loss_type\", type=str, default=\"both\", choices=[\"dice\", \"ce\", \"both\"], help=\"Loss type\")\n",
    "    parser.add_argument(\"--scheduler\", type=str, default=\"none\", choices=[\"cosine\", \"none\"], help=\"Scheduler type\")\n",
    "    parser.add_argument(\"--train_size\", type=float, default=80, help=\"Train split ratio as a percentage\")\n",
    "    parser.add_argument(\"--image_size\", type=int, default=256, help=\"Image size for data augmentation\")\n",
    "    parser.add_argument(\"--accumulate_grad_steps\", type=int, default=1, help=\"Accumulate grad steps\")\n",
    "    parser.add_argument(\"--image_dir\", type=str, default=\"../../data/vess-map/images\", help=\"Images directory\")\n",
    "    parser.add_argument(\"--mask_dir\", type=str, default=\"../../data/vess-map/labels\", help=\"Masks directory\")\n",
    "    parser.add_argument(\"--skeleton_dir\", type=str, default=\"../../data/vess-map/skeletons\", help=\"Skeletons directory\")\n",
    "    parser.add_argument(\"--augment\", type=bool, default=True, help=\"Apply random data augmentation\")\n",
    "    # Pass an empty list to parse_args so that defaults are used\n",
    "    return parser.parse_args([])\n",
    "\n",
    "# Get arguments (using defaults)\n",
    "args = get_args()\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "                    handlers=[logging.StreamHandler(sys.stdout)])\n",
    "\n",
    "# Run your training function\n",
    "train_umamba(model, args)\n",
    "\n",
    "# Log completion\n",
    "log_message(logging.INFO, \"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (umamba)",
   "language": "python",
   "name": "umamba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
